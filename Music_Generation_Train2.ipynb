{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In our last model in file \"Music_Generation_Train1.ipynb\", we got only 82% accuracy. However, in order to generate melodious music, we need at least 90% accuracy. \n",
    "### So, we have loaded the weights of last epoch from our previous model into this model and also we have added 2 extra layers of LSTM here with more LSTM units. \n",
    "### Here, we are fine-tuning our old layers and we have added more layers. In short, here we are doing \"Transfer Learning\" from old to new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, TimeDistributed, Dense, Activation, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = \"../Data2/\"\n",
    "data_file = \"Data_Tunes.txt\"\n",
    "charIndex_json = \"char_to_index.json\"\n",
    "model_weights_directory = '../Data2/Model_Weights/'\n",
    "BATCH_SIZE = 16\n",
    "SEQ_LENGTH = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_batches(all_chars, unique_chars):\n",
    "    length = all_chars.shape[0]\n",
    "    batch_chars = int(length / BATCH_SIZE) #155222/16 = 9701\n",
    "    \n",
    "    for start in range(0, batch_chars - SEQ_LENGTH, 64):  #(0, 9637, 64)  #it denotes number of batches. It runs everytime when\n",
    "        #new batch is created. We have a total of 151 batches.\n",
    "        X = np.zeros((BATCH_SIZE, SEQ_LENGTH))    #(16, 64)\n",
    "        Y = np.zeros((BATCH_SIZE, SEQ_LENGTH, unique_chars))   #(16, 64, 87)\n",
    "        for batch_index in range(0, 16):  #it denotes each row in a batch.  \n",
    "            for i in range(0, 64):  #it denotes each column in a batch. Each column represents each character means \n",
    "                #each time-step character in a sequence.\n",
    "                X[batch_index, i] = all_chars[batch_index * batch_chars + start + i]\n",
    "                Y[batch_index, i, all_chars[batch_index * batch_chars + start + i + 1]] = 1 #here we have added '1' because the\n",
    "                #correct label will be the next character in the sequence. So, the next character will be denoted by\n",
    "                #all_chars[batch_index * batch_chars + start + i] + 1. \n",
    "        yield X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def built_model(batch_size, seq_length, unique_chars):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Embedding(input_dim = unique_chars, output_dim = 512, batch_input_shape = (batch_size, seq_length), name = \"embd_1\")) \n",
    "    \n",
    "    model.add(LSTM(256, return_sequences = True, stateful = True, name = \"lstm_first\"))\n",
    "    model.add(Dropout(0.2, name = \"drp_1\"))\n",
    "    \n",
    "    model.add(LSTM(256, return_sequences = True, stateful = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(LSTM(256, return_sequences = True, stateful = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(TimeDistributed(Dense(unique_chars)))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    \n",
    "    model.load_weights(\"../Data/Model_Weights/Weights_80.h5\", by_name = True)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_model(data, epochs = 90):\n",
    "    #mapping character to index\n",
    "    char_to_index = {ch: i for (i, ch) in enumerate(sorted(list(set(data))))}\n",
    "    print(\"Number of unique characters in our whole tunes database = {}\".format(len(char_to_index))) #87\n",
    "    \n",
    "    with open(os.path.join(data_directory, charIndex_json), mode = \"w\") as f:\n",
    "        json.dump(char_to_index, f)\n",
    "        \n",
    "    index_to_char = {i: ch for (ch, i) in char_to_index.items()}\n",
    "    unique_chars = len(char_to_index)\n",
    "    \n",
    "    model = built_model(BATCH_SIZE, SEQ_LENGTH, unique_chars)\n",
    "    model.summary()\n",
    "    model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "    \n",
    "    all_characters = np.asarray([char_to_index[c] for c in data], dtype = np.int32)\n",
    "    print(\"Total number of characters = \"+str(all_characters.shape[0])) #155222\n",
    "    \n",
    "    epoch_number, loss, accuracy = [], [], []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch+1, epochs))\n",
    "        final_epoch_loss, final_epoch_accuracy = 0, 0\n",
    "        epoch_number.append(epoch+1)\n",
    "        \n",
    "        for i, (x, y) in enumerate(read_batches(all_characters, unique_chars)):\n",
    "            final_epoch_loss, final_epoch_accuracy = model.train_on_batch(x, y) #check documentation of train_on_batch here: https://keras.io/models/sequential/\n",
    "            print(\"Batch: {}, Loss: {}, Accuracy: {}\".format(i+1, final_epoch_loss, final_epoch_accuracy))\n",
    "            #here, above we are reading the batches one-by-one and train our model on each batch one-by-one.\n",
    "        loss.append(final_epoch_loss)\n",
    "        accuracy.append(final_epoch_accuracy)\n",
    "        \n",
    "        #saving weights after every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            if not os.path.exists(model_weights_directory):\n",
    "                os.makedirs(model_weights_directory)\n",
    "            model.save_weights(os.path.join(model_weights_directory, \"Weights_{}.h5\".format(epoch+1)))\n",
    "            print('Saved Weights at epoch {} to file Weights_{}.h5'.format(epoch+1, epoch+1))\n",
    "    \n",
    "    #creating dataframe and record all the losses and accuracies at each epoch\n",
    "    log_frame = pd.DataFrame(columns = [\"Epoch\", \"Loss\", \"Accuracy\"])\n",
    "    log_frame[\"Epoch\"] = epoch_number\n",
    "    log_frame[\"Loss\"] = loss\n",
    "    log_frame[\"Accuracy\"] = accuracy\n",
    "    log_frame.to_csv(\"../Data2/log.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters in our whole tunes database = 87\n",
      "WARNING:tensorflow:From C:\\Users\\Samyak\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Samyak\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Samyak\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Samyak\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Samyak\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embd_1 (Embedding)           (16, 64, 512)             44544     \n",
      "_________________________________________________________________\n",
      "lstm_first (LSTM)            (16, 64, 256)             787456    \n",
      "_________________________________________________________________\n",
      "drp_1 (Dropout)              (16, 64, 256)             0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (16, 64, 256)             525312    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (16, 64, 256)             0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (16, 64, 256)             525312    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (16, 64, 256)             0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (16, 64, 87)              22359     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (16, 64, 87)              0         \n",
      "=================================================================\n",
      "Total params: 1,904,983\n",
      "Trainable params: 1,904,983\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\Samyak\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Samyak\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "Total number of characters = 155222\n",
      "Epoch 1/90\n",
      "WARNING:tensorflow:From C:\\Users\\Samyak\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\Samyak\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Samyak\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Samyak\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Samyak\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Samyak\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Samyak\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Samyak\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Samyak\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "Batch: 1, Loss: 4.465806007385254, Accuracy: 0.01171875\n",
      "Batch: 2, Loss: 4.447969913482666, Accuracy: 0.1748046875\n",
      "Batch: 3, Loss: 4.416105270385742, Accuracy: 0.134765625\n",
      "Batch: 4, Loss: 4.333923816680908, Accuracy: 0.1025390625\n",
      "Batch: 5, Loss: 3.959050416946411, Accuracy: 0.1435546875\n",
      "Batch: 6, Loss: 3.775230646133423, Accuracy: 0.166015625\n",
      "Batch: 7, Loss: 3.5774142742156982, Accuracy: 0.1630859375\n",
      "Batch: 8, Loss: 3.599449872970581, Accuracy: 0.125\n",
      "Batch: 9, Loss: 3.7045750617980957, Accuracy: 0.056640625\n",
      "Batch: 10, Loss: 3.55876088142395, Accuracy: 0.0673828125\n",
      "Batch: 11, Loss: 3.3212594985961914, Accuracy: 0.0830078125\n",
      "Batch: 12, Loss: 3.482234477996826, Accuracy: 0.087890625\n",
      "Batch: 13, Loss: 3.6882283687591553, Accuracy: 0.1162109375\n",
      "Batch: 14, Loss: 3.4393017292022705, Accuracy: 0.1474609375\n",
      "Batch: 15, Loss: 3.6843738555908203, Accuracy: 0.1298828125\n",
      "Batch: 16, Loss: 3.403935432434082, Accuracy: 0.162109375\n",
      "Batch: 17, Loss: 3.3109190464019775, Accuracy: 0.1796875\n",
      "Batch: 18, Loss: 3.290386199951172, Accuracy: 0.16796875\n",
      "Batch: 19, Loss: 3.5621283054351807, Accuracy: 0.12890625\n",
      "Batch: 20, Loss: 3.6731815338134766, Accuracy: 0.1123046875\n",
      "Batch: 21, Loss: 3.514194965362549, Accuracy: 0.12890625\n",
      "Batch: 22, Loss: 3.3093628883361816, Accuracy: 0.1728515625\n",
      "Batch: 23, Loss: 3.3989944458007812, Accuracy: 0.126953125\n",
      "Batch: 24, Loss: 3.533853530883789, Accuracy: 0.0947265625\n",
      "Batch: 25, Loss: 3.484896659851074, Accuracy: 0.10546875\n",
      "Batch: 26, Loss: 3.468561887741089, Accuracy: 0.130859375\n",
      "Batch: 27, Loss: 3.40908145904541, Accuracy: 0.126953125\n",
      "Batch: 28, Loss: 3.2768049240112305, Accuracy: 0.15625\n",
      "Batch: 29, Loss: 3.4427194595336914, Accuracy: 0.130859375\n",
      "Batch: 30, Loss: 3.7511377334594727, Accuracy: 0.091796875\n",
      "Batch: 31, Loss: 3.6420490741729736, Accuracy: 0.1240234375\n",
      "Batch: 32, Loss: 3.524411678314209, Accuracy: 0.1279296875\n",
      "Batch: 33, Loss: 3.5100035667419434, Accuracy: 0.158203125\n",
      "Batch: 34, Loss: 3.366121530532837, Accuracy: 0.1533203125\n",
      "Batch: 35, Loss: 3.4870333671569824, Accuracy: 0.119140625\n",
      "Batch: 36, Loss: 3.603954315185547, Accuracy: 0.103515625\n",
      "Batch: 37, Loss: 3.4683661460876465, Accuracy: 0.1279296875\n",
      "Batch: 38, Loss: 3.366764545440674, Accuracy: 0.1484375\n",
      "Batch: 39, Loss: 3.431509494781494, Accuracy: 0.142578125\n",
      "Batch: 40, Loss: 3.57755708694458, Accuracy: 0.1318359375\n",
      "Batch: 41, Loss: 3.5442068576812744, Accuracy: 0.1416015625\n",
      "Batch: 42, Loss: 3.3565821647644043, Accuracy: 0.1640625\n",
      "Batch: 43, Loss: 3.2367751598358154, Accuracy: 0.1748046875\n",
      "Batch: 44, Loss: 3.2436180114746094, Accuracy: 0.1728515625\n",
      "Batch: 45, Loss: 3.2570414543151855, Accuracy: 0.1650390625\n",
      "Batch: 46, Loss: 3.5555825233459473, Accuracy: 0.126953125\n",
      "Batch: 47, Loss: 3.5140137672424316, Accuracy: 0.1240234375\n",
      "Batch: 48, Loss: 3.4114367961883545, Accuracy: 0.1328125\n",
      "Batch: 49, Loss: 3.3204293251037598, Accuracy: 0.1474609375\n",
      "Batch: 50, Loss: 3.2566869258880615, Accuracy: 0.146484375\n",
      "Batch: 51, Loss: 3.2790379524230957, Accuracy: 0.150390625\n",
      "Batch: 52, Loss: 3.423856735229492, Accuracy: 0.1337890625\n",
      "Batch: 53, Loss: 3.3294363021850586, Accuracy: 0.1416015625\n",
      "Batch: 54, Loss: 3.330312728881836, Accuracy: 0.1494140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 55, Loss: 3.260678291320801, Accuracy: 0.1376953125\n",
      "Batch: 56, Loss: 3.3201704025268555, Accuracy: 0.150390625\n",
      "Batch: 57, Loss: 3.364957809448242, Accuracy: 0.1318359375\n",
      "Batch: 58, Loss: 3.2458271980285645, Accuracy: 0.1455078125\n",
      "Batch: 59, Loss: 3.3630290031433105, Accuracy: 0.138671875\n",
      "Batch: 60, Loss: 3.2287213802337646, Accuracy: 0.140625\n",
      "Batch: 61, Loss: 3.244297981262207, Accuracy: 0.1611328125\n",
      "Batch: 62, Loss: 3.3278794288635254, Accuracy: 0.1513671875\n",
      "Batch: 63, Loss: 3.277700901031494, Accuracy: 0.1474609375\n",
      "Batch: 64, Loss: 3.300107955932617, Accuracy: 0.15234375\n",
      "Batch: 65, Loss: 3.2747254371643066, Accuracy: 0.1630859375\n",
      "Batch: 66, Loss: 3.2456910610198975, Accuracy: 0.1591796875\n",
      "Batch: 67, Loss: 3.1462767124176025, Accuracy: 0.185546875\n",
      "Batch: 68, Loss: 3.192640781402588, Accuracy: 0.1884765625\n",
      "Batch: 69, Loss: 3.2781474590301514, Accuracy: 0.1640625\n",
      "Batch: 70, Loss: 3.256969451904297, Accuracy: 0.1669921875\n",
      "Batch: 71, Loss: 3.2020156383514404, Accuracy: 0.171875\n",
      "Batch: 72, Loss: 3.247866153717041, Accuracy: 0.1591796875\n",
      "Batch: 73, Loss: 3.3312876224517822, Accuracy: 0.140625\n",
      "Batch: 74, Loss: 3.274284839630127, Accuracy: 0.1484375\n",
      "Batch: 75, Loss: 3.1446731090545654, Accuracy: 0.171875\n",
      "Batch: 76, Loss: 3.1279664039611816, Accuracy: 0.169921875\n",
      "Batch: 77, Loss: 3.202331304550171, Accuracy: 0.1728515625\n",
      "Batch: 78, Loss: 3.3625307083129883, Accuracy: 0.1533203125\n",
      "Batch: 79, Loss: 3.3514254093170166, Accuracy: 0.13671875\n",
      "Batch: 80, Loss: 3.0793981552124023, Accuracy: 0.1806640625\n",
      "Batch: 81, Loss: 3.049844264984131, Accuracy: 0.19140625\n",
      "Batch: 82, Loss: 3.124767303466797, Accuracy: 0.1806640625\n",
      "Batch: 83, Loss: 3.175711154937744, Accuracy: 0.169921875\n",
      "Batch: 84, Loss: 3.2447826862335205, Accuracy: 0.1650390625\n",
      "Batch: 85, Loss: 3.2344040870666504, Accuracy: 0.16015625\n",
      "Batch: 86, Loss: 3.150421142578125, Accuracy: 0.166015625\n",
      "Batch: 87, Loss: 3.175755023956299, Accuracy: 0.17578125\n",
      "Batch: 88, Loss: 3.1690943241119385, Accuracy: 0.1728515625\n",
      "Batch: 89, Loss: 3.1948130130767822, Accuracy: 0.1591796875\n",
      "Batch: 90, Loss: 3.2098779678344727, Accuracy: 0.169921875\n",
      "Batch: 91, Loss: 3.1574082374572754, Accuracy: 0.1611328125\n",
      "Batch: 92, Loss: 3.1755785942077637, Accuracy: 0.1650390625\n",
      "Batch: 93, Loss: 3.146146059036255, Accuracy: 0.1484375\n",
      "Batch: 94, Loss: 3.1263465881347656, Accuracy: 0.185546875\n",
      "Batch: 95, Loss: 3.033552646636963, Accuracy: 0.1943359375\n",
      "Batch: 96, Loss: 3.191533088684082, Accuracy: 0.1728515625\n",
      "Batch: 97, Loss: 3.181226968765259, Accuracy: 0.173828125\n",
      "Batch: 98, Loss: 3.2000937461853027, Accuracy: 0.177734375\n",
      "Batch: 99, Loss: 3.0847668647766113, Accuracy: 0.166015625\n",
      "Batch: 100, Loss: 3.020937442779541, Accuracy: 0.1845703125\n",
      "Batch: 101, Loss: 3.069955348968506, Accuracy: 0.1806640625\n",
      "Batch: 102, Loss: 3.0655605792999268, Accuracy: 0.1630859375\n",
      "Batch: 103, Loss: 3.2049105167388916, Accuracy: 0.1484375\n",
      "Batch: 104, Loss: 3.078126907348633, Accuracy: 0.1748046875\n",
      "Batch: 105, Loss: 3.074413299560547, Accuracy: 0.1650390625\n",
      "Batch: 106, Loss: 3.120851993560791, Accuracy: 0.169921875\n",
      "Batch: 107, Loss: 3.1600770950317383, Accuracy: 0.16796875\n",
      "Batch: 108, Loss: 3.136136531829834, Accuracy: 0.169921875\n",
      "Batch: 109, Loss: 3.096151351928711, Accuracy: 0.177734375\n",
      "Batch: 110, Loss: 3.0416808128356934, Accuracy: 0.177734375\n",
      "Batch: 111, Loss: 2.951756477355957, Accuracy: 0.1875\n",
      "Batch: 112, Loss: 3.12306809425354, Accuracy: 0.1767578125\n",
      "Batch: 113, Loss: 3.171518325805664, Accuracy: 0.1552734375\n",
      "Batch: 114, Loss: 3.0315134525299072, Accuracy: 0.185546875\n",
      "Batch: 115, Loss: 3.068894147872925, Accuracy: 0.2001953125\n",
      "Batch: 116, Loss: 3.0680692195892334, Accuracy: 0.1806640625\n",
      "Batch: 117, Loss: 3.138608455657959, Accuracy: 0.1728515625\n",
      "Batch: 118, Loss: 3.101052761077881, Accuracy: 0.177734375\n",
      "Batch: 119, Loss: 3.1555066108703613, Accuracy: 0.1669921875\n",
      "Batch: 120, Loss: 3.0434012413024902, Accuracy: 0.1845703125\n",
      "Batch: 121, Loss: 3.032984495162964, Accuracy: 0.201171875\n",
      "Batch: 122, Loss: 3.1593921184539795, Accuracy: 0.17578125\n",
      "Batch: 123, Loss: 3.083268165588379, Accuracy: 0.1708984375\n",
      "Batch: 124, Loss: 3.036660671234131, Accuracy: 0.1865234375\n",
      "Batch: 125, Loss: 3.0086419582366943, Accuracy: 0.1923828125\n",
      "Batch: 126, Loss: 3.0239953994750977, Accuracy: 0.1865234375\n",
      "Batch: 127, Loss: 3.073249101638794, Accuracy: 0.1689453125\n",
      "Batch: 128, Loss: 3.070709228515625, Accuracy: 0.1796875\n",
      "Batch: 129, Loss: 3.005335569381714, Accuracy: 0.185546875\n",
      "Batch: 130, Loss: 3.032032012939453, Accuracy: 0.1845703125\n",
      "Batch: 131, Loss: 3.0309133529663086, Accuracy: 0.173828125\n",
      "Batch: 132, Loss: 3.101574420928955, Accuracy: 0.1787109375\n",
      "Batch: 133, Loss: 3.0623779296875, Accuracy: 0.1884765625\n",
      "Batch: 134, Loss: 2.998426914215088, Accuracy: 0.205078125\n",
      "Batch: 135, Loss: 2.9599227905273438, Accuracy: 0.205078125\n",
      "Batch: 136, Loss: 2.939126968383789, Accuracy: 0.212890625\n",
      "Batch: 137, Loss: 2.7885470390319824, Accuracy: 0.2314453125\n",
      "Batch: 138, Loss: 2.8604140281677246, Accuracy: 0.216796875\n",
      "Batch: 139, Loss: 2.81278395652771, Accuracy: 0.220703125\n",
      "Batch: 140, Loss: 2.89809250831604, Accuracy: 0.2177734375\n",
      "Batch: 141, Loss: 2.945685863494873, Accuracy: 0.1962890625\n",
      "Batch: 142, Loss: 2.861588716506958, Accuracy: 0.2236328125\n",
      "Batch: 143, Loss: 2.9047231674194336, Accuracy: 0.189453125\n",
      "Batch: 144, Loss: 2.895860195159912, Accuracy: 0.2197265625\n",
      "Batch: 145, Loss: 2.81766414642334, Accuracy: 0.2275390625\n",
      "Batch: 146, Loss: 2.9464826583862305, Accuracy: 0.21875\n",
      "Batch: 147, Loss: 2.9773924350738525, Accuracy: 0.208984375\n",
      "Batch: 148, Loss: 2.8823771476745605, Accuracy: 0.2119140625\n",
      "Batch: 149, Loss: 2.9275827407836914, Accuracy: 0.2177734375\n",
      "Batch: 150, Loss: 2.8423871994018555, Accuracy: 0.25390625\n",
      "Batch: 151, Loss: 2.945814847946167, Accuracy: 0.2177734375\n",
      "Epoch 2/90\n",
      "Batch: 1, Loss: 2.810152769088745, Accuracy: 0.2607421875\n",
      "Batch: 2, Loss: 2.639261484146118, Accuracy: 0.2685546875\n",
      "Batch: 3, Loss: 2.774895191192627, Accuracy: 0.2568359375\n",
      "Batch: 4, Loss: 2.909003734588623, Accuracy: 0.232421875\n",
      "Batch: 5, Loss: 2.7662816047668457, Accuracy: 0.25\n",
      "Batch: 6, Loss: 2.649482011795044, Accuracy: 0.29296875\n",
      "Batch: 7, Loss: 2.6432461738586426, Accuracy: 0.28125\n",
      "Batch: 8, Loss: 2.7104716300964355, Accuracy: 0.271484375\n",
      "Batch: 9, Loss: 2.674497365951538, Accuracy: 0.2802734375\n",
      "Batch: 10, Loss: 2.659299612045288, Accuracy: 0.3037109375\n",
      "Batch: 11, Loss: 2.551835298538208, Accuracy: 0.3203125\n",
      "Batch: 12, Loss: 2.659188985824585, Accuracy: 0.298828125\n",
      "Batch: 13, Loss: 2.700798511505127, Accuracy: 0.26953125\n",
      "Batch: 14, Loss: 2.6245436668395996, Accuracy: 0.28125\n",
      "Batch: 15, Loss: 2.792433738708496, Accuracy: 0.2548828125\n",
      "Batch: 16, Loss: 2.556731700897217, Accuracy: 0.30078125\n",
      "Batch: 17, Loss: 2.507648468017578, Accuracy: 0.30859375\n",
      "Batch: 18, Loss: 2.5521202087402344, Accuracy: 0.2998046875\n",
      "Batch: 19, Loss: 2.653441905975342, Accuracy: 0.2685546875\n",
      "Batch: 20, Loss: 2.776844024658203, Accuracy: 0.23828125\n",
      "Batch: 21, Loss: 2.6383743286132812, Accuracy: 0.287109375\n",
      "Batch: 22, Loss: 2.4867238998413086, Accuracy: 0.3203125\n",
      "Batch: 23, Loss: 2.5055489540100098, Accuracy: 0.3046875\n",
      "Batch: 24, Loss: 2.6570448875427246, Accuracy: 0.2890625\n",
      "Batch: 25, Loss: 2.5151174068450928, Accuracy: 0.298828125\n",
      "Batch: 26, Loss: 2.4284424781799316, Accuracy: 0.3212890625\n",
      "Batch: 27, Loss: 2.5604441165924072, Accuracy: 0.30078125\n",
      "Batch: 28, Loss: 2.4450292587280273, Accuracy: 0.3154296875\n",
      "Batch: 29, Loss: 2.542837619781494, Accuracy: 0.296875\n",
      "Batch: 30, Loss: 2.7671351432800293, Accuracy: 0.2578125\n",
      "Batch: 31, Loss: 2.6838603019714355, Accuracy: 0.2763671875\n",
      "Batch: 32, Loss: 2.5381884574890137, Accuracy: 0.3076171875\n",
      "Batch: 33, Loss: 2.5707242488861084, Accuracy: 0.3076171875\n",
      "Batch: 34, Loss: 2.563502311706543, Accuracy: 0.3125\n",
      "Batch: 35, Loss: 2.587047576904297, Accuracy: 0.28515625\n",
      "Batch: 36, Loss: 2.7396039962768555, Accuracy: 0.263671875\n",
      "Batch: 37, Loss: 2.6081838607788086, Accuracy: 0.2890625\n",
      "Batch: 38, Loss: 2.5051918029785156, Accuracy: 0.3017578125\n",
      "Batch: 39, Loss: 2.547877788543701, Accuracy: 0.3154296875\n",
      "Batch: 40, Loss: 2.682891368865967, Accuracy: 0.30078125\n",
      "Batch: 41, Loss: 2.5539464950561523, Accuracy: 0.318359375\n",
      "Batch: 42, Loss: 2.402977228164673, Accuracy: 0.3359375\n",
      "Batch: 43, Loss: 2.271350145339966, Accuracy: 0.3564453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 44, Loss: 2.2387852668762207, Accuracy: 0.3740234375\n",
      "Batch: 45, Loss: 2.2744388580322266, Accuracy: 0.3662109375\n",
      "Batch: 46, Loss: 2.5781586170196533, Accuracy: 0.302734375\n",
      "Batch: 47, Loss: 2.683321475982666, Accuracy: 0.2783203125\n",
      "Batch: 48, Loss: 2.5579769611358643, Accuracy: 0.3134765625\n",
      "Batch: 49, Loss: 2.4809467792510986, Accuracy: 0.3173828125\n",
      "Batch: 50, Loss: 2.4808716773986816, Accuracy: 0.3154296875\n",
      "Batch: 51, Loss: 2.519428253173828, Accuracy: 0.31640625\n",
      "Batch: 52, Loss: 2.5301332473754883, Accuracy: 0.3017578125\n",
      "Batch: 53, Loss: 2.318150043487549, Accuracy: 0.3271484375\n",
      "Batch: 54, Loss: 2.4637017250061035, Accuracy: 0.3193359375\n",
      "Batch: 55, Loss: 2.338085174560547, Accuracy: 0.3359375\n",
      "Batch: 56, Loss: 2.4411890506744385, Accuracy: 0.34765625\n",
      "Batch: 57, Loss: 2.4545516967773438, Accuracy: 0.32421875\n",
      "Batch: 58, Loss: 2.3963820934295654, Accuracy: 0.3388671875\n",
      "Batch: 59, Loss: 2.482133388519287, Accuracy: 0.302734375\n",
      "Batch: 60, Loss: 2.3171069622039795, Accuracy: 0.359375\n",
      "Batch: 61, Loss: 2.3506155014038086, Accuracy: 0.333984375\n",
      "Batch: 62, Loss: 2.494192361831665, Accuracy: 0.3212890625\n",
      "Batch: 63, Loss: 2.3734116554260254, Accuracy: 0.3408203125\n",
      "Batch: 64, Loss: 2.421358108520508, Accuracy: 0.337890625\n",
      "Batch: 65, Loss: 2.4088737964630127, Accuracy: 0.330078125\n",
      "Batch: 66, Loss: 2.315946102142334, Accuracy: 0.3564453125\n",
      "Batch: 67, Loss: 2.267486333847046, Accuracy: 0.3662109375\n",
      "Batch: 68, Loss: 2.452103614807129, Accuracy: 0.3349609375\n",
      "Batch: 69, Loss: 2.390582323074341, Accuracy: 0.341796875\n",
      "Batch: 70, Loss: 2.4807024002075195, Accuracy: 0.32421875\n",
      "Batch: 71, Loss: 2.255934715270996, Accuracy: 0.3740234375\n",
      "Batch: 72, Loss: 2.3084402084350586, Accuracy: 0.3701171875\n",
      "Batch: 73, Loss: 2.5067505836486816, Accuracy: 0.32421875\n",
      "Batch: 74, Loss: 2.3528590202331543, Accuracy: 0.3544921875\n",
      "Batch: 75, Loss: 2.244162082672119, Accuracy: 0.3779296875\n",
      "Batch: 76, Loss: 2.1963706016540527, Accuracy: 0.369140625\n",
      "Batch: 77, Loss: 2.2691898345947266, Accuracy: 0.3662109375\n",
      "Batch: 78, Loss: 2.475584030151367, Accuracy: 0.3173828125\n",
      "Batch: 79, Loss: 2.4067540168762207, Accuracy: 0.3310546875\n",
      "Batch: 80, Loss: 2.12564754486084, Accuracy: 0.400390625\n",
      "Batch: 81, Loss: 2.0568838119506836, Accuracy: 0.4130859375\n",
      "Batch: 82, Loss: 2.1222548484802246, Accuracy: 0.3642578125\n",
      "Batch: 83, Loss: 2.2030115127563477, Accuracy: 0.35546875\n",
      "Batch: 84, Loss: 2.2826881408691406, Accuracy: 0.3505859375\n",
      "Batch: 85, Loss: 2.2634451389312744, Accuracy: 0.3681640625\n",
      "Batch: 86, Loss: 2.237123966217041, Accuracy: 0.388671875\n",
      "Batch: 87, Loss: 2.255972146987915, Accuracy: 0.384765625\n",
      "Batch: 88, Loss: 2.297502279281616, Accuracy: 0.365234375\n",
      "Batch: 89, Loss: 2.337224245071411, Accuracy: 0.3623046875\n",
      "Batch: 90, Loss: 2.3076364994049072, Accuracy: 0.34765625\n",
      "Batch: 91, Loss: 2.3156299591064453, Accuracy: 0.345703125\n",
      "Batch: 92, Loss: 2.230247735977173, Accuracy: 0.3671875\n",
      "Batch: 93, Loss: 2.267294406890869, Accuracy: 0.3642578125\n",
      "Batch: 94, Loss: 2.16302490234375, Accuracy: 0.392578125\n",
      "Batch: 95, Loss: 2.025054931640625, Accuracy: 0.44921875\n",
      "Batch: 96, Loss: 2.2950682640075684, Accuracy: 0.359375\n",
      "Batch: 97, Loss: 2.253636360168457, Accuracy: 0.3681640625\n",
      "Batch: 98, Loss: 2.186180830001831, Accuracy: 0.400390625\n",
      "Batch: 99, Loss: 2.066211223602295, Accuracy: 0.388671875\n",
      "Batch: 100, Loss: 2.0097005367279053, Accuracy: 0.4228515625\n",
      "Batch: 101, Loss: 2.177401542663574, Accuracy: 0.3876953125\n",
      "Batch: 102, Loss: 2.105093002319336, Accuracy: 0.396484375\n",
      "Batch: 103, Loss: 2.368661880493164, Accuracy: 0.35546875\n",
      "Batch: 104, Loss: 2.0844480991363525, Accuracy: 0.3955078125\n",
      "Batch: 105, Loss: 2.1209914684295654, Accuracy: 0.4189453125\n",
      "Batch: 106, Loss: 2.1647281646728516, Accuracy: 0.376953125\n",
      "Batch: 107, Loss: 2.279041290283203, Accuracy: 0.3720703125\n",
      "Batch: 108, Loss: 2.2783150672912598, Accuracy: 0.3720703125\n",
      "Batch: 109, Loss: 2.1795878410339355, Accuracy: 0.3876953125\n",
      "Batch: 110, Loss: 2.0216012001037598, Accuracy: 0.4033203125\n",
      "Batch: 111, Loss: 2.0382251739501953, Accuracy: 0.4287109375\n",
      "Batch: 112, Loss: 2.2276251316070557, Accuracy: 0.37890625\n",
      "Batch: 113, Loss: 2.244845390319824, Accuracy: 0.39453125\n",
      "Batch: 114, Loss: 2.121366024017334, Accuracy: 0.4072265625\n",
      "Batch: 115, Loss: 2.2303824424743652, Accuracy: 0.4140625\n",
      "Batch: 116, Loss: 2.248103141784668, Accuracy: 0.3779296875\n",
      "Batch: 117, Loss: 2.2618606090545654, Accuracy: 0.361328125\n",
      "Batch: 118, Loss: 2.1718215942382812, Accuracy: 0.38671875\n",
      "Batch: 119, Loss: 2.2522902488708496, Accuracy: 0.380859375\n",
      "Batch: 120, Loss: 2.1435976028442383, Accuracy: 0.41015625\n",
      "Batch: 121, Loss: 2.1568877696990967, Accuracy: 0.4208984375\n",
      "Batch: 122, Loss: 2.2695183753967285, Accuracy: 0.357421875\n",
      "Batch: 123, Loss: 2.2051141262054443, Accuracy: 0.3876953125\n",
      "Batch: 124, Loss: 2.1775102615356445, Accuracy: 0.3984375\n",
      "Batch: 125, Loss: 2.148831844329834, Accuracy: 0.40625\n",
      "Batch: 126, Loss: 2.176046371459961, Accuracy: 0.3837890625\n",
      "Batch: 127, Loss: 2.195704460144043, Accuracy: 0.3916015625\n",
      "Batch: 128, Loss: 2.2836523056030273, Accuracy: 0.3525390625\n",
      "Batch: 129, Loss: 2.1223011016845703, Accuracy: 0.41796875\n",
      "Batch: 130, Loss: 2.2760443687438965, Accuracy: 0.3671875\n",
      "Batch: 131, Loss: 2.2020254135131836, Accuracy: 0.384765625\n",
      "Batch: 132, Loss: 2.238795280456543, Accuracy: 0.38671875\n",
      "Batch: 133, Loss: 2.1495962142944336, Accuracy: 0.4248046875\n",
      "Batch: 134, Loss: 2.141716957092285, Accuracy: 0.392578125\n",
      "Batch: 135, Loss: 2.0907697677612305, Accuracy: 0.4111328125\n",
      "Batch: 136, Loss: 2.1124837398529053, Accuracy: 0.3994140625\n",
      "Batch: 137, Loss: 1.8736331462860107, Accuracy: 0.439453125\n",
      "Batch: 138, Loss: 1.8692516088485718, Accuracy: 0.4306640625\n",
      "Batch: 139, Loss: 1.9311368465423584, Accuracy: 0.416015625\n",
      "Batch: 140, Loss: 2.0751538276672363, Accuracy: 0.4033203125\n",
      "Batch: 141, Loss: 2.0747358798980713, Accuracy: 0.3994140625\n",
      "Batch: 142, Loss: 2.083266019821167, Accuracy: 0.392578125\n",
      "Batch: 143, Loss: 2.1861133575439453, Accuracy: 0.392578125\n",
      "Batch: 144, Loss: 2.09498929977417, Accuracy: 0.4052734375\n",
      "Batch: 145, Loss: 1.9988300800323486, Accuracy: 0.4091796875\n",
      "Batch: 146, Loss: 2.2000560760498047, Accuracy: 0.388671875\n",
      "Batch: 147, Loss: 2.055104970932007, Accuracy: 0.4111328125\n",
      "Batch: 148, Loss: 2.126495122909546, Accuracy: 0.3896484375\n",
      "Batch: 149, Loss: 2.16298770904541, Accuracy: 0.376953125\n",
      "Batch: 150, Loss: 2.0796923637390137, Accuracy: 0.390625\n",
      "Batch: 151, Loss: 2.0994043350219727, Accuracy: 0.3984375\n",
      "Epoch 3/90\n",
      "Batch: 1, Loss: 2.1851561069488525, Accuracy: 0.3994140625\n",
      "Batch: 2, Loss: 1.889265775680542, Accuracy: 0.4365234375\n",
      "Batch: 3, Loss: 2.0714449882507324, Accuracy: 0.4052734375\n",
      "Batch: 4, Loss: 2.0714666843414307, Accuracy: 0.412109375\n",
      "Batch: 5, Loss: 1.9872958660125732, Accuracy: 0.43359375\n",
      "Batch: 6, Loss: 1.9410609006881714, Accuracy: 0.4482421875\n",
      "Batch: 7, Loss: 1.949538230895996, Accuracy: 0.431640625\n",
      "Batch: 8, Loss: 1.9301509857177734, Accuracy: 0.435546875\n",
      "Batch: 9, Loss: 1.9377660751342773, Accuracy: 0.4326171875\n",
      "Batch: 10, Loss: 1.9143180847167969, Accuracy: 0.427734375\n",
      "Batch: 11, Loss: 1.8785042762756348, Accuracy: 0.451171875\n",
      "Batch: 12, Loss: 2.0966367721557617, Accuracy: 0.38671875\n",
      "Batch: 13, Loss: 1.9834094047546387, Accuracy: 0.41015625\n",
      "Batch: 14, Loss: 2.002850294113159, Accuracy: 0.416015625\n",
      "Batch: 15, Loss: 2.049910068511963, Accuracy: 0.4267578125\n",
      "Batch: 16, Loss: 1.8914881944656372, Accuracy: 0.439453125\n",
      "Batch: 17, Loss: 1.9582304954528809, Accuracy: 0.4033203125\n",
      "Batch: 18, Loss: 1.983473777770996, Accuracy: 0.41796875\n",
      "Batch: 19, Loss: 2.0847809314727783, Accuracy: 0.3955078125\n",
      "Batch: 20, Loss: 2.0940310955047607, Accuracy: 0.404296875\n",
      "Batch: 21, Loss: 1.933871865272522, Accuracy: 0.4501953125\n",
      "Batch: 22, Loss: 2.0127878189086914, Accuracy: 0.4365234375\n",
      "Batch: 23, Loss: 1.9363377094268799, Accuracy: 0.431640625\n",
      "Batch: 24, Loss: 2.059788465499878, Accuracy: 0.3955078125\n",
      "Batch: 25, Loss: 1.9241549968719482, Accuracy: 0.4189453125\n",
      "Batch: 26, Loss: 1.8302537202835083, Accuracy: 0.4453125\n",
      "Batch: 27, Loss: 1.9455146789550781, Accuracy: 0.4091796875\n",
      "Batch: 28, Loss: 1.8773893117904663, Accuracy: 0.4423828125\n",
      "Batch: 29, Loss: 2.0231175422668457, Accuracy: 0.4111328125\n",
      "Batch: 30, Loss: 2.1221914291381836, Accuracy: 0.3818359375\n",
      "Batch: 31, Loss: 2.096769332885742, Accuracy: 0.4169921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 32, Loss: 1.8904950618743896, Accuracy: 0.44140625\n",
      "Batch: 33, Loss: 2.0300452709198, Accuracy: 0.423828125\n",
      "Batch: 34, Loss: 2.1040940284729004, Accuracy: 0.4208984375\n",
      "Batch: 35, Loss: 2.034346103668213, Accuracy: 0.4189453125\n",
      "Batch: 36, Loss: 2.106020450592041, Accuracy: 0.419921875\n",
      "Batch: 37, Loss: 2.075193405151367, Accuracy: 0.42578125\n",
      "Batch: 38, Loss: 1.9712916612625122, Accuracy: 0.4306640625\n",
      "Batch: 39, Loss: 2.022064208984375, Accuracy: 0.4345703125\n",
      "Batch: 40, Loss: 2.1565542221069336, Accuracy: 0.4287109375\n",
      "Batch: 41, Loss: 2.089852809906006, Accuracy: 0.4365234375\n",
      "Batch: 42, Loss: 1.8232779502868652, Accuracy: 0.4755859375\n",
      "Batch: 43, Loss: 1.8631235361099243, Accuracy: 0.443359375\n",
      "Batch: 44, Loss: 1.8316395282745361, Accuracy: 0.4697265625\n",
      "Batch: 45, Loss: 1.758455514907837, Accuracy: 0.4775390625\n",
      "Batch: 46, Loss: 2.031264066696167, Accuracy: 0.44140625\n",
      "Batch: 47, Loss: 2.117203712463379, Accuracy: 0.4091796875\n",
      "Batch: 48, Loss: 1.9580832719802856, Accuracy: 0.4609375\n",
      "Batch: 49, Loss: 1.9949443340301514, Accuracy: 0.4111328125\n",
      "Batch: 50, Loss: 1.9796125888824463, Accuracy: 0.4345703125\n",
      "Batch: 51, Loss: 2.1126017570495605, Accuracy: 0.412109375\n",
      "Batch: 52, Loss: 2.0668444633483887, Accuracy: 0.4326171875\n",
      "Batch: 53, Loss: 1.7814881801605225, Accuracy: 0.4609375\n",
      "Batch: 54, Loss: 1.9992451667785645, Accuracy: 0.4521484375\n",
      "Batch: 55, Loss: 1.8949658870697021, Accuracy: 0.447265625\n",
      "Batch: 56, Loss: 2.070556163787842, Accuracy: 0.42578125\n",
      "Batch: 57, Loss: 1.9755527973175049, Accuracy: 0.44921875\n",
      "Batch: 58, Loss: 1.9449243545532227, Accuracy: 0.4501953125\n",
      "Batch: 59, Loss: 1.8939852714538574, Accuracy: 0.474609375\n",
      "Batch: 60, Loss: 1.8436939716339111, Accuracy: 0.4716796875\n",
      "Batch: 61, Loss: 1.9178581237792969, Accuracy: 0.4384765625\n",
      "Batch: 62, Loss: 2.001310348510742, Accuracy: 0.44921875\n",
      "Batch: 63, Loss: 1.9589738845825195, Accuracy: 0.4375\n",
      "Batch: 64, Loss: 1.9520366191864014, Accuracy: 0.4560546875\n",
      "Batch: 65, Loss: 1.9986226558685303, Accuracy: 0.423828125\n",
      "Batch: 66, Loss: 1.8598122596740723, Accuracy: 0.458984375\n",
      "Batch: 67, Loss: 1.885623812675476, Accuracy: 0.4765625\n",
      "Batch: 68, Loss: 2.026355266571045, Accuracy: 0.4482421875\n",
      "Batch: 69, Loss: 1.9565892219543457, Accuracy: 0.4541015625\n",
      "Batch: 70, Loss: 2.0642006397247314, Accuracy: 0.42578125\n",
      "Batch: 71, Loss: 1.8816070556640625, Accuracy: 0.46875\n",
      "Batch: 72, Loss: 1.8883354663848877, Accuracy: 0.4658203125\n",
      "Batch: 73, Loss: 2.005106210708618, Accuracy: 0.4423828125\n",
      "Batch: 74, Loss: 1.9037423133850098, Accuracy: 0.4482421875\n",
      "Batch: 75, Loss: 1.797745943069458, Accuracy: 0.47265625\n",
      "Batch: 76, Loss: 1.868216633796692, Accuracy: 0.44140625\n",
      "Batch: 77, Loss: 1.9235360622406006, Accuracy: 0.443359375\n",
      "Batch: 78, Loss: 1.9892938137054443, Accuracy: 0.453125\n",
      "Batch: 79, Loss: 1.8364461660385132, Accuracy: 0.5048828125\n",
      "Batch: 80, Loss: 1.7466914653778076, Accuracy: 0.4755859375\n",
      "Batch: 81, Loss: 1.8233625888824463, Accuracy: 0.4599609375\n",
      "Batch: 82, Loss: 1.8440836668014526, Accuracy: 0.4482421875\n",
      "Batch: 83, Loss: 1.7612526416778564, Accuracy: 0.484375\n",
      "Batch: 84, Loss: 1.8662559986114502, Accuracy: 0.4697265625\n",
      "Batch: 85, Loss: 1.7563806772232056, Accuracy: 0.5087890625\n",
      "Batch: 86, Loss: 1.9939098358154297, Accuracy: 0.4521484375\n",
      "Batch: 87, Loss: 1.8851195573806763, Accuracy: 0.4697265625\n",
      "Batch: 88, Loss: 1.9580841064453125, Accuracy: 0.46875\n",
      "Batch: 89, Loss: 1.939611554145813, Accuracy: 0.458984375\n",
      "Batch: 90, Loss: 1.8535330295562744, Accuracy: 0.453125\n",
      "Batch: 91, Loss: 1.8521950244903564, Accuracy: 0.4638671875\n",
      "Batch: 92, Loss: 1.9142725467681885, Accuracy: 0.458984375\n",
      "Batch: 93, Loss: 1.8060234785079956, Accuracy: 0.4892578125\n",
      "Batch: 94, Loss: 1.8262531757354736, Accuracy: 0.4658203125\n",
      "Batch: 95, Loss: 1.7955931425094604, Accuracy: 0.458984375\n",
      "Batch: 96, Loss: 1.9013724327087402, Accuracy: 0.4658203125\n",
      "Batch: 97, Loss: 1.8145618438720703, Accuracy: 0.48046875\n",
      "Batch: 98, Loss: 1.7487125396728516, Accuracy: 0.5185546875\n",
      "Batch: 99, Loss: 1.6972028017044067, Accuracy: 0.4931640625\n",
      "Batch: 100, Loss: 1.7491246461868286, Accuracy: 0.5029296875\n",
      "Batch: 101, Loss: 1.8245190382003784, Accuracy: 0.4775390625\n",
      "Batch: 102, Loss: 1.7199795246124268, Accuracy: 0.50390625\n",
      "Batch: 103, Loss: 1.9434006214141846, Accuracy: 0.474609375\n",
      "Batch: 104, Loss: 1.6933386325836182, Accuracy: 0.51171875\n",
      "Batch: 105, Loss: 1.8143482208251953, Accuracy: 0.4755859375\n",
      "Batch: 106, Loss: 1.8528512716293335, Accuracy: 0.474609375\n",
      "Batch: 107, Loss: 1.9794962406158447, Accuracy: 0.4462890625\n",
      "Batch: 108, Loss: 1.9551618099212646, Accuracy: 0.4619140625\n",
      "Batch: 109, Loss: 1.9543906450271606, Accuracy: 0.4453125\n",
      "Batch: 110, Loss: 1.6391021013259888, Accuracy: 0.5146484375\n",
      "Batch: 111, Loss: 1.7853738069534302, Accuracy: 0.4794921875\n",
      "Batch: 112, Loss: 1.8394920825958252, Accuracy: 0.48046875\n",
      "Batch: 113, Loss: 1.8800106048583984, Accuracy: 0.482421875\n",
      "Batch: 114, Loss: 1.8783953189849854, Accuracy: 0.4638671875\n",
      "Batch: 115, Loss: 1.9788110256195068, Accuracy: 0.458984375\n",
      "Batch: 116, Loss: 1.982259750366211, Accuracy: 0.447265625\n",
      "Batch: 117, Loss: 1.9062399864196777, Accuracy: 0.4833984375\n",
      "Batch: 118, Loss: 1.7551932334899902, Accuracy: 0.5205078125\n",
      "Batch: 119, Loss: 1.8708844184875488, Accuracy: 0.5048828125\n",
      "Batch: 120, Loss: 1.887220859527588, Accuracy: 0.451171875\n",
      "Batch: 121, Loss: 1.9485998153686523, Accuracy: 0.4482421875\n",
      "Batch: 122, Loss: 1.8983134031295776, Accuracy: 0.458984375\n",
      "Batch: 123, Loss: 1.8228743076324463, Accuracy: 0.486328125\n",
      "Batch: 124, Loss: 1.8567638397216797, Accuracy: 0.484375\n",
      "Batch: 125, Loss: 1.8655486106872559, Accuracy: 0.4619140625\n",
      "Batch: 126, Loss: 1.8427271842956543, Accuracy: 0.44921875\n",
      "Batch: 127, Loss: 1.7376433610916138, Accuracy: 0.498046875\n",
      "Batch: 128, Loss: 2.020918846130371, Accuracy: 0.4267578125\n",
      "Batch: 129, Loss: 1.858792781829834, Accuracy: 0.47265625\n",
      "Batch: 130, Loss: 2.036076068878174, Accuracy: 0.427734375\n",
      "Batch: 131, Loss: 1.872778058052063, Accuracy: 0.4814453125\n",
      "Batch: 132, Loss: 1.9630672931671143, Accuracy: 0.46484375\n",
      "Batch: 133, Loss: 1.8617479801177979, Accuracy: 0.4873046875\n",
      "Batch: 134, Loss: 1.8601081371307373, Accuracy: 0.486328125\n",
      "Batch: 135, Loss: 1.7777862548828125, Accuracy: 0.4931640625\n",
      "Batch: 136, Loss: 1.8099186420440674, Accuracy: 0.494140625\n",
      "Batch: 137, Loss: 1.6578714847564697, Accuracy: 0.4970703125\n",
      "Batch: 138, Loss: 1.5759143829345703, Accuracy: 0.5283203125\n",
      "Batch: 139, Loss: 1.6249573230743408, Accuracy: 0.5087890625\n",
      "Batch: 140, Loss: 1.7746407985687256, Accuracy: 0.48828125\n",
      "Batch: 141, Loss: 1.7829945087432861, Accuracy: 0.4951171875\n",
      "Batch: 142, Loss: 1.820906639099121, Accuracy: 0.4775390625\n",
      "Batch: 143, Loss: 1.9042328596115112, Accuracy: 0.4609375\n",
      "Batch: 144, Loss: 1.8118786811828613, Accuracy: 0.484375\n",
      "Batch: 145, Loss: 1.699649691581726, Accuracy: 0.494140625\n",
      "Batch: 146, Loss: 1.9177582263946533, Accuracy: 0.4541015625\n",
      "Batch: 147, Loss: 1.7797131538391113, Accuracy: 0.4794921875\n",
      "Batch: 148, Loss: 1.9166967868804932, Accuracy: 0.427734375\n",
      "Batch: 149, Loss: 1.8806461095809937, Accuracy: 0.4482421875\n",
      "Batch: 150, Loss: 1.7613532543182373, Accuracy: 0.49609375\n",
      "Batch: 151, Loss: 1.7464691400527954, Accuracy: 0.490234375\n",
      "Epoch 4/90\n",
      "Batch: 1, Loss: 2.0195093154907227, Accuracy: 0.41796875\n",
      "Batch: 2, Loss: 1.6630113124847412, Accuracy: 0.5\n",
      "Batch: 3, Loss: 1.707519292831421, Accuracy: 0.50390625\n",
      "Batch: 4, Loss: 1.6775312423706055, Accuracy: 0.52734375\n",
      "Batch: 5, Loss: 1.677677869796753, Accuracy: 0.529296875\n",
      "Batch: 6, Loss: 1.7294974327087402, Accuracy: 0.4814453125\n",
      "Batch: 7, Loss: 1.6956332921981812, Accuracy: 0.494140625\n",
      "Batch: 8, Loss: 1.6542447805404663, Accuracy: 0.5078125\n",
      "Batch: 9, Loss: 1.5996501445770264, Accuracy: 0.5390625\n",
      "Batch: 10, Loss: 1.6719743013381958, Accuracy: 0.5146484375\n",
      "Batch: 11, Loss: 1.7253526449203491, Accuracy: 0.4775390625\n",
      "Batch: 12, Loss: 1.8763047456741333, Accuracy: 0.45703125\n",
      "Batch: 13, Loss: 1.6229134798049927, Accuracy: 0.533203125\n",
      "Batch: 14, Loss: 1.7674726247787476, Accuracy: 0.4921875\n",
      "Batch: 15, Loss: 1.7280685901641846, Accuracy: 0.517578125\n",
      "Batch: 16, Loss: 1.6612135171890259, Accuracy: 0.5166015625\n",
      "Batch: 17, Loss: 1.7327110767364502, Accuracy: 0.4716796875\n",
      "Batch: 18, Loss: 1.7834433317184448, Accuracy: 0.4697265625\n",
      "Batch: 19, Loss: 1.7727630138397217, Accuracy: 0.486328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 20, Loss: 1.7794570922851562, Accuracy: 0.5107421875\n",
      "Batch: 21, Loss: 1.6258368492126465, Accuracy: 0.52734375\n",
      "Batch: 22, Loss: 1.8232612609863281, Accuracy: 0.4697265625\n",
      "Batch: 23, Loss: 1.6577234268188477, Accuracy: 0.5068359375\n",
      "Batch: 24, Loss: 1.7494055032730103, Accuracy: 0.484375\n",
      "Batch: 25, Loss: 1.6384801864624023, Accuracy: 0.5068359375\n",
      "Batch: 26, Loss: 1.5785644054412842, Accuracy: 0.5458984375\n",
      "Batch: 27, Loss: 1.6877998113632202, Accuracy: 0.4951171875\n",
      "Batch: 28, Loss: 1.7093384265899658, Accuracy: 0.490234375\n",
      "Batch: 29, Loss: 1.7428278923034668, Accuracy: 0.48828125\n",
      "Batch: 30, Loss: 1.7487263679504395, Accuracy: 0.509765625\n",
      "Batch: 31, Loss: 1.735903263092041, Accuracy: 0.5087890625\n",
      "Batch: 32, Loss: 1.622748613357544, Accuracy: 0.5234375\n",
      "Batch: 33, Loss: 1.807680606842041, Accuracy: 0.48828125\n",
      "Batch: 34, Loss: 1.8917003870010376, Accuracy: 0.4619140625\n",
      "Batch: 35, Loss: 1.784576177597046, Accuracy: 0.4931640625\n",
      "Batch: 36, Loss: 1.7859129905700684, Accuracy: 0.5087890625\n",
      "Batch: 37, Loss: 1.788962960243225, Accuracy: 0.4833984375\n",
      "Batch: 38, Loss: 1.7265346050262451, Accuracy: 0.4814453125\n",
      "Batch: 39, Loss: 1.801455020904541, Accuracy: 0.501953125\n",
      "Batch: 40, Loss: 1.8750158548355103, Accuracy: 0.5078125\n",
      "Batch: 41, Loss: 1.8027265071868896, Accuracy: 0.51171875\n",
      "Batch: 42, Loss: 1.5258502960205078, Accuracy: 0.556640625\n",
      "Batch: 43, Loss: 1.6656334400177002, Accuracy: 0.4951171875\n",
      "Batch: 44, Loss: 1.6500957012176514, Accuracy: 0.5048828125\n",
      "Batch: 45, Loss: 1.5342531204223633, Accuracy: 0.5322265625\n",
      "Batch: 46, Loss: 1.7932578325271606, Accuracy: 0.5234375\n",
      "Batch: 47, Loss: 1.792067527770996, Accuracy: 0.501953125\n",
      "Batch: 48, Loss: 1.6975393295288086, Accuracy: 0.5234375\n",
      "Batch: 49, Loss: 1.8046774864196777, Accuracy: 0.4775390625\n",
      "Batch: 50, Loss: 1.7443679571151733, Accuracy: 0.48828125\n",
      "Batch: 51, Loss: 1.8638508319854736, Accuracy: 0.4560546875\n",
      "Batch: 52, Loss: 1.8317172527313232, Accuracy: 0.478515625\n",
      "Batch: 53, Loss: 1.5589876174926758, Accuracy: 0.529296875\n",
      "Batch: 54, Loss: 1.708624243736267, Accuracy: 0.5185546875\n",
      "Batch: 55, Loss: 1.6745939254760742, Accuracy: 0.4990234375\n",
      "Batch: 56, Loss: 1.8240958452224731, Accuracy: 0.4814453125\n",
      "Batch: 57, Loss: 1.7370810508728027, Accuracy: 0.5185546875\n",
      "Batch: 58, Loss: 1.7705135345458984, Accuracy: 0.5029296875\n",
      "Batch: 59, Loss: 1.5673511028289795, Accuracy: 0.5498046875\n",
      "Batch: 60, Loss: 1.5952832698822021, Accuracy: 0.5322265625\n",
      "Batch: 61, Loss: 1.6993951797485352, Accuracy: 0.5\n",
      "Batch: 62, Loss: 1.7474102973937988, Accuracy: 0.5205078125\n",
      "Batch: 63, Loss: 1.7056772708892822, Accuracy: 0.513671875\n",
      "Batch: 64, Loss: 1.6919814348220825, Accuracy: 0.5166015625\n",
      "Batch: 65, Loss: 1.7301759719848633, Accuracy: 0.498046875\n",
      "Batch: 66, Loss: 1.6031088829040527, Accuracy: 0.533203125\n",
      "Batch: 67, Loss: 1.7024037837982178, Accuracy: 0.5107421875\n",
      "Batch: 68, Loss: 1.8055214881896973, Accuracy: 0.5029296875\n",
      "Batch: 69, Loss: 1.7193474769592285, Accuracy: 0.509765625\n",
      "Batch: 70, Loss: 1.7935594320297241, Accuracy: 0.5068359375\n",
      "Batch: 71, Loss: 1.7066919803619385, Accuracy: 0.50390625\n",
      "Batch: 72, Loss: 1.647727608680725, Accuracy: 0.505859375\n",
      "Batch: 73, Loss: 1.7303993701934814, Accuracy: 0.5146484375\n",
      "Batch: 74, Loss: 1.6473400592803955, Accuracy: 0.5087890625\n",
      "Batch: 75, Loss: 1.580381155014038, Accuracy: 0.51953125\n",
      "Batch: 76, Loss: 1.7296788692474365, Accuracy: 0.4755859375\n",
      "Batch: 77, Loss: 1.7207142114639282, Accuracy: 0.498046875\n",
      "Batch: 78, Loss: 1.719463586807251, Accuracy: 0.5263671875\n",
      "Batch: 79, Loss: 1.529767632484436, Accuracy: 0.58203125\n",
      "Batch: 80, Loss: 1.5338401794433594, Accuracy: 0.5341796875\n",
      "Batch: 81, Loss: 1.686026692390442, Accuracy: 0.501953125\n",
      "Batch: 82, Loss: 1.684667706489563, Accuracy: 0.4697265625\n",
      "Batch: 83, Loss: 1.5471885204315186, Accuracy: 0.5537109375\n",
      "Batch: 84, Loss: 1.6133302450180054, Accuracy: 0.546875\n",
      "Batch: 85, Loss: 1.4950807094573975, Accuracy: 0.578125\n",
      "Batch: 86, Loss: 1.8295574188232422, Accuracy: 0.4794921875\n",
      "Batch: 87, Loss: 1.6145986318588257, Accuracy: 0.541015625\n",
      "Batch: 88, Loss: 1.7604366540908813, Accuracy: 0.5029296875\n",
      "Batch: 89, Loss: 1.7507941722869873, Accuracy: 0.4970703125\n",
      "Batch: 90, Loss: 1.6235554218292236, Accuracy: 0.5361328125\n",
      "Batch: 91, Loss: 1.6096733808517456, Accuracy: 0.533203125\n",
      "Batch: 92, Loss: 1.7296804189682007, Accuracy: 0.50390625\n",
      "Batch: 93, Loss: 1.6163640022277832, Accuracy: 0.53515625\n",
      "Batch: 94, Loss: 1.6018242835998535, Accuracy: 0.51953125\n",
      "Batch: 95, Loss: 1.6541786193847656, Accuracy: 0.49609375\n",
      "Batch: 96, Loss: 1.6477618217468262, Accuracy: 0.5458984375\n",
      "Batch: 97, Loss: 1.5978556871414185, Accuracy: 0.5361328125\n",
      "Batch: 98, Loss: 1.5288050174713135, Accuracy: 0.56640625\n",
      "Batch: 99, Loss: 1.5066800117492676, Accuracy: 0.5419921875\n",
      "Batch: 100, Loss: 1.5986542701721191, Accuracy: 0.5126953125\n",
      "Batch: 101, Loss: 1.6290290355682373, Accuracy: 0.5244140625\n",
      "Batch: 102, Loss: 1.5042757987976074, Accuracy: 0.55078125\n",
      "Batch: 103, Loss: 1.692840337753296, Accuracy: 0.533203125\n",
      "Batch: 104, Loss: 1.4992034435272217, Accuracy: 0.552734375\n",
      "Batch: 105, Loss: 1.6283221244812012, Accuracy: 0.525390625\n",
      "Batch: 106, Loss: 1.6733627319335938, Accuracy: 0.5048828125\n",
      "Batch: 107, Loss: 1.79902982711792, Accuracy: 0.4833984375\n",
      "Batch: 108, Loss: 1.7666096687316895, Accuracy: 0.50390625\n",
      "Batch: 109, Loss: 1.791140079498291, Accuracy: 0.49609375\n",
      "Batch: 110, Loss: 1.4372036457061768, Accuracy: 0.568359375\n",
      "Batch: 111, Loss: 1.6246881484985352, Accuracy: 0.515625\n",
      "Batch: 112, Loss: 1.6257989406585693, Accuracy: 0.544921875\n",
      "Batch: 113, Loss: 1.6515529155731201, Accuracy: 0.546875\n",
      "Batch: 114, Loss: 1.723447561264038, Accuracy: 0.49609375\n",
      "Batch: 115, Loss: 1.7949658632278442, Accuracy: 0.50390625\n",
      "Batch: 116, Loss: 1.774469256401062, Accuracy: 0.4736328125\n",
      "Batch: 117, Loss: 1.71198308467865, Accuracy: 0.5185546875\n",
      "Batch: 118, Loss: 1.5276299715042114, Accuracy: 0.5703125\n",
      "Batch: 119, Loss: 1.5961179733276367, Accuracy: 0.560546875\n",
      "Batch: 120, Loss: 1.7239079475402832, Accuracy: 0.49609375\n",
      "Batch: 121, Loss: 1.7999111413955688, Accuracy: 0.46875\n",
      "Batch: 122, Loss: 1.5808125734329224, Accuracy: 0.5478515625\n",
      "Batch: 123, Loss: 1.5689791440963745, Accuracy: 0.544921875\n",
      "Batch: 124, Loss: 1.639923095703125, Accuracy: 0.5380859375\n",
      "Batch: 125, Loss: 1.6674778461456299, Accuracy: 0.5078125\n",
      "Batch: 126, Loss: 1.6656699180603027, Accuracy: 0.501953125\n",
      "Batch: 127, Loss: 1.4896767139434814, Accuracy: 0.5673828125\n",
      "Batch: 128, Loss: 1.7430270910263062, Accuracy: 0.515625\n",
      "Batch: 129, Loss: 1.647631049156189, Accuracy: 0.5166015625\n",
      "Batch: 130, Loss: 1.8495045900344849, Accuracy: 0.4775390625\n",
      "Batch: 131, Loss: 1.6740009784698486, Accuracy: 0.5205078125\n",
      "Batch: 132, Loss: 1.7544727325439453, Accuracy: 0.5029296875\n",
      "Batch: 133, Loss: 1.6363441944122314, Accuracy: 0.5361328125\n",
      "Batch: 134, Loss: 1.6733759641647339, Accuracy: 0.51953125\n",
      "Batch: 135, Loss: 1.580089807510376, Accuracy: 0.546875\n",
      "Batch: 136, Loss: 1.6090362071990967, Accuracy: 0.525390625\n",
      "Batch: 137, Loss: 1.5074827671051025, Accuracy: 0.533203125\n",
      "Batch: 138, Loss: 1.4167368412017822, Accuracy: 0.5712890625\n",
      "Batch: 139, Loss: 1.4514362812042236, Accuracy: 0.560546875\n",
      "Batch: 140, Loss: 1.593252420425415, Accuracy: 0.5244140625\n",
      "Batch: 141, Loss: 1.5993149280548096, Accuracy: 0.5380859375\n",
      "Batch: 142, Loss: 1.6431944370269775, Accuracy: 0.509765625\n",
      "Batch: 143, Loss: 1.6488561630249023, Accuracy: 0.533203125\n",
      "Batch: 144, Loss: 1.6119686365127563, Accuracy: 0.5322265625\n",
      "Batch: 145, Loss: 1.5109429359436035, Accuracy: 0.5400390625\n",
      "Batch: 146, Loss: 1.719170093536377, Accuracy: 0.49609375\n",
      "Batch: 147, Loss: 1.5800319910049438, Accuracy: 0.53515625\n",
      "Batch: 148, Loss: 1.7724535465240479, Accuracy: 0.4736328125\n",
      "Batch: 149, Loss: 1.6822837591171265, Accuracy: 0.5048828125\n",
      "Batch: 150, Loss: 1.5677342414855957, Accuracy: 0.5322265625\n",
      "Batch: 151, Loss: 1.5437084436416626, Accuracy: 0.5400390625\n",
      "Epoch 5/90\n",
      "Batch: 1, Loss: 1.8799653053283691, Accuracy: 0.4521484375\n",
      "Batch: 2, Loss: 1.5644556283950806, Accuracy: 0.4892578125\n",
      "Batch: 3, Loss: 1.5599000453948975, Accuracy: 0.5224609375\n",
      "Batch: 4, Loss: 1.4270846843719482, Accuracy: 0.5908203125\n",
      "Batch: 5, Loss: 1.4952127933502197, Accuracy: 0.5576171875\n",
      "Batch: 6, Loss: 1.6244159936904907, Accuracy: 0.4970703125\n",
      "Batch: 7, Loss: 1.5443389415740967, Accuracy: 0.52734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 8, Loss: 1.5172083377838135, Accuracy: 0.5244140625\n",
      "Batch: 9, Loss: 1.4046924114227295, Accuracy: 0.57421875\n",
      "Batch: 10, Loss: 1.484846591949463, Accuracy: 0.53515625\n",
      "Batch: 11, Loss: 1.6186399459838867, Accuracy: 0.4833984375\n",
      "Batch: 12, Loss: 1.708073616027832, Accuracy: 0.478515625\n",
      "Batch: 13, Loss: 1.402250051498413, Accuracy: 0.5810546875\n",
      "Batch: 14, Loss: 1.6224079132080078, Accuracy: 0.5107421875\n",
      "Batch: 15, Loss: 1.5410549640655518, Accuracy: 0.5546875\n",
      "Batch: 16, Loss: 1.508266568183899, Accuracy: 0.5498046875\n",
      "Batch: 17, Loss: 1.5968713760375977, Accuracy: 0.5068359375\n",
      "Batch: 18, Loss: 1.6377384662628174, Accuracy: 0.4892578125\n",
      "Batch: 19, Loss: 1.6234259605407715, Accuracy: 0.5166015625\n",
      "Batch: 20, Loss: 1.537273645401001, Accuracy: 0.560546875\n",
      "Batch: 21, Loss: 1.4534077644348145, Accuracy: 0.56640625\n",
      "Batch: 22, Loss: 1.6622378826141357, Accuracy: 0.5234375\n",
      "Batch: 23, Loss: 1.5316870212554932, Accuracy: 0.517578125\n",
      "Batch: 24, Loss: 1.5471831560134888, Accuracy: 0.5283203125\n",
      "Batch: 25, Loss: 1.5016980171203613, Accuracy: 0.5322265625\n",
      "Batch: 26, Loss: 1.4146672487258911, Accuracy: 0.5732421875\n",
      "Batch: 27, Loss: 1.5537842512130737, Accuracy: 0.51953125\n",
      "Batch: 28, Loss: 1.5741816759109497, Accuracy: 0.505859375\n",
      "Batch: 29, Loss: 1.5957953929901123, Accuracy: 0.509765625\n",
      "Batch: 30, Loss: 1.5434699058532715, Accuracy: 0.5576171875\n",
      "Batch: 31, Loss: 1.53121018409729, Accuracy: 0.5595703125\n",
      "Batch: 32, Loss: 1.479984164237976, Accuracy: 0.54296875\n",
      "Batch: 33, Loss: 1.6756099462509155, Accuracy: 0.4912109375\n",
      "Batch: 34, Loss: 1.755197525024414, Accuracy: 0.4755859375\n",
      "Batch: 35, Loss: 1.6076202392578125, Accuracy: 0.51953125\n",
      "Batch: 36, Loss: 1.590262532234192, Accuracy: 0.5224609375\n",
      "Batch: 37, Loss: 1.6452231407165527, Accuracy: 0.4970703125\n",
      "Batch: 38, Loss: 1.5751805305480957, Accuracy: 0.5146484375\n",
      "Batch: 39, Loss: 1.5992012023925781, Accuracy: 0.5078125\n",
      "Batch: 40, Loss: 1.602118730545044, Accuracy: 0.552734375\n",
      "Batch: 41, Loss: 1.632927656173706, Accuracy: 0.537109375\n",
      "Batch: 42, Loss: 1.3480955362319946, Accuracy: 0.595703125\n",
      "Batch: 43, Loss: 1.4942517280578613, Accuracy: 0.5302734375\n",
      "Batch: 44, Loss: 1.4971474409103394, Accuracy: 0.53515625\n",
      "Batch: 45, Loss: 1.3486428260803223, Accuracy: 0.578125\n",
      "Batch: 46, Loss: 1.5729608535766602, Accuracy: 0.55078125\n",
      "Batch: 47, Loss: 1.5739678144454956, Accuracy: 0.541015625\n",
      "Batch: 48, Loss: 1.5028218030929565, Accuracy: 0.5615234375\n",
      "Batch: 49, Loss: 1.6527475118637085, Accuracy: 0.5009765625\n",
      "Batch: 50, Loss: 1.5866608619689941, Accuracy: 0.5205078125\n",
      "Batch: 51, Loss: 1.7051771879196167, Accuracy: 0.4853515625\n",
      "Batch: 52, Loss: 1.6467809677124023, Accuracy: 0.5048828125\n",
      "Batch: 53, Loss: 1.390152931213379, Accuracy: 0.5625\n",
      "Batch: 54, Loss: 1.5260605812072754, Accuracy: 0.5556640625\n",
      "Batch: 55, Loss: 1.5310730934143066, Accuracy: 0.529296875\n",
      "Batch: 56, Loss: 1.647526741027832, Accuracy: 0.5\n",
      "Batch: 57, Loss: 1.524564504623413, Accuracy: 0.5498046875\n",
      "Batch: 58, Loss: 1.6123507022857666, Accuracy: 0.521484375\n",
      "Batch: 59, Loss: 1.39473557472229, Accuracy: 0.583984375\n",
      "Batch: 60, Loss: 1.4315704107284546, Accuracy: 0.5673828125\n",
      "Batch: 61, Loss: 1.5671266317367554, Accuracy: 0.53125\n",
      "Batch: 62, Loss: 1.5421711206436157, Accuracy: 0.5458984375\n",
      "Batch: 63, Loss: 1.5363436937332153, Accuracy: 0.5361328125\n",
      "Batch: 64, Loss: 1.4953365325927734, Accuracy: 0.5576171875\n",
      "Batch: 65, Loss: 1.520969033241272, Accuracy: 0.53125\n",
      "Batch: 66, Loss: 1.4113531112670898, Accuracy: 0.564453125\n",
      "Batch: 67, Loss: 1.5638339519500732, Accuracy: 0.5322265625\n",
      "Batch: 68, Loss: 1.6189429759979248, Accuracy: 0.541015625\n",
      "Batch: 69, Loss: 1.5368516445159912, Accuracy: 0.5458984375\n",
      "Batch: 70, Loss: 1.560594916343689, Accuracy: 0.5498046875\n",
      "Batch: 71, Loss: 1.5416574478149414, Accuracy: 0.51171875\n",
      "Batch: 72, Loss: 1.4617624282836914, Accuracy: 0.5615234375\n",
      "Batch: 73, Loss: 1.556565761566162, Accuracy: 0.548828125\n",
      "Batch: 74, Loss: 1.4767649173736572, Accuracy: 0.5439453125\n",
      "Batch: 75, Loss: 1.4177229404449463, Accuracy: 0.5732421875\n",
      "Batch: 76, Loss: 1.5809178352355957, Accuracy: 0.490234375\n",
      "Batch: 77, Loss: 1.566829800605774, Accuracy: 0.515625\n",
      "Batch: 78, Loss: 1.5105952024459839, Accuracy: 0.5595703125\n",
      "Batch: 79, Loss: 1.3598381280899048, Accuracy: 0.611328125\n",
      "Batch: 80, Loss: 1.4115257263183594, Accuracy: 0.5625\n",
      "Batch: 81, Loss: 1.550166368484497, Accuracy: 0.52734375\n",
      "Batch: 82, Loss: 1.5229318141937256, Accuracy: 0.521484375\n",
      "Batch: 83, Loss: 1.350392460823059, Accuracy: 0.5849609375\n",
      "Batch: 84, Loss: 1.4395227432250977, Accuracy: 0.578125\n",
      "Batch: 85, Loss: 1.3470791578292847, Accuracy: 0.5927734375\n",
      "Batch: 86, Loss: 1.6789567470550537, Accuracy: 0.5009765625\n",
      "Batch: 87, Loss: 1.4588881731033325, Accuracy: 0.5791015625\n",
      "Batch: 88, Loss: 1.5820196866989136, Accuracy: 0.529296875\n",
      "Batch: 89, Loss: 1.6057534217834473, Accuracy: 0.51953125\n",
      "Batch: 90, Loss: 1.4326610565185547, Accuracy: 0.5634765625\n",
      "Batch: 91, Loss: 1.4457037448883057, Accuracy: 0.5537109375\n",
      "Batch: 92, Loss: 1.524966835975647, Accuracy: 0.525390625\n",
      "Batch: 93, Loss: 1.39793062210083, Accuracy: 0.5703125\n",
      "Batch: 94, Loss: 1.4414031505584717, Accuracy: 0.54296875\n",
      "Batch: 95, Loss: 1.4998693466186523, Accuracy: 0.529296875\n",
      "Batch: 96, Loss: 1.496288776397705, Accuracy: 0.5703125\n",
      "Batch: 97, Loss: 1.3767175674438477, Accuracy: 0.5810546875\n",
      "Batch: 98, Loss: 1.3440662622451782, Accuracy: 0.5947265625\n",
      "Batch: 99, Loss: 1.3607416152954102, Accuracy: 0.58203125\n",
      "Batch: 100, Loss: 1.4388601779937744, Accuracy: 0.548828125\n",
      "Batch: 101, Loss: 1.5060245990753174, Accuracy: 0.541015625\n",
      "Batch: 102, Loss: 1.3844393491744995, Accuracy: 0.5703125\n",
      "Batch: 103, Loss: 1.5159181356430054, Accuracy: 0.556640625\n",
      "Batch: 104, Loss: 1.3845239877700806, Accuracy: 0.5615234375\n",
      "Batch: 105, Loss: 1.50616455078125, Accuracy: 0.5322265625\n",
      "Batch: 106, Loss: 1.5364809036254883, Accuracy: 0.53125\n",
      "Batch: 107, Loss: 1.6505199670791626, Accuracy: 0.5244140625\n",
      "Batch: 108, Loss: 1.5877916812896729, Accuracy: 0.53125\n",
      "Batch: 109, Loss: 1.6640557050704956, Accuracy: 0.4892578125\n",
      "Batch: 110, Loss: 1.3065000772476196, Accuracy: 0.5908203125\n",
      "Batch: 111, Loss: 1.512129783630371, Accuracy: 0.5263671875\n",
      "Batch: 112, Loss: 1.4611179828643799, Accuracy: 0.5615234375\n",
      "Batch: 113, Loss: 1.4794819355010986, Accuracy: 0.576171875\n",
      "Batch: 114, Loss: 1.6235884428024292, Accuracy: 0.5087890625\n",
      "Batch: 115, Loss: 1.6609504222869873, Accuracy: 0.529296875\n",
      "Batch: 116, Loss: 1.6029798984527588, Accuracy: 0.5078125\n",
      "Batch: 117, Loss: 1.5851109027862549, Accuracy: 0.5478515625\n",
      "Batch: 118, Loss: 1.3452231884002686, Accuracy: 0.5966796875\n",
      "Batch: 119, Loss: 1.3946661949157715, Accuracy: 0.591796875\n",
      "Batch: 120, Loss: 1.5909045934677124, Accuracy: 0.515625\n",
      "Batch: 121, Loss: 1.658657431602478, Accuracy: 0.509765625\n",
      "Batch: 122, Loss: 1.4277151823043823, Accuracy: 0.57421875\n",
      "Batch: 123, Loss: 1.41473388671875, Accuracy: 0.5830078125\n",
      "Batch: 124, Loss: 1.4966347217559814, Accuracy: 0.5615234375\n",
      "Batch: 125, Loss: 1.4903385639190674, Accuracy: 0.5390625\n",
      "Batch: 126, Loss: 1.5324054956436157, Accuracy: 0.509765625\n",
      "Batch: 127, Loss: 1.3734605312347412, Accuracy: 0.59765625\n",
      "Batch: 128, Loss: 1.615515947341919, Accuracy: 0.537109375\n",
      "Batch: 129, Loss: 1.4919307231903076, Accuracy: 0.546875\n",
      "Batch: 130, Loss: 1.7044718265533447, Accuracy: 0.48828125\n",
      "Batch: 131, Loss: 1.5562703609466553, Accuracy: 0.521484375\n",
      "Batch: 132, Loss: 1.5998181104660034, Accuracy: 0.51953125\n",
      "Batch: 133, Loss: 1.4711028337478638, Accuracy: 0.556640625\n",
      "Batch: 134, Loss: 1.5180953741073608, Accuracy: 0.5322265625\n",
      "Batch: 135, Loss: 1.4257357120513916, Accuracy: 0.5751953125\n",
      "Batch: 136, Loss: 1.463512897491455, Accuracy: 0.544921875\n",
      "Batch: 137, Loss: 1.3834031820297241, Accuracy: 0.548828125\n",
      "Batch: 138, Loss: 1.2721412181854248, Accuracy: 0.6015625\n",
      "Batch: 139, Loss: 1.3317246437072754, Accuracy: 0.5625\n",
      "Batch: 140, Loss: 1.4801642894744873, Accuracy: 0.53515625\n",
      "Batch: 141, Loss: 1.4617691040039062, Accuracy: 0.5556640625\n",
      "Batch: 142, Loss: 1.4992156028747559, Accuracy: 0.541015625\n",
      "Batch: 143, Loss: 1.5436747074127197, Accuracy: 0.533203125\n",
      "Batch: 144, Loss: 1.4772623777389526, Accuracy: 0.552734375\n",
      "Batch: 145, Loss: 1.3726568222045898, Accuracy: 0.568359375\n",
      "Batch: 146, Loss: 1.5565400123596191, Accuracy: 0.5107421875\n",
      "Batch: 147, Loss: 1.4964957237243652, Accuracy: 0.5439453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 148, Loss: 1.6757471561431885, Accuracy: 0.4873046875\n",
      "Batch: 149, Loss: 1.5392649173736572, Accuracy: 0.5107421875\n",
      "Batch: 150, Loss: 1.4349420070648193, Accuracy: 0.5478515625\n",
      "Batch: 151, Loss: 1.4231963157653809, Accuracy: 0.5712890625\n",
      "Epoch 6/90\n",
      "Batch: 1, Loss: 1.7653038501739502, Accuracy: 0.47265625\n",
      "Batch: 2, Loss: 1.4756393432617188, Accuracy: 0.51953125\n",
      "Batch: 3, Loss: 1.4352068901062012, Accuracy: 0.55078125\n",
      "Batch: 4, Loss: 1.3013134002685547, Accuracy: 0.6240234375\n",
      "Batch: 5, Loss: 1.3730335235595703, Accuracy: 0.587890625\n",
      "Batch: 6, Loss: 1.5203344821929932, Accuracy: 0.5146484375\n",
      "Batch: 7, Loss: 1.4130150079727173, Accuracy: 0.5498046875\n",
      "Batch: 8, Loss: 1.3846821784973145, Accuracy: 0.5537109375\n",
      "Batch: 9, Loss: 1.3161909580230713, Accuracy: 0.5947265625\n",
      "Batch: 10, Loss: 1.366972804069519, Accuracy: 0.560546875\n",
      "Batch: 11, Loss: 1.5351604223251343, Accuracy: 0.5048828125\n",
      "Batch: 12, Loss: 1.6101572513580322, Accuracy: 0.501953125\n",
      "Batch: 13, Loss: 1.2738730907440186, Accuracy: 0.6123046875\n",
      "Batch: 14, Loss: 1.5338906049728394, Accuracy: 0.533203125\n",
      "Batch: 15, Loss: 1.4162006378173828, Accuracy: 0.56640625\n",
      "Batch: 16, Loss: 1.398419976234436, Accuracy: 0.572265625\n",
      "Batch: 17, Loss: 1.4957118034362793, Accuracy: 0.5205078125\n",
      "Batch: 18, Loss: 1.5294970273971558, Accuracy: 0.509765625\n",
      "Batch: 19, Loss: 1.5488663911819458, Accuracy: 0.5390625\n",
      "Batch: 20, Loss: 1.4478235244750977, Accuracy: 0.57421875\n",
      "Batch: 21, Loss: 1.3699123859405518, Accuracy: 0.568359375\n",
      "Batch: 22, Loss: 1.595430612564087, Accuracy: 0.515625\n",
      "Batch: 23, Loss: 1.4213043451309204, Accuracy: 0.5439453125\n",
      "Batch: 24, Loss: 1.4732568264007568, Accuracy: 0.5302734375\n",
      "Batch: 25, Loss: 1.4320852756500244, Accuracy: 0.5283203125\n",
      "Batch: 26, Loss: 1.3469890356063843, Accuracy: 0.5732421875\n",
      "Batch: 27, Loss: 1.4046858549118042, Accuracy: 0.5478515625\n",
      "Batch: 28, Loss: 1.461305022239685, Accuracy: 0.52734375\n",
      "Batch: 29, Loss: 1.4840147495269775, Accuracy: 0.5283203125\n",
      "Batch: 30, Loss: 1.4300720691680908, Accuracy: 0.5771484375\n",
      "Batch: 31, Loss: 1.4185930490493774, Accuracy: 0.578125\n",
      "Batch: 32, Loss: 1.3703608512878418, Accuracy: 0.560546875\n",
      "Batch: 33, Loss: 1.6078190803527832, Accuracy: 0.5126953125\n",
      "Batch: 34, Loss: 1.6313605308532715, Accuracy: 0.509765625\n",
      "Batch: 35, Loss: 1.485284686088562, Accuracy: 0.5263671875\n",
      "Batch: 36, Loss: 1.4525421857833862, Accuracy: 0.5546875\n",
      "Batch: 37, Loss: 1.5040454864501953, Accuracy: 0.5390625\n",
      "Batch: 38, Loss: 1.4568965435028076, Accuracy: 0.525390625\n",
      "Batch: 39, Loss: 1.4997552633285522, Accuracy: 0.55078125\n",
      "Batch: 40, Loss: 1.5126912593841553, Accuracy: 0.55078125\n",
      "Batch: 41, Loss: 1.5238709449768066, Accuracy: 0.5498046875\n",
      "Batch: 42, Loss: 1.2607650756835938, Accuracy: 0.609375\n",
      "Batch: 43, Loss: 1.4210389852523804, Accuracy: 0.533203125\n",
      "Batch: 44, Loss: 1.4005087614059448, Accuracy: 0.5498046875\n",
      "Batch: 45, Loss: 1.24440598487854, Accuracy: 0.5947265625\n",
      "Batch: 46, Loss: 1.4899682998657227, Accuracy: 0.564453125\n",
      "Batch: 47, Loss: 1.4488904476165771, Accuracy: 0.56640625\n",
      "Batch: 48, Loss: 1.4142522811889648, Accuracy: 0.5595703125\n",
      "Batch: 49, Loss: 1.5263605117797852, Accuracy: 0.5224609375\n",
      "Batch: 50, Loss: 1.487952709197998, Accuracy: 0.5302734375\n",
      "Batch: 51, Loss: 1.6100462675094604, Accuracy: 0.501953125\n",
      "Batch: 52, Loss: 1.5342707633972168, Accuracy: 0.533203125\n",
      "Batch: 53, Loss: 1.286363124847412, Accuracy: 0.5771484375\n",
      "Batch: 54, Loss: 1.3900141716003418, Accuracy: 0.5703125\n",
      "Batch: 55, Loss: 1.4511089324951172, Accuracy: 0.53515625\n",
      "Batch: 56, Loss: 1.5320955514907837, Accuracy: 0.5234375\n",
      "Batch: 57, Loss: 1.4176894426345825, Accuracy: 0.564453125\n",
      "Batch: 58, Loss: 1.5151917934417725, Accuracy: 0.5498046875\n",
      "Batch: 59, Loss: 1.3235262632369995, Accuracy: 0.609375\n",
      "Batch: 60, Loss: 1.3082292079925537, Accuracy: 0.59765625\n",
      "Batch: 61, Loss: 1.46806001663208, Accuracy: 0.5595703125\n",
      "Batch: 62, Loss: 1.4555683135986328, Accuracy: 0.5595703125\n",
      "Batch: 63, Loss: 1.4353463649749756, Accuracy: 0.556640625\n",
      "Batch: 64, Loss: 1.3990039825439453, Accuracy: 0.576171875\n",
      "Batch: 65, Loss: 1.4362549781799316, Accuracy: 0.560546875\n",
      "Batch: 66, Loss: 1.3278295993804932, Accuracy: 0.5888671875\n",
      "Batch: 67, Loss: 1.495805263519287, Accuracy: 0.5498046875\n",
      "Batch: 68, Loss: 1.5480966567993164, Accuracy: 0.54296875\n",
      "Batch: 69, Loss: 1.4405114650726318, Accuracy: 0.564453125\n",
      "Batch: 70, Loss: 1.4675939083099365, Accuracy: 0.5556640625\n",
      "Batch: 71, Loss: 1.4859485626220703, Accuracy: 0.53125\n",
      "Batch: 72, Loss: 1.358273983001709, Accuracy: 0.5751953125\n",
      "Batch: 73, Loss: 1.430892825126648, Accuracy: 0.568359375\n",
      "Batch: 74, Loss: 1.3766682147979736, Accuracy: 0.56640625\n",
      "Batch: 75, Loss: 1.3172121047973633, Accuracy: 0.5791015625\n",
      "Batch: 76, Loss: 1.4941530227661133, Accuracy: 0.5244140625\n",
      "Batch: 77, Loss: 1.4697372913360596, Accuracy: 0.537109375\n",
      "Batch: 78, Loss: 1.4344463348388672, Accuracy: 0.576171875\n",
      "Batch: 79, Loss: 1.242497205734253, Accuracy: 0.646484375\n",
      "Batch: 80, Loss: 1.327930212020874, Accuracy: 0.580078125\n",
      "Batch: 81, Loss: 1.4797762632369995, Accuracy: 0.513671875\n",
      "Batch: 82, Loss: 1.4495768547058105, Accuracy: 0.5400390625\n",
      "Batch: 83, Loss: 1.2902774810791016, Accuracy: 0.5986328125\n",
      "Batch: 84, Loss: 1.3481559753417969, Accuracy: 0.587890625\n",
      "Batch: 85, Loss: 1.2729125022888184, Accuracy: 0.5947265625\n",
      "Batch: 86, Loss: 1.5754142999649048, Accuracy: 0.5185546875\n",
      "Batch: 87, Loss: 1.3481261730194092, Accuracy: 0.595703125\n",
      "Batch: 88, Loss: 1.4849350452423096, Accuracy: 0.55859375\n",
      "Batch: 89, Loss: 1.4815047979354858, Accuracy: 0.5419921875\n",
      "Batch: 90, Loss: 1.3588578701019287, Accuracy: 0.5859375\n",
      "Batch: 91, Loss: 1.3710923194885254, Accuracy: 0.5693359375\n",
      "Batch: 92, Loss: 1.4350612163543701, Accuracy: 0.5595703125\n",
      "Batch: 93, Loss: 1.3181777000427246, Accuracy: 0.583984375\n",
      "Batch: 94, Loss: 1.3545609712600708, Accuracy: 0.5634765625\n",
      "Batch: 95, Loss: 1.4264072179794312, Accuracy: 0.533203125\n",
      "Batch: 96, Loss: 1.390561819076538, Accuracy: 0.583984375\n",
      "Batch: 97, Loss: 1.2563382387161255, Accuracy: 0.5986328125\n",
      "Batch: 98, Loss: 1.2745568752288818, Accuracy: 0.6171875\n",
      "Batch: 99, Loss: 1.2702109813690186, Accuracy: 0.599609375\n",
      "Batch: 100, Loss: 1.3852368593215942, Accuracy: 0.5712890625\n",
      "Batch: 101, Loss: 1.4071052074432373, Accuracy: 0.5595703125\n",
      "Batch: 102, Loss: 1.2893155813217163, Accuracy: 0.5712890625\n",
      "Batch: 103, Loss: 1.4229397773742676, Accuracy: 0.5791015625\n",
      "Batch: 104, Loss: 1.2789324522018433, Accuracy: 0.5966796875\n",
      "Batch: 105, Loss: 1.414320707321167, Accuracy: 0.5634765625\n",
      "Batch: 106, Loss: 1.4434949159622192, Accuracy: 0.5498046875\n",
      "Batch: 107, Loss: 1.5781371593475342, Accuracy: 0.517578125\n",
      "Batch: 108, Loss: 1.5090765953063965, Accuracy: 0.533203125\n",
      "Batch: 109, Loss: 1.5626399517059326, Accuracy: 0.5361328125\n",
      "Batch: 110, Loss: 1.2310571670532227, Accuracy: 0.5986328125\n",
      "Batch: 111, Loss: 1.4534657001495361, Accuracy: 0.541015625\n",
      "Batch: 112, Loss: 1.383898377418518, Accuracy: 0.578125\n",
      "Batch: 113, Loss: 1.4007222652435303, Accuracy: 0.5732421875\n",
      "Batch: 114, Loss: 1.5506105422973633, Accuracy: 0.52734375\n",
      "Batch: 115, Loss: 1.5710501670837402, Accuracy: 0.5439453125\n",
      "Batch: 116, Loss: 1.5166478157043457, Accuracy: 0.52734375\n",
      "Batch: 117, Loss: 1.4759190082550049, Accuracy: 0.56640625\n",
      "Batch: 118, Loss: 1.2517694234848022, Accuracy: 0.6259765625\n",
      "Batch: 119, Loss: 1.284358263015747, Accuracy: 0.6005859375\n",
      "Batch: 120, Loss: 1.4886574745178223, Accuracy: 0.529296875\n",
      "Batch: 121, Loss: 1.538567304611206, Accuracy: 0.521484375\n",
      "Batch: 122, Loss: 1.3635895252227783, Accuracy: 0.5810546875\n",
      "Batch: 123, Loss: 1.3452072143554688, Accuracy: 0.599609375\n",
      "Batch: 124, Loss: 1.405057430267334, Accuracy: 0.568359375\n",
      "Batch: 125, Loss: 1.4445704221725464, Accuracy: 0.552734375\n",
      "Batch: 126, Loss: 1.4690723419189453, Accuracy: 0.53125\n",
      "Batch: 127, Loss: 1.2963441610336304, Accuracy: 0.5966796875\n",
      "Batch: 128, Loss: 1.53216552734375, Accuracy: 0.541015625\n",
      "Batch: 129, Loss: 1.3957406282424927, Accuracy: 0.5517578125\n",
      "Batch: 130, Loss: 1.6230039596557617, Accuracy: 0.5126953125\n",
      "Batch: 131, Loss: 1.452714443206787, Accuracy: 0.541015625\n",
      "Batch: 132, Loss: 1.5260534286499023, Accuracy: 0.53515625\n",
      "Batch: 133, Loss: 1.3595342636108398, Accuracy: 0.5751953125\n",
      "Batch: 134, Loss: 1.4197224378585815, Accuracy: 0.5615234375\n",
      "Batch: 135, Loss: 1.3373277187347412, Accuracy: 0.595703125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 136, Loss: 1.3766987323760986, Accuracy: 0.5693359375\n",
      "Batch: 137, Loss: 1.318969488143921, Accuracy: 0.55859375\n",
      "Batch: 138, Loss: 1.1883859634399414, Accuracy: 0.6025390625\n",
      "Batch: 139, Loss: 1.2686774730682373, Accuracy: 0.58984375\n",
      "Batch: 140, Loss: 1.3801541328430176, Accuracy: 0.5537109375\n",
      "Batch: 141, Loss: 1.3829313516616821, Accuracy: 0.5791015625\n",
      "Batch: 142, Loss: 1.4326207637786865, Accuracy: 0.5517578125\n",
      "Batch: 143, Loss: 1.4390475749969482, Accuracy: 0.560546875\n",
      "Batch: 144, Loss: 1.3847811222076416, Accuracy: 0.564453125\n",
      "Batch: 145, Loss: 1.3019230365753174, Accuracy: 0.5810546875\n",
      "Batch: 146, Loss: 1.482799768447876, Accuracy: 0.525390625\n",
      "Batch: 147, Loss: 1.378619909286499, Accuracy: 0.5537109375\n",
      "Batch: 148, Loss: 1.5695888996124268, Accuracy: 0.4853515625\n",
      "Batch: 149, Loss: 1.440581202507019, Accuracy: 0.541015625\n",
      "Batch: 150, Loss: 1.336675763130188, Accuracy: 0.57421875\n",
      "Batch: 151, Loss: 1.3118271827697754, Accuracy: 0.5966796875\n",
      "Epoch 7/90\n",
      "Batch: 1, Loss: 1.66156804561615, Accuracy: 0.490234375\n",
      "Batch: 2, Loss: 1.3561201095581055, Accuracy: 0.544921875\n",
      "Batch: 3, Loss: 1.3079999685287476, Accuracy: 0.578125\n",
      "Batch: 4, Loss: 1.21297287940979, Accuracy: 0.62890625\n",
      "Batch: 5, Loss: 1.2700505256652832, Accuracy: 0.6005859375\n",
      "Batch: 6, Loss: 1.4177392721176147, Accuracy: 0.544921875\n",
      "Batch: 7, Loss: 1.33797287940979, Accuracy: 0.55078125\n",
      "Batch: 8, Loss: 1.3056161403656006, Accuracy: 0.578125\n",
      "Batch: 9, Loss: 1.2379956245422363, Accuracy: 0.6083984375\n",
      "Batch: 10, Loss: 1.26857328414917, Accuracy: 0.5927734375\n",
      "Batch: 11, Loss: 1.4793155193328857, Accuracy: 0.5244140625\n",
      "Batch: 12, Loss: 1.5236625671386719, Accuracy: 0.5205078125\n",
      "Batch: 13, Loss: 1.1863034963607788, Accuracy: 0.6337890625\n",
      "Batch: 14, Loss: 1.4500306844711304, Accuracy: 0.5419921875\n",
      "Batch: 15, Loss: 1.304052472114563, Accuracy: 0.599609375\n",
      "Batch: 16, Loss: 1.3281282186508179, Accuracy: 0.5830078125\n",
      "Batch: 17, Loss: 1.4290521144866943, Accuracy: 0.5302734375\n",
      "Batch: 18, Loss: 1.4261119365692139, Accuracy: 0.5380859375\n",
      "Batch: 19, Loss: 1.4575847387313843, Accuracy: 0.5546875\n",
      "Batch: 20, Loss: 1.3431308269500732, Accuracy: 0.5888671875\n",
      "Batch: 21, Loss: 1.3038804531097412, Accuracy: 0.6015625\n",
      "Batch: 22, Loss: 1.4607466459274292, Accuracy: 0.5517578125\n",
      "Batch: 23, Loss: 1.3523646593093872, Accuracy: 0.564453125\n",
      "Batch: 24, Loss: 1.3909938335418701, Accuracy: 0.55859375\n",
      "Batch: 25, Loss: 1.3417491912841797, Accuracy: 0.5732421875\n",
      "Batch: 26, Loss: 1.2632291316986084, Accuracy: 0.6015625\n",
      "Batch: 27, Loss: 1.3393008708953857, Accuracy: 0.560546875\n",
      "Batch: 28, Loss: 1.3954235315322876, Accuracy: 0.544921875\n",
      "Batch: 29, Loss: 1.415877342224121, Accuracy: 0.548828125\n",
      "Batch: 30, Loss: 1.3291712999343872, Accuracy: 0.603515625\n",
      "Batch: 31, Loss: 1.3102664947509766, Accuracy: 0.6025390625\n",
      "Batch: 32, Loss: 1.2770169973373413, Accuracy: 0.5849609375\n",
      "Batch: 33, Loss: 1.4924933910369873, Accuracy: 0.5419921875\n",
      "Batch: 34, Loss: 1.5665159225463867, Accuracy: 0.49609375\n",
      "Batch: 35, Loss: 1.4093844890594482, Accuracy: 0.5400390625\n",
      "Batch: 36, Loss: 1.3822929859161377, Accuracy: 0.57421875\n",
      "Batch: 37, Loss: 1.3976125717163086, Accuracy: 0.5517578125\n",
      "Batch: 38, Loss: 1.3684415817260742, Accuracy: 0.546875\n",
      "Batch: 39, Loss: 1.4015090465545654, Accuracy: 0.5703125\n",
      "Batch: 40, Loss: 1.422049880027771, Accuracy: 0.580078125\n",
      "Batch: 41, Loss: 1.4411637783050537, Accuracy: 0.5546875\n",
      "Batch: 42, Loss: 1.152350664138794, Accuracy: 0.63671875\n",
      "Batch: 43, Loss: 1.3125858306884766, Accuracy: 0.5576171875\n",
      "Batch: 44, Loss: 1.3374555110931396, Accuracy: 0.5595703125\n",
      "Batch: 45, Loss: 1.1827986240386963, Accuracy: 0.60546875\n",
      "Batch: 46, Loss: 1.3772969245910645, Accuracy: 0.595703125\n",
      "Batch: 47, Loss: 1.3712347745895386, Accuracy: 0.580078125\n",
      "Batch: 48, Loss: 1.3191652297973633, Accuracy: 0.5908203125\n",
      "Batch: 49, Loss: 1.4688166379928589, Accuracy: 0.521484375\n",
      "Batch: 50, Loss: 1.4144595861434937, Accuracy: 0.537109375\n",
      "Batch: 51, Loss: 1.5188764333724976, Accuracy: 0.5185546875\n",
      "Batch: 52, Loss: 1.4606266021728516, Accuracy: 0.5458984375\n",
      "Batch: 53, Loss: 1.1809139251708984, Accuracy: 0.6181640625\n",
      "Batch: 54, Loss: 1.3235865831375122, Accuracy: 0.5888671875\n",
      "Batch: 55, Loss: 1.3870242834091187, Accuracy: 0.556640625\n",
      "Batch: 56, Loss: 1.4443063735961914, Accuracy: 0.548828125\n",
      "Batch: 57, Loss: 1.3296494483947754, Accuracy: 0.5859375\n",
      "Batch: 58, Loss: 1.442918062210083, Accuracy: 0.5634765625\n",
      "Batch: 59, Loss: 1.2547385692596436, Accuracy: 0.6181640625\n",
      "Batch: 60, Loss: 1.2647573947906494, Accuracy: 0.6123046875\n",
      "Batch: 61, Loss: 1.4043855667114258, Accuracy: 0.564453125\n",
      "Batch: 62, Loss: 1.3554424047470093, Accuracy: 0.57421875\n",
      "Batch: 63, Loss: 1.3340848684310913, Accuracy: 0.5703125\n",
      "Batch: 64, Loss: 1.3127809762954712, Accuracy: 0.5771484375\n",
      "Batch: 65, Loss: 1.3489927053451538, Accuracy: 0.576171875\n",
      "Batch: 66, Loss: 1.2613251209259033, Accuracy: 0.6103515625\n",
      "Batch: 67, Loss: 1.4035242795944214, Accuracy: 0.5625\n",
      "Batch: 68, Loss: 1.4757120609283447, Accuracy: 0.5615234375\n",
      "Batch: 69, Loss: 1.3646730184555054, Accuracy: 0.572265625\n",
      "Batch: 70, Loss: 1.406931757926941, Accuracy: 0.5576171875\n",
      "Batch: 71, Loss: 1.3902599811553955, Accuracy: 0.5576171875\n",
      "Batch: 72, Loss: 1.2863380908966064, Accuracy: 0.6015625\n",
      "Batch: 73, Loss: 1.353376865386963, Accuracy: 0.578125\n",
      "Batch: 74, Loss: 1.2939709424972534, Accuracy: 0.5849609375\n",
      "Batch: 75, Loss: 1.230621337890625, Accuracy: 0.6181640625\n",
      "Batch: 76, Loss: 1.4080805778503418, Accuracy: 0.5478515625\n",
      "Batch: 77, Loss: 1.371512532234192, Accuracy: 0.556640625\n",
      "Batch: 78, Loss: 1.363091230392456, Accuracy: 0.595703125\n",
      "Batch: 79, Loss: 1.1830997467041016, Accuracy: 0.658203125\n",
      "Batch: 80, Loss: 1.2624499797821045, Accuracy: 0.583984375\n",
      "Batch: 81, Loss: 1.4375519752502441, Accuracy: 0.5166015625\n",
      "Batch: 82, Loss: 1.3861379623413086, Accuracy: 0.5478515625\n",
      "Batch: 83, Loss: 1.2106831073760986, Accuracy: 0.6220703125\n",
      "Batch: 84, Loss: 1.2791407108306885, Accuracy: 0.6259765625\n",
      "Batch: 85, Loss: 1.1852118968963623, Accuracy: 0.63671875\n",
      "Batch: 86, Loss: 1.5028076171875, Accuracy: 0.525390625\n",
      "Batch: 87, Loss: 1.2691361904144287, Accuracy: 0.603515625\n",
      "Batch: 88, Loss: 1.403937816619873, Accuracy: 0.580078125\n",
      "Batch: 89, Loss: 1.4251132011413574, Accuracy: 0.556640625\n",
      "Batch: 90, Loss: 1.270881175994873, Accuracy: 0.5869140625\n",
      "Batch: 91, Loss: 1.2941908836364746, Accuracy: 0.59375\n",
      "Batch: 92, Loss: 1.348982334136963, Accuracy: 0.5673828125\n",
      "Batch: 93, Loss: 1.244806170463562, Accuracy: 0.60546875\n",
      "Batch: 94, Loss: 1.3061420917510986, Accuracy: 0.5693359375\n",
      "Batch: 95, Loss: 1.3559777736663818, Accuracy: 0.5537109375\n",
      "Batch: 96, Loss: 1.323634386062622, Accuracy: 0.5947265625\n",
      "Batch: 97, Loss: 1.1691428422927856, Accuracy: 0.6337890625\n",
      "Batch: 98, Loss: 1.2220641374588013, Accuracy: 0.6181640625\n",
      "Batch: 99, Loss: 1.1911559104919434, Accuracy: 0.6162109375\n",
      "Batch: 100, Loss: 1.3314173221588135, Accuracy: 0.580078125\n",
      "Batch: 101, Loss: 1.3521811962127686, Accuracy: 0.583984375\n",
      "Batch: 102, Loss: 1.2338510751724243, Accuracy: 0.599609375\n",
      "Batch: 103, Loss: 1.3230438232421875, Accuracy: 0.603515625\n",
      "Batch: 104, Loss: 1.2059653997421265, Accuracy: 0.6044921875\n",
      "Batch: 105, Loss: 1.3680166006088257, Accuracy: 0.56640625\n",
      "Batch: 106, Loss: 1.3824231624603271, Accuracy: 0.583984375\n",
      "Batch: 107, Loss: 1.502549409866333, Accuracy: 0.537109375\n",
      "Batch: 108, Loss: 1.417201042175293, Accuracy: 0.5615234375\n",
      "Batch: 109, Loss: 1.5001322031021118, Accuracy: 0.5322265625\n",
      "Batch: 110, Loss: 1.1553635597229004, Accuracy: 0.62890625\n",
      "Batch: 111, Loss: 1.3795990943908691, Accuracy: 0.55078125\n",
      "Batch: 112, Loss: 1.3199217319488525, Accuracy: 0.591796875\n",
      "Batch: 113, Loss: 1.335672378540039, Accuracy: 0.6103515625\n",
      "Batch: 114, Loss: 1.4876863956451416, Accuracy: 0.5498046875\n",
      "Batch: 115, Loss: 1.5092735290527344, Accuracy: 0.5576171875\n",
      "Batch: 116, Loss: 1.4333064556121826, Accuracy: 0.5390625\n",
      "Batch: 117, Loss: 1.4354941844940186, Accuracy: 0.568359375\n",
      "Batch: 118, Loss: 1.1711275577545166, Accuracy: 0.6279296875\n",
      "Batch: 119, Loss: 1.2215609550476074, Accuracy: 0.6220703125\n",
      "Batch: 120, Loss: 1.4020878076553345, Accuracy: 0.5498046875\n",
      "Batch: 121, Loss: 1.4575188159942627, Accuracy: 0.548828125\n",
      "Batch: 122, Loss: 1.3030447959899902, Accuracy: 0.59765625\n",
      "Batch: 123, Loss: 1.256865382194519, Accuracy: 0.6044921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 124, Loss: 1.3319594860076904, Accuracy: 0.5849609375\n",
      "Batch: 125, Loss: 1.3866665363311768, Accuracy: 0.5625\n",
      "Batch: 126, Loss: 1.4030823707580566, Accuracy: 0.5556640625\n",
      "Batch: 127, Loss: 1.2255942821502686, Accuracy: 0.6201171875\n",
      "Batch: 128, Loss: 1.4745233058929443, Accuracy: 0.5498046875\n",
      "Batch: 129, Loss: 1.3388397693634033, Accuracy: 0.5615234375\n",
      "Batch: 130, Loss: 1.5516196489334106, Accuracy: 0.53125\n",
      "Batch: 131, Loss: 1.4097299575805664, Accuracy: 0.5537109375\n",
      "Batch: 132, Loss: 1.434544324874878, Accuracy: 0.5625\n",
      "Batch: 133, Loss: 1.2798755168914795, Accuracy: 0.595703125\n",
      "Batch: 134, Loss: 1.3572430610656738, Accuracy: 0.5654296875\n",
      "Batch: 135, Loss: 1.256243109703064, Accuracy: 0.6181640625\n",
      "Batch: 136, Loss: 1.3143960237503052, Accuracy: 0.5791015625\n",
      "Batch: 137, Loss: 1.2579429149627686, Accuracy: 0.583984375\n",
      "Batch: 138, Loss: 1.128221035003662, Accuracy: 0.630859375\n",
      "Batch: 139, Loss: 1.2096836566925049, Accuracy: 0.5888671875\n",
      "Batch: 140, Loss: 1.3185381889343262, Accuracy: 0.5498046875\n",
      "Batch: 141, Loss: 1.3451110124588013, Accuracy: 0.572265625\n",
      "Batch: 142, Loss: 1.371945858001709, Accuracy: 0.56640625\n",
      "Batch: 143, Loss: 1.3703588247299194, Accuracy: 0.5576171875\n",
      "Batch: 144, Loss: 1.339702844619751, Accuracy: 0.5908203125\n",
      "Batch: 145, Loss: 1.2381696701049805, Accuracy: 0.58984375\n",
      "Batch: 146, Loss: 1.3683130741119385, Accuracy: 0.5595703125\n",
      "Batch: 147, Loss: 1.3379876613616943, Accuracy: 0.5634765625\n",
      "Batch: 148, Loss: 1.4996697902679443, Accuracy: 0.5126953125\n",
      "Batch: 149, Loss: 1.380488395690918, Accuracy: 0.548828125\n",
      "Batch: 150, Loss: 1.2824852466583252, Accuracy: 0.58203125\n",
      "Batch: 151, Loss: 1.251826524734497, Accuracy: 0.599609375\n",
      "Epoch 8/90\n",
      "Batch: 1, Loss: 1.617661714553833, Accuracy: 0.4873046875\n",
      "Batch: 2, Loss: 1.3494662046432495, Accuracy: 0.5498046875\n",
      "Batch: 3, Loss: 1.256920576095581, Accuracy: 0.6044921875\n",
      "Batch: 4, Loss: 1.1704230308532715, Accuracy: 0.642578125\n",
      "Batch: 5, Loss: 1.2030208110809326, Accuracy: 0.6337890625\n",
      "Batch: 6, Loss: 1.3580772876739502, Accuracy: 0.5634765625\n",
      "Batch: 7, Loss: 1.248738169670105, Accuracy: 0.5888671875\n",
      "Batch: 8, Loss: 1.2324508428573608, Accuracy: 0.607421875\n",
      "Batch: 9, Loss: 1.1860406398773193, Accuracy: 0.6220703125\n",
      "Batch: 10, Loss: 1.2159485816955566, Accuracy: 0.6025390625\n",
      "Batch: 11, Loss: 1.4196999073028564, Accuracy: 0.548828125\n",
      "Batch: 12, Loss: 1.4602774381637573, Accuracy: 0.5234375\n",
      "Batch: 13, Loss: 1.131563425064087, Accuracy: 0.638671875\n",
      "Batch: 14, Loss: 1.390831708908081, Accuracy: 0.5498046875\n",
      "Batch: 15, Loss: 1.2491741180419922, Accuracy: 0.6103515625\n",
      "Batch: 16, Loss: 1.269031286239624, Accuracy: 0.5830078125\n",
      "Batch: 17, Loss: 1.3705956935882568, Accuracy: 0.5517578125\n",
      "Batch: 18, Loss: 1.3780356645584106, Accuracy: 0.548828125\n",
      "Batch: 19, Loss: 1.3855737447738647, Accuracy: 0.57421875\n",
      "Batch: 20, Loss: 1.2899036407470703, Accuracy: 0.5947265625\n",
      "Batch: 21, Loss: 1.2273437976837158, Accuracy: 0.59765625\n",
      "Batch: 22, Loss: 1.4188674688339233, Accuracy: 0.5625\n",
      "Batch: 23, Loss: 1.2815518379211426, Accuracy: 0.5732421875\n",
      "Batch: 24, Loss: 1.3176531791687012, Accuracy: 0.5625\n",
      "Batch: 25, Loss: 1.2906179428100586, Accuracy: 0.5771484375\n",
      "Batch: 26, Loss: 1.1994884014129639, Accuracy: 0.6181640625\n",
      "Batch: 27, Loss: 1.259464144706726, Accuracy: 0.5791015625\n",
      "Batch: 28, Loss: 1.3312618732452393, Accuracy: 0.5546875\n",
      "Batch: 29, Loss: 1.354966402053833, Accuracy: 0.5634765625\n",
      "Batch: 30, Loss: 1.2885315418243408, Accuracy: 0.611328125\n",
      "Batch: 31, Loss: 1.2577286958694458, Accuracy: 0.6162109375\n",
      "Batch: 32, Loss: 1.2212735414505005, Accuracy: 0.603515625\n",
      "Batch: 33, Loss: 1.427660346031189, Accuracy: 0.5419921875\n",
      "Batch: 34, Loss: 1.494821548461914, Accuracy: 0.5234375\n",
      "Batch: 35, Loss: 1.359783411026001, Accuracy: 0.5498046875\n",
      "Batch: 36, Loss: 1.3360381126403809, Accuracy: 0.5791015625\n",
      "Batch: 37, Loss: 1.3114378452301025, Accuracy: 0.5732421875\n",
      "Batch: 38, Loss: 1.301445722579956, Accuracy: 0.5703125\n",
      "Batch: 39, Loss: 1.3484666347503662, Accuracy: 0.5810546875\n",
      "Batch: 40, Loss: 1.3671295642852783, Accuracy: 0.5888671875\n",
      "Batch: 41, Loss: 1.3797152042388916, Accuracy: 0.576171875\n",
      "Batch: 42, Loss: 1.100409984588623, Accuracy: 0.6513671875\n",
      "Batch: 43, Loss: 1.2854347229003906, Accuracy: 0.5751953125\n",
      "Batch: 44, Loss: 1.292601466178894, Accuracy: 0.5615234375\n",
      "Batch: 45, Loss: 1.1371451616287231, Accuracy: 0.6240234375\n",
      "Batch: 46, Loss: 1.311309814453125, Accuracy: 0.609375\n",
      "Batch: 47, Loss: 1.288353443145752, Accuracy: 0.5927734375\n",
      "Batch: 48, Loss: 1.25521719455719, Accuracy: 0.583984375\n",
      "Batch: 49, Loss: 1.4020200967788696, Accuracy: 0.5439453125\n",
      "Batch: 50, Loss: 1.3446109294891357, Accuracy: 0.5478515625\n",
      "Batch: 51, Loss: 1.4442758560180664, Accuracy: 0.54296875\n",
      "Batch: 52, Loss: 1.4073138236999512, Accuracy: 0.55078125\n",
      "Batch: 53, Loss: 1.1706655025482178, Accuracy: 0.6220703125\n",
      "Batch: 54, Loss: 1.2750298976898193, Accuracy: 0.611328125\n",
      "Batch: 55, Loss: 1.3404619693756104, Accuracy: 0.560546875\n",
      "Batch: 56, Loss: 1.38483726978302, Accuracy: 0.564453125\n",
      "Batch: 57, Loss: 1.2801103591918945, Accuracy: 0.5947265625\n",
      "Batch: 58, Loss: 1.403566837310791, Accuracy: 0.5693359375\n",
      "Batch: 59, Loss: 1.1846833229064941, Accuracy: 0.64453125\n",
      "Batch: 60, Loss: 1.2102429866790771, Accuracy: 0.623046875\n",
      "Batch: 61, Loss: 1.3293505907058716, Accuracy: 0.5634765625\n",
      "Batch: 62, Loss: 1.2967290878295898, Accuracy: 0.5966796875\n",
      "Batch: 63, Loss: 1.264404535293579, Accuracy: 0.5908203125\n",
      "Batch: 64, Loss: 1.264660358428955, Accuracy: 0.58203125\n",
      "Batch: 65, Loss: 1.3181946277618408, Accuracy: 0.568359375\n",
      "Batch: 66, Loss: 1.2225230932235718, Accuracy: 0.6259765625\n",
      "Batch: 67, Loss: 1.3765809535980225, Accuracy: 0.56640625\n",
      "Batch: 68, Loss: 1.427330493927002, Accuracy: 0.583984375\n",
      "Batch: 69, Loss: 1.3202924728393555, Accuracy: 0.580078125\n",
      "Batch: 70, Loss: 1.3397910594940186, Accuracy: 0.5869140625\n",
      "Batch: 71, Loss: 1.3449993133544922, Accuracy: 0.5615234375\n",
      "Batch: 72, Loss: 1.2088890075683594, Accuracy: 0.6298828125\n",
      "Batch: 73, Loss: 1.2930960655212402, Accuracy: 0.6083984375\n",
      "Batch: 74, Loss: 1.2535390853881836, Accuracy: 0.62109375\n",
      "Batch: 75, Loss: 1.1939345598220825, Accuracy: 0.619140625\n",
      "Batch: 76, Loss: 1.3346712589263916, Accuracy: 0.5703125\n",
      "Batch: 77, Loss: 1.3372396230697632, Accuracy: 0.5693359375\n",
      "Batch: 78, Loss: 1.3321608304977417, Accuracy: 0.58984375\n",
      "Batch: 79, Loss: 1.1520867347717285, Accuracy: 0.6484375\n",
      "Batch: 80, Loss: 1.2182331085205078, Accuracy: 0.5947265625\n",
      "Batch: 81, Loss: 1.3890819549560547, Accuracy: 0.548828125\n",
      "Batch: 82, Loss: 1.3524751663208008, Accuracy: 0.5537109375\n",
      "Batch: 83, Loss: 1.2465444803237915, Accuracy: 0.60546875\n",
      "Batch: 84, Loss: 1.2469241619110107, Accuracy: 0.619140625\n",
      "Batch: 85, Loss: 1.1662527322769165, Accuracy: 0.6357421875\n",
      "Batch: 86, Loss: 1.4689881801605225, Accuracy: 0.53515625\n",
      "Batch: 87, Loss: 1.2693618535995483, Accuracy: 0.6025390625\n",
      "Batch: 88, Loss: 1.3718760013580322, Accuracy: 0.5771484375\n",
      "Batch: 89, Loss: 1.3674076795578003, Accuracy: 0.57421875\n",
      "Batch: 90, Loss: 1.2386670112609863, Accuracy: 0.5859375\n",
      "Batch: 91, Loss: 1.2892744541168213, Accuracy: 0.59765625\n",
      "Batch: 92, Loss: 1.3106675148010254, Accuracy: 0.5908203125\n",
      "Batch: 93, Loss: 1.214784860610962, Accuracy: 0.623046875\n",
      "Batch: 94, Loss: 1.2642312049865723, Accuracy: 0.5927734375\n",
      "Batch: 95, Loss: 1.3010292053222656, Accuracy: 0.5791015625\n",
      "Batch: 96, Loss: 1.2769783735275269, Accuracy: 0.5986328125\n",
      "Batch: 97, Loss: 1.122795820236206, Accuracy: 0.6416015625\n",
      "Batch: 98, Loss: 1.185274362564087, Accuracy: 0.638671875\n",
      "Batch: 99, Loss: 1.1735782623291016, Accuracy: 0.6171875\n",
      "Batch: 100, Loss: 1.268399715423584, Accuracy: 0.6025390625\n",
      "Batch: 101, Loss: 1.3215067386627197, Accuracy: 0.583984375\n",
      "Batch: 102, Loss: 1.1873990297317505, Accuracy: 0.6201171875\n",
      "Batch: 103, Loss: 1.2988760471343994, Accuracy: 0.6123046875\n",
      "Batch: 104, Loss: 1.1925959587097168, Accuracy: 0.61328125\n",
      "Batch: 105, Loss: 1.3162636756896973, Accuracy: 0.5771484375\n",
      "Batch: 106, Loss: 1.3216310739517212, Accuracy: 0.5849609375\n",
      "Batch: 107, Loss: 1.4224036931991577, Accuracy: 0.5556640625\n",
      "Batch: 108, Loss: 1.3587493896484375, Accuracy: 0.568359375\n",
      "Batch: 109, Loss: 1.449263095855713, Accuracy: 0.5283203125\n",
      "Batch: 110, Loss: 1.1047979593276978, Accuracy: 0.6376953125\n",
      "Batch: 111, Loss: 1.3310179710388184, Accuracy: 0.5517578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 112, Loss: 1.2779769897460938, Accuracy: 0.599609375\n",
      "Batch: 113, Loss: 1.2927110195159912, Accuracy: 0.5986328125\n",
      "Batch: 114, Loss: 1.4210206270217896, Accuracy: 0.5556640625\n",
      "Batch: 115, Loss: 1.4432392120361328, Accuracy: 0.57421875\n",
      "Batch: 116, Loss: 1.3815689086914062, Accuracy: 0.5615234375\n",
      "Batch: 117, Loss: 1.3913525342941284, Accuracy: 0.568359375\n",
      "Batch: 118, Loss: 1.1299176216125488, Accuracy: 0.642578125\n",
      "Batch: 119, Loss: 1.1871778964996338, Accuracy: 0.6298828125\n",
      "Batch: 120, Loss: 1.3519635200500488, Accuracy: 0.55078125\n",
      "Batch: 121, Loss: 1.4035155773162842, Accuracy: 0.5625\n",
      "Batch: 122, Loss: 1.238538384437561, Accuracy: 0.6181640625\n",
      "Batch: 123, Loss: 1.2306829690933228, Accuracy: 0.6220703125\n",
      "Batch: 124, Loss: 1.2627819776535034, Accuracy: 0.6083984375\n",
      "Batch: 125, Loss: 1.3425610065460205, Accuracy: 0.5703125\n",
      "Batch: 126, Loss: 1.350866675376892, Accuracy: 0.5634765625\n",
      "Batch: 127, Loss: 1.208341360092163, Accuracy: 0.6298828125\n",
      "Batch: 128, Loss: 1.429760217666626, Accuracy: 0.5634765625\n",
      "Batch: 129, Loss: 1.2974638938903809, Accuracy: 0.5859375\n",
      "Batch: 130, Loss: 1.496171474456787, Accuracy: 0.5517578125\n",
      "Batch: 131, Loss: 1.3758491277694702, Accuracy: 0.5654296875\n",
      "Batch: 132, Loss: 1.4022125005722046, Accuracy: 0.5654296875\n",
      "Batch: 133, Loss: 1.2244352102279663, Accuracy: 0.603515625\n",
      "Batch: 134, Loss: 1.2990152835845947, Accuracy: 0.57421875\n",
      "Batch: 135, Loss: 1.215476393699646, Accuracy: 0.6337890625\n",
      "Batch: 136, Loss: 1.266789197921753, Accuracy: 0.6015625\n",
      "Batch: 137, Loss: 1.19362473487854, Accuracy: 0.6171875\n",
      "Batch: 138, Loss: 1.0820099115371704, Accuracy: 0.650390625\n",
      "Batch: 139, Loss: 1.165391445159912, Accuracy: 0.603515625\n",
      "Batch: 140, Loss: 1.2627534866333008, Accuracy: 0.564453125\n",
      "Batch: 141, Loss: 1.3058819770812988, Accuracy: 0.5751953125\n",
      "Batch: 142, Loss: 1.3293592929840088, Accuracy: 0.5791015625\n",
      "Batch: 143, Loss: 1.3187617063522339, Accuracy: 0.5830078125\n",
      "Batch: 144, Loss: 1.2668113708496094, Accuracy: 0.6044921875\n",
      "Batch: 145, Loss: 1.20762038230896, Accuracy: 0.5947265625\n",
      "Batch: 146, Loss: 1.3314281702041626, Accuracy: 0.5634765625\n",
      "Batch: 147, Loss: 1.3055155277252197, Accuracy: 0.576171875\n",
      "Batch: 148, Loss: 1.44803786277771, Accuracy: 0.5283203125\n",
      "Batch: 149, Loss: 1.3173819780349731, Accuracy: 0.578125\n",
      "Batch: 150, Loss: 1.2383372783660889, Accuracy: 0.587890625\n",
      "Batch: 151, Loss: 1.185374140739441, Accuracy: 0.615234375\n",
      "Epoch 9/90\n",
      "Batch: 1, Loss: 1.54738450050354, Accuracy: 0.501953125\n",
      "Batch: 2, Loss: 1.2950769662857056, Accuracy: 0.5693359375\n",
      "Batch: 3, Loss: 1.2210495471954346, Accuracy: 0.6005859375\n",
      "Batch: 4, Loss: 1.1340556144714355, Accuracy: 0.65625\n",
      "Batch: 5, Loss: 1.1846240758895874, Accuracy: 0.6376953125\n",
      "Batch: 6, Loss: 1.3197259902954102, Accuracy: 0.560546875\n",
      "Batch: 7, Loss: 1.228219747543335, Accuracy: 0.59765625\n",
      "Batch: 8, Loss: 1.195613980293274, Accuracy: 0.6123046875\n",
      "Batch: 9, Loss: 1.1466090679168701, Accuracy: 0.6298828125\n",
      "Batch: 10, Loss: 1.1555960178375244, Accuracy: 0.6142578125\n",
      "Batch: 11, Loss: 1.3768831491470337, Accuracy: 0.5556640625\n",
      "Batch: 12, Loss: 1.4107030630111694, Accuracy: 0.55859375\n",
      "Batch: 13, Loss: 1.1142053604125977, Accuracy: 0.6484375\n",
      "Batch: 14, Loss: 1.3501644134521484, Accuracy: 0.5615234375\n",
      "Batch: 15, Loss: 1.1945655345916748, Accuracy: 0.6171875\n",
      "Batch: 16, Loss: 1.2348222732543945, Accuracy: 0.59765625\n",
      "Batch: 17, Loss: 1.3391618728637695, Accuracy: 0.55859375\n",
      "Batch: 18, Loss: 1.3221787214279175, Accuracy: 0.572265625\n",
      "Batch: 19, Loss: 1.3643068075180054, Accuracy: 0.5712890625\n",
      "Batch: 20, Loss: 1.2312500476837158, Accuracy: 0.609375\n",
      "Batch: 21, Loss: 1.2096285820007324, Accuracy: 0.6103515625\n",
      "Batch: 22, Loss: 1.3957717418670654, Accuracy: 0.564453125\n",
      "Batch: 23, Loss: 1.261059045791626, Accuracy: 0.6015625\n",
      "Batch: 24, Loss: 1.2679884433746338, Accuracy: 0.56640625\n",
      "Batch: 25, Loss: 1.2561678886413574, Accuracy: 0.587890625\n",
      "Batch: 26, Loss: 1.140214443206787, Accuracy: 0.6328125\n",
      "Batch: 27, Loss: 1.2034964561462402, Accuracy: 0.5859375\n",
      "Batch: 28, Loss: 1.2809998989105225, Accuracy: 0.58203125\n",
      "Batch: 29, Loss: 1.306830883026123, Accuracy: 0.5888671875\n",
      "Batch: 30, Loss: 1.2092392444610596, Accuracy: 0.63671875\n",
      "Batch: 31, Loss: 1.2175523042678833, Accuracy: 0.62890625\n",
      "Batch: 32, Loss: 1.1553633213043213, Accuracy: 0.6142578125\n",
      "Batch: 33, Loss: 1.3561131954193115, Accuracy: 0.5556640625\n",
      "Batch: 34, Loss: 1.425572156906128, Accuracy: 0.5537109375\n",
      "Batch: 35, Loss: 1.316893219947815, Accuracy: 0.5634765625\n",
      "Batch: 36, Loss: 1.289948582649231, Accuracy: 0.5927734375\n",
      "Batch: 37, Loss: 1.2634732723236084, Accuracy: 0.58203125\n",
      "Batch: 38, Loss: 1.2707788944244385, Accuracy: 0.5751953125\n",
      "Batch: 39, Loss: 1.2942408323287964, Accuracy: 0.6064453125\n",
      "Batch: 40, Loss: 1.3141427040100098, Accuracy: 0.6103515625\n",
      "Batch: 41, Loss: 1.3203537464141846, Accuracy: 0.5947265625\n",
      "Batch: 42, Loss: 1.0532668828964233, Accuracy: 0.6484375\n",
      "Batch: 43, Loss: 1.251459002494812, Accuracy: 0.576171875\n",
      "Batch: 44, Loss: 1.2342474460601807, Accuracy: 0.5908203125\n",
      "Batch: 45, Loss: 1.0893149375915527, Accuracy: 0.6357421875\n",
      "Batch: 46, Loss: 1.2853100299835205, Accuracy: 0.6044921875\n",
      "Batch: 47, Loss: 1.2313997745513916, Accuracy: 0.6201171875\n",
      "Batch: 48, Loss: 1.2018119096755981, Accuracy: 0.607421875\n",
      "Batch: 49, Loss: 1.3604799509048462, Accuracy: 0.560546875\n",
      "Batch: 50, Loss: 1.297412395477295, Accuracy: 0.5751953125\n",
      "Batch: 51, Loss: 1.4090871810913086, Accuracy: 0.5576171875\n",
      "Batch: 52, Loss: 1.3420934677124023, Accuracy: 0.587890625\n",
      "Batch: 53, Loss: 1.1203064918518066, Accuracy: 0.625\n",
      "Batch: 54, Loss: 1.2251842021942139, Accuracy: 0.6259765625\n",
      "Batch: 55, Loss: 1.2897242307662964, Accuracy: 0.58984375\n",
      "Batch: 56, Loss: 1.3192843198776245, Accuracy: 0.59375\n",
      "Batch: 57, Loss: 1.263489842414856, Accuracy: 0.619140625\n",
      "Batch: 58, Loss: 1.3585624694824219, Accuracy: 0.580078125\n",
      "Batch: 59, Loss: 1.1689342260360718, Accuracy: 0.6435546875\n",
      "Batch: 60, Loss: 1.1566696166992188, Accuracy: 0.6357421875\n",
      "Batch: 61, Loss: 1.2984459400177002, Accuracy: 0.5849609375\n",
      "Batch: 62, Loss: 1.2375394105911255, Accuracy: 0.6103515625\n",
      "Batch: 63, Loss: 1.2635313272476196, Accuracy: 0.5869140625\n",
      "Batch: 64, Loss: 1.2383344173431396, Accuracy: 0.6005859375\n",
      "Batch: 65, Loss: 1.2517585754394531, Accuracy: 0.6025390625\n",
      "Batch: 66, Loss: 1.1759452819824219, Accuracy: 0.6328125\n",
      "Batch: 67, Loss: 1.3606462478637695, Accuracy: 0.5791015625\n",
      "Batch: 68, Loss: 1.359541416168213, Accuracy: 0.5947265625\n",
      "Batch: 69, Loss: 1.2771319150924683, Accuracy: 0.6025390625\n",
      "Batch: 70, Loss: 1.2913891077041626, Accuracy: 0.6083984375\n",
      "Batch: 71, Loss: 1.3050888776779175, Accuracy: 0.583984375\n",
      "Batch: 72, Loss: 1.1622388362884521, Accuracy: 0.6318359375\n",
      "Batch: 73, Loss: 1.215657114982605, Accuracy: 0.6142578125\n",
      "Batch: 74, Loss: 1.1863383054733276, Accuracy: 0.619140625\n",
      "Batch: 75, Loss: 1.1433336734771729, Accuracy: 0.63671875\n",
      "Batch: 76, Loss: 1.2871339321136475, Accuracy: 0.5703125\n",
      "Batch: 77, Loss: 1.2659097909927368, Accuracy: 0.59375\n",
      "Batch: 78, Loss: 1.2534631490707397, Accuracy: 0.6083984375\n",
      "Batch: 79, Loss: 1.1056203842163086, Accuracy: 0.6591796875\n",
      "Batch: 80, Loss: 1.1584606170654297, Accuracy: 0.611328125\n",
      "Batch: 81, Loss: 1.3554742336273193, Accuracy: 0.54296875\n",
      "Batch: 82, Loss: 1.307353138923645, Accuracy: 0.57421875\n",
      "Batch: 83, Loss: 1.1428124904632568, Accuracy: 0.6396484375\n",
      "Batch: 84, Loss: 1.1965949535369873, Accuracy: 0.634765625\n",
      "Batch: 85, Loss: 1.111558198928833, Accuracy: 0.6455078125\n",
      "Batch: 86, Loss: 1.4035513401031494, Accuracy: 0.5537109375\n",
      "Batch: 87, Loss: 1.1628270149230957, Accuracy: 0.6494140625\n",
      "Batch: 88, Loss: 1.2992790937423706, Accuracy: 0.5986328125\n",
      "Batch: 89, Loss: 1.3160722255706787, Accuracy: 0.5966796875\n",
      "Batch: 90, Loss: 1.1809154748916626, Accuracy: 0.6015625\n",
      "Batch: 91, Loss: 1.2102725505828857, Accuracy: 0.609375\n",
      "Batch: 92, Loss: 1.2535966634750366, Accuracy: 0.59375\n",
      "Batch: 93, Loss: 1.1633716821670532, Accuracy: 0.6259765625\n",
      "Batch: 94, Loss: 1.2148337364196777, Accuracy: 0.599609375\n",
      "Batch: 95, Loss: 1.2562780380249023, Accuracy: 0.5859375\n",
      "Batch: 96, Loss: 1.2327697277069092, Accuracy: 0.6123046875\n",
      "Batch: 97, Loss: 1.0883095264434814, Accuracy: 0.646484375\n",
      "Batch: 98, Loss: 1.1174893379211426, Accuracy: 0.65625\n",
      "Batch: 99, Loss: 1.1198049783706665, Accuracy: 0.61328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 100, Loss: 1.230478048324585, Accuracy: 0.61328125\n",
      "Batch: 101, Loss: 1.2741810083389282, Accuracy: 0.591796875\n",
      "Batch: 102, Loss: 1.1477642059326172, Accuracy: 0.6298828125\n",
      "Batch: 103, Loss: 1.2410639524459839, Accuracy: 0.626953125\n",
      "Batch: 104, Loss: 1.1386489868164062, Accuracy: 0.6328125\n",
      "Batch: 105, Loss: 1.2735130786895752, Accuracy: 0.595703125\n",
      "Batch: 106, Loss: 1.269158124923706, Accuracy: 0.607421875\n",
      "Batch: 107, Loss: 1.3735606670379639, Accuracy: 0.5634765625\n",
      "Batch: 108, Loss: 1.3098491430282593, Accuracy: 0.5830078125\n",
      "Batch: 109, Loss: 1.394590139389038, Accuracy: 0.5556640625\n",
      "Batch: 110, Loss: 1.0795013904571533, Accuracy: 0.6416015625\n",
      "Batch: 111, Loss: 1.3027207851409912, Accuracy: 0.5634765625\n",
      "Batch: 112, Loss: 1.2244958877563477, Accuracy: 0.6123046875\n",
      "Batch: 113, Loss: 1.2298145294189453, Accuracy: 0.6279296875\n",
      "Batch: 114, Loss: 1.3775370121002197, Accuracy: 0.5751953125\n",
      "Batch: 115, Loss: 1.425600528717041, Accuracy: 0.58203125\n",
      "Batch: 116, Loss: 1.3492326736450195, Accuracy: 0.5556640625\n",
      "Batch: 117, Loss: 1.3349123001098633, Accuracy: 0.5927734375\n",
      "Batch: 118, Loss: 1.1234524250030518, Accuracy: 0.65234375\n",
      "Batch: 119, Loss: 1.1419589519500732, Accuracy: 0.6494140625\n",
      "Batch: 120, Loss: 1.2917125225067139, Accuracy: 0.5830078125\n",
      "Batch: 121, Loss: 1.3627150058746338, Accuracy: 0.560546875\n",
      "Batch: 122, Loss: 1.2093501091003418, Accuracy: 0.6279296875\n",
      "Batch: 123, Loss: 1.2067174911499023, Accuracy: 0.6181640625\n",
      "Batch: 124, Loss: 1.2340188026428223, Accuracy: 0.6181640625\n",
      "Batch: 125, Loss: 1.2915841341018677, Accuracy: 0.5849609375\n",
      "Batch: 126, Loss: 1.293339729309082, Accuracy: 0.56640625\n",
      "Batch: 127, Loss: 1.1474056243896484, Accuracy: 0.65234375\n",
      "Batch: 128, Loss: 1.3780030012130737, Accuracy: 0.58203125\n",
      "Batch: 129, Loss: 1.2244426012039185, Accuracy: 0.5908203125\n",
      "Batch: 130, Loss: 1.425032615661621, Accuracy: 0.552734375\n",
      "Batch: 131, Loss: 1.3198152780532837, Accuracy: 0.5791015625\n",
      "Batch: 132, Loss: 1.3443574905395508, Accuracy: 0.5751953125\n",
      "Batch: 133, Loss: 1.1634043455123901, Accuracy: 0.625\n",
      "Batch: 134, Loss: 1.2548267841339111, Accuracy: 0.591796875\n",
      "Batch: 135, Loss: 1.1732394695281982, Accuracy: 0.6396484375\n",
      "Batch: 136, Loss: 1.2192400693893433, Accuracy: 0.6103515625\n",
      "Batch: 137, Loss: 1.171278715133667, Accuracy: 0.603515625\n",
      "Batch: 138, Loss: 1.0436527729034424, Accuracy: 0.654296875\n",
      "Batch: 139, Loss: 1.1243034601211548, Accuracy: 0.6201171875\n",
      "Batch: 140, Loss: 1.2200021743774414, Accuracy: 0.603515625\n",
      "Batch: 141, Loss: 1.2817612886428833, Accuracy: 0.583984375\n",
      "Batch: 142, Loss: 1.2774252891540527, Accuracy: 0.595703125\n",
      "Batch: 143, Loss: 1.2750176191329956, Accuracy: 0.5908203125\n",
      "Batch: 144, Loss: 1.2493934631347656, Accuracy: 0.603515625\n",
      "Batch: 145, Loss: 1.1723078489303589, Accuracy: 0.6044921875\n",
      "Batch: 146, Loss: 1.2985703945159912, Accuracy: 0.5869140625\n",
      "Batch: 147, Loss: 1.2663084268569946, Accuracy: 0.5908203125\n",
      "Batch: 148, Loss: 1.4090800285339355, Accuracy: 0.55078125\n",
      "Batch: 149, Loss: 1.2702585458755493, Accuracy: 0.5751953125\n",
      "Batch: 150, Loss: 1.1853256225585938, Accuracy: 0.60546875\n",
      "Batch: 151, Loss: 1.1139825582504272, Accuracy: 0.6328125\n",
      "Epoch 10/90\n",
      "Batch: 1, Loss: 1.5036742687225342, Accuracy: 0.5087890625\n",
      "Batch: 2, Loss: 1.268734097480774, Accuracy: 0.56640625\n",
      "Batch: 3, Loss: 1.170473575592041, Accuracy: 0.6123046875\n",
      "Batch: 4, Loss: 1.096710443496704, Accuracy: 0.6748046875\n",
      "Batch: 5, Loss: 1.1374099254608154, Accuracy: 0.6396484375\n",
      "Batch: 6, Loss: 1.2626487016677856, Accuracy: 0.5771484375\n",
      "Batch: 7, Loss: 1.1836389303207397, Accuracy: 0.61328125\n",
      "Batch: 8, Loss: 1.1509374380111694, Accuracy: 0.6240234375\n",
      "Batch: 9, Loss: 1.1143913269042969, Accuracy: 0.65234375\n",
      "Batch: 10, Loss: 1.1412944793701172, Accuracy: 0.6318359375\n",
      "Batch: 11, Loss: 1.3522381782531738, Accuracy: 0.5634765625\n",
      "Batch: 12, Loss: 1.357609748840332, Accuracy: 0.568359375\n",
      "Batch: 13, Loss: 1.0467694997787476, Accuracy: 0.66796875\n",
      "Batch: 14, Loss: 1.275133490562439, Accuracy: 0.595703125\n",
      "Batch: 15, Loss: 1.1467795372009277, Accuracy: 0.6513671875\n",
      "Batch: 16, Loss: 1.17882239818573, Accuracy: 0.6181640625\n",
      "Batch: 17, Loss: 1.2926892042160034, Accuracy: 0.5791015625\n",
      "Batch: 18, Loss: 1.2712373733520508, Accuracy: 0.583984375\n",
      "Batch: 19, Loss: 1.3277554512023926, Accuracy: 0.580078125\n",
      "Batch: 20, Loss: 1.2035168409347534, Accuracy: 0.6123046875\n",
      "Batch: 21, Loss: 1.1866450309753418, Accuracy: 0.6171875\n",
      "Batch: 22, Loss: 1.327984094619751, Accuracy: 0.5791015625\n",
      "Batch: 23, Loss: 1.213866949081421, Accuracy: 0.6015625\n",
      "Batch: 24, Loss: 1.2272000312805176, Accuracy: 0.5869140625\n",
      "Batch: 25, Loss: 1.2054295539855957, Accuracy: 0.611328125\n",
      "Batch: 26, Loss: 1.1163909435272217, Accuracy: 0.6279296875\n",
      "Batch: 27, Loss: 1.160912036895752, Accuracy: 0.5947265625\n",
      "Batch: 28, Loss: 1.2652759552001953, Accuracy: 0.576171875\n",
      "Batch: 29, Loss: 1.26344633102417, Accuracy: 0.5830078125\n",
      "Batch: 30, Loss: 1.1869161128997803, Accuracy: 0.642578125\n",
      "Batch: 31, Loss: 1.1700150966644287, Accuracy: 0.650390625\n",
      "Batch: 32, Loss: 1.1296088695526123, Accuracy: 0.61328125\n",
      "Batch: 33, Loss: 1.3288685083389282, Accuracy: 0.5751953125\n",
      "Batch: 34, Loss: 1.3931009769439697, Accuracy: 0.5517578125\n",
      "Batch: 35, Loss: 1.2477881908416748, Accuracy: 0.587890625\n",
      "Batch: 36, Loss: 1.2385883331298828, Accuracy: 0.603515625\n",
      "Batch: 37, Loss: 1.2043241262435913, Accuracy: 0.6064453125\n",
      "Batch: 38, Loss: 1.2326304912567139, Accuracy: 0.5888671875\n",
      "Batch: 39, Loss: 1.2456473112106323, Accuracy: 0.6171875\n",
      "Batch: 40, Loss: 1.273668646812439, Accuracy: 0.6201171875\n",
      "Batch: 41, Loss: 1.2720003128051758, Accuracy: 0.607421875\n",
      "Batch: 42, Loss: 1.0224418640136719, Accuracy: 0.66015625\n",
      "Batch: 43, Loss: 1.2010102272033691, Accuracy: 0.59375\n",
      "Batch: 44, Loss: 1.2006080150604248, Accuracy: 0.58984375\n",
      "Batch: 45, Loss: 1.06317138671875, Accuracy: 0.62890625\n",
      "Batch: 46, Loss: 1.2344725131988525, Accuracy: 0.625\n",
      "Batch: 47, Loss: 1.2037851810455322, Accuracy: 0.626953125\n",
      "Batch: 48, Loss: 1.1731114387512207, Accuracy: 0.62109375\n",
      "Batch: 49, Loss: 1.3279409408569336, Accuracy: 0.5693359375\n",
      "Batch: 50, Loss: 1.2695236206054688, Accuracy: 0.5830078125\n",
      "Batch: 51, Loss: 1.3635119199752808, Accuracy: 0.55859375\n",
      "Batch: 52, Loss: 1.313385248184204, Accuracy: 0.591796875\n",
      "Batch: 53, Loss: 1.093074083328247, Accuracy: 0.6298828125\n",
      "Batch: 54, Loss: 1.1928404569625854, Accuracy: 0.6357421875\n",
      "Batch: 55, Loss: 1.242233395576477, Accuracy: 0.58984375\n",
      "Batch: 56, Loss: 1.2874791622161865, Accuracy: 0.5869140625\n",
      "Batch: 57, Loss: 1.1995482444763184, Accuracy: 0.6171875\n",
      "Batch: 58, Loss: 1.2910332679748535, Accuracy: 0.62109375\n",
      "Batch: 59, Loss: 1.1095186471939087, Accuracy: 0.6591796875\n",
      "Batch: 60, Loss: 1.1165716648101807, Accuracy: 0.6337890625\n",
      "Batch: 61, Loss: 1.2420380115509033, Accuracy: 0.607421875\n",
      "Batch: 62, Loss: 1.2110142707824707, Accuracy: 0.6103515625\n",
      "Batch: 63, Loss: 1.2235571146011353, Accuracy: 0.6044921875\n",
      "Batch: 64, Loss: 1.1795711517333984, Accuracy: 0.623046875\n",
      "Batch: 65, Loss: 1.2372868061065674, Accuracy: 0.6064453125\n",
      "Batch: 66, Loss: 1.1385222673416138, Accuracy: 0.6533203125\n",
      "Batch: 67, Loss: 1.2928338050842285, Accuracy: 0.6064453125\n",
      "Batch: 68, Loss: 1.3212648630142212, Accuracy: 0.6005859375\n",
      "Batch: 69, Loss: 1.2476376295089722, Accuracy: 0.6103515625\n",
      "Batch: 70, Loss: 1.257318377494812, Accuracy: 0.609375\n",
      "Batch: 71, Loss: 1.2564678192138672, Accuracy: 0.595703125\n",
      "Batch: 72, Loss: 1.106246829032898, Accuracy: 0.6572265625\n",
      "Batch: 73, Loss: 1.1780271530151367, Accuracy: 0.6328125\n",
      "Batch: 74, Loss: 1.1638720035552979, Accuracy: 0.615234375\n",
      "Batch: 75, Loss: 1.109596848487854, Accuracy: 0.6494140625\n",
      "Batch: 76, Loss: 1.24308180809021, Accuracy: 0.583984375\n",
      "Batch: 77, Loss: 1.2108536958694458, Accuracy: 0.6064453125\n",
      "Batch: 78, Loss: 1.1954954862594604, Accuracy: 0.6201171875\n",
      "Batch: 79, Loss: 1.0633599758148193, Accuracy: 0.67578125\n",
      "Batch: 80, Loss: 1.130812644958496, Accuracy: 0.626953125\n",
      "Batch: 81, Loss: 1.2870804071426392, Accuracy: 0.5615234375\n",
      "Batch: 82, Loss: 1.2757904529571533, Accuracy: 0.5830078125\n",
      "Batch: 83, Loss: 1.0990880727767944, Accuracy: 0.6552734375\n",
      "Batch: 84, Loss: 1.15975821018219, Accuracy: 0.64453125\n",
      "Batch: 85, Loss: 1.0944833755493164, Accuracy: 0.6494140625\n",
      "Batch: 86, Loss: 1.3661071062088013, Accuracy: 0.5576171875\n",
      "Batch: 87, Loss: 1.130079746246338, Accuracy: 0.6640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 88, Loss: 1.2556829452514648, Accuracy: 0.6201171875\n",
      "Batch: 89, Loss: 1.274505853652954, Accuracy: 0.59375\n",
      "Batch: 90, Loss: 1.126273274421692, Accuracy: 0.630859375\n",
      "Batch: 91, Loss: 1.184218406677246, Accuracy: 0.62890625\n",
      "Batch: 92, Loss: 1.2188518047332764, Accuracy: 0.603515625\n",
      "Batch: 93, Loss: 1.116747260093689, Accuracy: 0.650390625\n",
      "Batch: 94, Loss: 1.1698007583618164, Accuracy: 0.6201171875\n",
      "Batch: 95, Loss: 1.232497215270996, Accuracy: 0.5849609375\n",
      "Batch: 96, Loss: 1.1875238418579102, Accuracy: 0.638671875\n",
      "Batch: 97, Loss: 1.0473740100860596, Accuracy: 0.654296875\n",
      "Batch: 98, Loss: 1.1086807250976562, Accuracy: 0.66015625\n",
      "Batch: 99, Loss: 1.0929288864135742, Accuracy: 0.6328125\n",
      "Batch: 100, Loss: 1.2067580223083496, Accuracy: 0.619140625\n",
      "Batch: 101, Loss: 1.235370397567749, Accuracy: 0.603515625\n",
      "Batch: 102, Loss: 1.1209994554519653, Accuracy: 0.625\n",
      "Batch: 103, Loss: 1.2008731365203857, Accuracy: 0.626953125\n",
      "Batch: 104, Loss: 1.097110390663147, Accuracy: 0.6376953125\n",
      "Batch: 105, Loss: 1.2533073425292969, Accuracy: 0.609375\n",
      "Batch: 106, Loss: 1.2322924137115479, Accuracy: 0.611328125\n",
      "Batch: 107, Loss: 1.2959367036819458, Accuracy: 0.5810546875\n",
      "Batch: 108, Loss: 1.2374560832977295, Accuracy: 0.5927734375\n",
      "Batch: 109, Loss: 1.3541195392608643, Accuracy: 0.5673828125\n",
      "Batch: 110, Loss: 1.0273292064666748, Accuracy: 0.66015625\n",
      "Batch: 111, Loss: 1.2577810287475586, Accuracy: 0.58203125\n",
      "Batch: 112, Loss: 1.2109233140945435, Accuracy: 0.6162109375\n",
      "Batch: 113, Loss: 1.2055720090866089, Accuracy: 0.6435546875\n",
      "Batch: 114, Loss: 1.327752947807312, Accuracy: 0.583984375\n",
      "Batch: 115, Loss: 1.3469772338867188, Accuracy: 0.580078125\n",
      "Batch: 116, Loss: 1.2706284523010254, Accuracy: 0.5849609375\n",
      "Batch: 117, Loss: 1.2740068435668945, Accuracy: 0.59375\n",
      "Batch: 118, Loss: 1.0807549953460693, Accuracy: 0.654296875\n",
      "Batch: 119, Loss: 1.0971293449401855, Accuracy: 0.6552734375\n",
      "Batch: 120, Loss: 1.2514500617980957, Accuracy: 0.5859375\n",
      "Batch: 121, Loss: 1.2944583892822266, Accuracy: 0.59765625\n",
      "Batch: 122, Loss: 1.1518104076385498, Accuracy: 0.634765625\n",
      "Batch: 123, Loss: 1.1506593227386475, Accuracy: 0.64453125\n",
      "Batch: 124, Loss: 1.1994240283966064, Accuracy: 0.6220703125\n",
      "Batch: 125, Loss: 1.275673270225525, Accuracy: 0.591796875\n",
      "Batch: 126, Loss: 1.2418415546417236, Accuracy: 0.59375\n",
      "Batch: 127, Loss: 1.1023569107055664, Accuracy: 0.64453125\n",
      "Batch: 128, Loss: 1.3361563682556152, Accuracy: 0.59765625\n",
      "Batch: 129, Loss: 1.1869611740112305, Accuracy: 0.6162109375\n",
      "Batch: 130, Loss: 1.3783369064331055, Accuracy: 0.572265625\n",
      "Batch: 131, Loss: 1.2792558670043945, Accuracy: 0.5869140625\n",
      "Batch: 132, Loss: 1.306357502937317, Accuracy: 0.59765625\n",
      "Batch: 133, Loss: 1.1358354091644287, Accuracy: 0.62890625\n",
      "Batch: 134, Loss: 1.2119061946868896, Accuracy: 0.607421875\n",
      "Batch: 135, Loss: 1.1149696111679077, Accuracy: 0.64453125\n",
      "Batch: 136, Loss: 1.179991602897644, Accuracy: 0.6298828125\n",
      "Batch: 137, Loss: 1.1143734455108643, Accuracy: 0.626953125\n",
      "Batch: 138, Loss: 0.9892416000366211, Accuracy: 0.6630859375\n",
      "Batch: 139, Loss: 1.0620602369308472, Accuracy: 0.6376953125\n",
      "Batch: 140, Loss: 1.1485806703567505, Accuracy: 0.6171875\n",
      "Batch: 141, Loss: 1.2524573802947998, Accuracy: 0.599609375\n",
      "Batch: 142, Loss: 1.2422124147415161, Accuracy: 0.6064453125\n",
      "Batch: 143, Loss: 1.2373945713043213, Accuracy: 0.607421875\n",
      "Batch: 144, Loss: 1.206474781036377, Accuracy: 0.615234375\n",
      "Batch: 145, Loss: 1.1433520317077637, Accuracy: 0.6025390625\n",
      "Batch: 146, Loss: 1.2772858142852783, Accuracy: 0.5771484375\n",
      "Batch: 147, Loss: 1.215471625328064, Accuracy: 0.6083984375\n",
      "Batch: 148, Loss: 1.3617993593215942, Accuracy: 0.54296875\n",
      "Batch: 149, Loss: 1.2275538444519043, Accuracy: 0.5791015625\n",
      "Batch: 150, Loss: 1.1490058898925781, Accuracy: 0.619140625\n",
      "Batch: 151, Loss: 1.0755743980407715, Accuracy: 0.6650390625\n",
      "Saved Weights at epoch 10 to file Weights_10.h5\n",
      "Epoch 11/90\n",
      "Batch: 1, Loss: 1.4600684642791748, Accuracy: 0.533203125\n",
      "Batch: 2, Loss: 1.2477355003356934, Accuracy: 0.5849609375\n",
      "Batch: 3, Loss: 1.1281702518463135, Accuracy: 0.630859375\n",
      "Batch: 4, Loss: 1.0434057712554932, Accuracy: 0.671875\n",
      "Batch: 5, Loss: 1.0881898403167725, Accuracy: 0.6474609375\n",
      "Batch: 6, Loss: 1.2033541202545166, Accuracy: 0.59375\n",
      "Batch: 7, Loss: 1.1443257331848145, Accuracy: 0.6318359375\n",
      "Batch: 8, Loss: 1.1051576137542725, Accuracy: 0.6337890625\n",
      "Batch: 9, Loss: 1.060149908065796, Accuracy: 0.6630859375\n",
      "Batch: 10, Loss: 1.0881553888320923, Accuracy: 0.6484375\n",
      "Batch: 11, Loss: 1.3183600902557373, Accuracy: 0.5732421875\n",
      "Batch: 12, Loss: 1.3135263919830322, Accuracy: 0.5703125\n",
      "Batch: 13, Loss: 1.0195943117141724, Accuracy: 0.66796875\n",
      "Batch: 14, Loss: 1.2438809871673584, Accuracy: 0.6005859375\n",
      "Batch: 15, Loss: 1.10606050491333, Accuracy: 0.654296875\n",
      "Batch: 16, Loss: 1.112526297569275, Accuracy: 0.6328125\n",
      "Batch: 17, Loss: 1.2289583683013916, Accuracy: 0.587890625\n",
      "Batch: 18, Loss: 1.2337360382080078, Accuracy: 0.5859375\n",
      "Batch: 19, Loss: 1.2751309871673584, Accuracy: 0.6025390625\n",
      "Batch: 20, Loss: 1.1432865858078003, Accuracy: 0.638671875\n",
      "Batch: 21, Loss: 1.130783200263977, Accuracy: 0.6240234375\n",
      "Batch: 22, Loss: 1.2428079843521118, Accuracy: 0.61328125\n",
      "Batch: 23, Loss: 1.1732518672943115, Accuracy: 0.6044921875\n",
      "Batch: 24, Loss: 1.180238127708435, Accuracy: 0.6171875\n",
      "Batch: 25, Loss: 1.151457667350769, Accuracy: 0.6298828125\n",
      "Batch: 26, Loss: 1.0599652528762817, Accuracy: 0.658203125\n",
      "Batch: 27, Loss: 1.1144969463348389, Accuracy: 0.619140625\n",
      "Batch: 28, Loss: 1.2184350490570068, Accuracy: 0.5810546875\n",
      "Batch: 29, Loss: 1.1970564126968384, Accuracy: 0.6025390625\n",
      "Batch: 30, Loss: 1.130782127380371, Accuracy: 0.6552734375\n",
      "Batch: 31, Loss: 1.137026071548462, Accuracy: 0.6513671875\n",
      "Batch: 32, Loss: 1.066213846206665, Accuracy: 0.6455078125\n",
      "Batch: 33, Loss: 1.2812092304229736, Accuracy: 0.58984375\n",
      "Batch: 34, Loss: 1.3220696449279785, Accuracy: 0.568359375\n",
      "Batch: 35, Loss: 1.2086997032165527, Accuracy: 0.6044921875\n",
      "Batch: 36, Loss: 1.1851484775543213, Accuracy: 0.6220703125\n",
      "Batch: 37, Loss: 1.160890817642212, Accuracy: 0.611328125\n",
      "Batch: 38, Loss: 1.2026052474975586, Accuracy: 0.576171875\n",
      "Batch: 39, Loss: 1.2302205562591553, Accuracy: 0.6201171875\n",
      "Batch: 40, Loss: 1.2408801317214966, Accuracy: 0.6162109375\n",
      "Batch: 41, Loss: 1.2118189334869385, Accuracy: 0.62109375\n",
      "Batch: 42, Loss: 0.9715437889099121, Accuracy: 0.673828125\n",
      "Batch: 43, Loss: 1.2040395736694336, Accuracy: 0.5888671875\n",
      "Batch: 44, Loss: 1.158966064453125, Accuracy: 0.603515625\n",
      "Batch: 45, Loss: 1.0162224769592285, Accuracy: 0.65234375\n",
      "Batch: 46, Loss: 1.1948251724243164, Accuracy: 0.6455078125\n",
      "Batch: 47, Loss: 1.1447674036026, Accuracy: 0.6484375\n",
      "Batch: 48, Loss: 1.1079001426696777, Accuracy: 0.6318359375\n",
      "Batch: 49, Loss: 1.2969043254852295, Accuracy: 0.595703125\n",
      "Batch: 50, Loss: 1.2370810508728027, Accuracy: 0.6044921875\n",
      "Batch: 51, Loss: 1.2972524166107178, Accuracy: 0.57421875\n",
      "Batch: 52, Loss: 1.252374529838562, Accuracy: 0.6171875\n",
      "Batch: 53, Loss: 1.0615932941436768, Accuracy: 0.6396484375\n",
      "Batch: 54, Loss: 1.1343278884887695, Accuracy: 0.646484375\n",
      "Batch: 55, Loss: 1.2177085876464844, Accuracy: 0.5849609375\n",
      "Batch: 56, Loss: 1.2518073320388794, Accuracy: 0.59375\n",
      "Batch: 57, Loss: 1.1583938598632812, Accuracy: 0.6416015625\n",
      "Batch: 58, Loss: 1.2362481355667114, Accuracy: 0.6220703125\n",
      "Batch: 59, Loss: 1.0606416463851929, Accuracy: 0.666015625\n",
      "Batch: 60, Loss: 1.0759403705596924, Accuracy: 0.6484375\n",
      "Batch: 61, Loss: 1.1986854076385498, Accuracy: 0.61328125\n",
      "Batch: 62, Loss: 1.1614396572113037, Accuracy: 0.6279296875\n",
      "Batch: 63, Loss: 1.1543660163879395, Accuracy: 0.626953125\n",
      "Batch: 64, Loss: 1.1490676403045654, Accuracy: 0.6181640625\n",
      "Batch: 65, Loss: 1.1769886016845703, Accuracy: 0.634765625\n",
      "Batch: 66, Loss: 1.1102910041809082, Accuracy: 0.646484375\n",
      "Batch: 67, Loss: 1.2694522142410278, Accuracy: 0.5966796875\n",
      "Batch: 68, Loss: 1.2788269519805908, Accuracy: 0.615234375\n",
      "Batch: 69, Loss: 1.205946683883667, Accuracy: 0.6015625\n",
      "Batch: 70, Loss: 1.2105478048324585, Accuracy: 0.6171875\n",
      "Batch: 71, Loss: 1.2110412120819092, Accuracy: 0.611328125\n",
      "Batch: 72, Loss: 1.039304256439209, Accuracy: 0.6640625\n",
      "Batch: 73, Loss: 1.1332125663757324, Accuracy: 0.638671875\n",
      "Batch: 74, Loss: 1.1143639087677002, Accuracy: 0.6416015625\n",
      "Batch: 75, Loss: 1.0505858659744263, Accuracy: 0.6611328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 76, Loss: 1.1873385906219482, Accuracy: 0.59765625\n",
      "Batch: 77, Loss: 1.1729626655578613, Accuracy: 0.6064453125\n",
      "Batch: 78, Loss: 1.1572024822235107, Accuracy: 0.6396484375\n",
      "Batch: 79, Loss: 1.0307273864746094, Accuracy: 0.6943359375\n",
      "Batch: 80, Loss: 1.106895089149475, Accuracy: 0.6328125\n",
      "Batch: 81, Loss: 1.2604628801345825, Accuracy: 0.5673828125\n",
      "Batch: 82, Loss: 1.2227234840393066, Accuracy: 0.595703125\n",
      "Batch: 83, Loss: 1.0532925128936768, Accuracy: 0.6796875\n",
      "Batch: 84, Loss: 1.1212384700775146, Accuracy: 0.6533203125\n",
      "Batch: 85, Loss: 1.0405999422073364, Accuracy: 0.6728515625\n",
      "Batch: 86, Loss: 1.3139479160308838, Accuracy: 0.58203125\n",
      "Batch: 87, Loss: 1.0848705768585205, Accuracy: 0.6591796875\n",
      "Batch: 88, Loss: 1.214620590209961, Accuracy: 0.6298828125\n",
      "Batch: 89, Loss: 1.233569622039795, Accuracy: 0.6220703125\n",
      "Batch: 90, Loss: 1.0738658905029297, Accuracy: 0.6533203125\n",
      "Batch: 91, Loss: 1.1564184427261353, Accuracy: 0.6357421875\n",
      "Batch: 92, Loss: 1.174041748046875, Accuracy: 0.6142578125\n",
      "Batch: 93, Loss: 1.0946975946426392, Accuracy: 0.6572265625\n",
      "Batch: 94, Loss: 1.1366395950317383, Accuracy: 0.6181640625\n",
      "Batch: 95, Loss: 1.1698880195617676, Accuracy: 0.6025390625\n",
      "Batch: 96, Loss: 1.1503448486328125, Accuracy: 0.642578125\n",
      "Batch: 97, Loss: 1.0051043033599854, Accuracy: 0.671875\n",
      "Batch: 98, Loss: 1.0737097263336182, Accuracy: 0.666015625\n",
      "Batch: 99, Loss: 1.057600975036621, Accuracy: 0.6513671875\n",
      "Batch: 100, Loss: 1.1524202823638916, Accuracy: 0.6396484375\n",
      "Batch: 101, Loss: 1.1965769529342651, Accuracy: 0.609375\n",
      "Batch: 102, Loss: 1.0925548076629639, Accuracy: 0.640625\n",
      "Batch: 103, Loss: 1.1671425104141235, Accuracy: 0.6484375\n",
      "Batch: 104, Loss: 1.0651332139968872, Accuracy: 0.6513671875\n",
      "Batch: 105, Loss: 1.206702470779419, Accuracy: 0.6201171875\n",
      "Batch: 106, Loss: 1.17096745967865, Accuracy: 0.625\n",
      "Batch: 107, Loss: 1.2490460872650146, Accuracy: 0.59765625\n",
      "Batch: 108, Loss: 1.1795107126235962, Accuracy: 0.607421875\n",
      "Batch: 109, Loss: 1.2986780405044556, Accuracy: 0.5732421875\n",
      "Batch: 110, Loss: 0.9973565340042114, Accuracy: 0.6708984375\n",
      "Batch: 111, Loss: 1.2043547630310059, Accuracy: 0.5986328125\n",
      "Batch: 112, Loss: 1.1727080345153809, Accuracy: 0.630859375\n",
      "Batch: 113, Loss: 1.172392725944519, Accuracy: 0.6484375\n",
      "Batch: 114, Loss: 1.3088433742523193, Accuracy: 0.5927734375\n",
      "Batch: 115, Loss: 1.3015159368515015, Accuracy: 0.6162109375\n",
      "Batch: 116, Loss: 1.240940809249878, Accuracy: 0.59765625\n",
      "Batch: 117, Loss: 1.2331855297088623, Accuracy: 0.6064453125\n",
      "Batch: 118, Loss: 1.0484559535980225, Accuracy: 0.66015625\n",
      "Batch: 119, Loss: 1.0331040620803833, Accuracy: 0.6787109375\n",
      "Batch: 120, Loss: 1.2079464197158813, Accuracy: 0.5888671875\n",
      "Batch: 121, Loss: 1.2607868909835815, Accuracy: 0.595703125\n",
      "Batch: 122, Loss: 1.148724913597107, Accuracy: 0.6376953125\n",
      "Batch: 123, Loss: 1.1168982982635498, Accuracy: 0.6494140625\n",
      "Batch: 124, Loss: 1.1893922090530396, Accuracy: 0.6201171875\n",
      "Batch: 125, Loss: 1.2265605926513672, Accuracy: 0.6171875\n",
      "Batch: 126, Loss: 1.2074096202850342, Accuracy: 0.6015625\n",
      "Batch: 127, Loss: 1.0797340869903564, Accuracy: 0.654296875\n",
      "Batch: 128, Loss: 1.2879688739776611, Accuracy: 0.6083984375\n",
      "Batch: 129, Loss: 1.1315466165542603, Accuracy: 0.625\n",
      "Batch: 130, Loss: 1.3256453275680542, Accuracy: 0.57421875\n",
      "Batch: 131, Loss: 1.2337567806243896, Accuracy: 0.6171875\n",
      "Batch: 132, Loss: 1.2625621557235718, Accuracy: 0.603515625\n",
      "Batch: 133, Loss: 1.089491844177246, Accuracy: 0.642578125\n",
      "Batch: 134, Loss: 1.1744005680084229, Accuracy: 0.611328125\n",
      "Batch: 135, Loss: 1.0815269947052002, Accuracy: 0.6640625\n",
      "Batch: 136, Loss: 1.1425666809082031, Accuracy: 0.646484375\n",
      "Batch: 137, Loss: 1.062604308128357, Accuracy: 0.6494140625\n",
      "Batch: 138, Loss: 0.9642811417579651, Accuracy: 0.6708984375\n",
      "Batch: 139, Loss: 1.048345923423767, Accuracy: 0.6416015625\n",
      "Batch: 140, Loss: 1.147037386894226, Accuracy: 0.6103515625\n",
      "Batch: 141, Loss: 1.1893012523651123, Accuracy: 0.6171875\n",
      "Batch: 142, Loss: 1.2130203247070312, Accuracy: 0.6123046875\n",
      "Batch: 143, Loss: 1.1977968215942383, Accuracy: 0.6015625\n",
      "Batch: 144, Loss: 1.1521713733673096, Accuracy: 0.630859375\n",
      "Batch: 145, Loss: 1.1067336797714233, Accuracy: 0.6240234375\n",
      "Batch: 146, Loss: 1.209169864654541, Accuracy: 0.6083984375\n",
      "Batch: 147, Loss: 1.171725869178772, Accuracy: 0.6181640625\n",
      "Batch: 148, Loss: 1.3030591011047363, Accuracy: 0.56640625\n",
      "Batch: 149, Loss: 1.1831941604614258, Accuracy: 0.6015625\n",
      "Batch: 150, Loss: 1.1043074131011963, Accuracy: 0.6318359375\n",
      "Batch: 151, Loss: 1.0163328647613525, Accuracy: 0.677734375\n",
      "Epoch 12/90\n",
      "Batch: 1, Loss: 1.4107091426849365, Accuracy: 0.5390625\n",
      "Batch: 2, Loss: 1.207956075668335, Accuracy: 0.576171875\n",
      "Batch: 3, Loss: 1.0830035209655762, Accuracy: 0.6455078125\n",
      "Batch: 4, Loss: 1.0087040662765503, Accuracy: 0.6875\n",
      "Batch: 5, Loss: 1.0616888999938965, Accuracy: 0.654296875\n",
      "Batch: 6, Loss: 1.1714787483215332, Accuracy: 0.62109375\n",
      "Batch: 7, Loss: 1.104516863822937, Accuracy: 0.6494140625\n",
      "Batch: 8, Loss: 1.0759668350219727, Accuracy: 0.630859375\n",
      "Batch: 9, Loss: 1.0171035528182983, Accuracy: 0.6748046875\n",
      "Batch: 10, Loss: 1.036483645439148, Accuracy: 0.6474609375\n",
      "Batch: 11, Loss: 1.259612798690796, Accuracy: 0.5771484375\n",
      "Batch: 12, Loss: 1.28946053981781, Accuracy: 0.5869140625\n",
      "Batch: 13, Loss: 0.9786373376846313, Accuracy: 0.6767578125\n",
      "Batch: 14, Loss: 1.2174322605133057, Accuracy: 0.60546875\n",
      "Batch: 15, Loss: 1.0569446086883545, Accuracy: 0.68359375\n",
      "Batch: 16, Loss: 1.0598039627075195, Accuracy: 0.666015625\n",
      "Batch: 17, Loss: 1.1828416585922241, Accuracy: 0.6162109375\n",
      "Batch: 18, Loss: 1.1721527576446533, Accuracy: 0.6259765625\n",
      "Batch: 19, Loss: 1.2507632970809937, Accuracy: 0.6083984375\n",
      "Batch: 20, Loss: 1.0963561534881592, Accuracy: 0.6591796875\n",
      "Batch: 21, Loss: 1.0903730392456055, Accuracy: 0.63671875\n",
      "Batch: 22, Loss: 1.2264974117279053, Accuracy: 0.615234375\n",
      "Batch: 23, Loss: 1.1298818588256836, Accuracy: 0.6240234375\n",
      "Batch: 24, Loss: 1.133584976196289, Accuracy: 0.619140625\n",
      "Batch: 25, Loss: 1.125483512878418, Accuracy: 0.630859375\n",
      "Batch: 26, Loss: 1.0363961458206177, Accuracy: 0.6640625\n",
      "Batch: 27, Loss: 1.0457534790039062, Accuracy: 0.6435546875\n",
      "Batch: 28, Loss: 1.1849793195724487, Accuracy: 0.6044921875\n",
      "Batch: 29, Loss: 1.1589828729629517, Accuracy: 0.6259765625\n",
      "Batch: 30, Loss: 1.096900463104248, Accuracy: 0.6650390625\n",
      "Batch: 31, Loss: 1.0973100662231445, Accuracy: 0.6494140625\n",
      "Batch: 32, Loss: 1.028621792793274, Accuracy: 0.66015625\n",
      "Batch: 33, Loss: 1.2104939222335815, Accuracy: 0.609375\n",
      "Batch: 34, Loss: 1.2933862209320068, Accuracy: 0.5712890625\n",
      "Batch: 35, Loss: 1.1968090534210205, Accuracy: 0.603515625\n",
      "Batch: 36, Loss: 1.1664910316467285, Accuracy: 0.640625\n",
      "Batch: 37, Loss: 1.1342403888702393, Accuracy: 0.6259765625\n",
      "Batch: 38, Loss: 1.1586322784423828, Accuracy: 0.6279296875\n",
      "Batch: 39, Loss: 1.176224946975708, Accuracy: 0.6376953125\n",
      "Batch: 40, Loss: 1.1953537464141846, Accuracy: 0.630859375\n",
      "Batch: 41, Loss: 1.1716142892837524, Accuracy: 0.630859375\n",
      "Batch: 42, Loss: 0.9565368890762329, Accuracy: 0.6845703125\n",
      "Batch: 43, Loss: 1.1565728187561035, Accuracy: 0.6171875\n",
      "Batch: 44, Loss: 1.1422183513641357, Accuracy: 0.6005859375\n",
      "Batch: 45, Loss: 1.012641429901123, Accuracy: 0.6513671875\n",
      "Batch: 46, Loss: 1.1254661083221436, Accuracy: 0.6494140625\n",
      "Batch: 47, Loss: 1.0978829860687256, Accuracy: 0.6533203125\n",
      "Batch: 48, Loss: 1.0630738735198975, Accuracy: 0.6474609375\n",
      "Batch: 49, Loss: 1.261232852935791, Accuracy: 0.5830078125\n",
      "Batch: 50, Loss: 1.2140228748321533, Accuracy: 0.611328125\n",
      "Batch: 51, Loss: 1.2768605947494507, Accuracy: 0.5947265625\n",
      "Batch: 52, Loss: 1.2232176065444946, Accuracy: 0.6103515625\n",
      "Batch: 53, Loss: 1.032198190689087, Accuracy: 0.654296875\n",
      "Batch: 54, Loss: 1.1210815906524658, Accuracy: 0.6376953125\n",
      "Batch: 55, Loss: 1.1884773969650269, Accuracy: 0.5888671875\n",
      "Batch: 56, Loss: 1.1900267601013184, Accuracy: 0.625\n",
      "Batch: 57, Loss: 1.1129858493804932, Accuracy: 0.64453125\n",
      "Batch: 58, Loss: 1.2156420946121216, Accuracy: 0.638671875\n",
      "Batch: 59, Loss: 1.0419014692306519, Accuracy: 0.6826171875\n",
      "Batch: 60, Loss: 1.0487644672393799, Accuracy: 0.66796875\n",
      "Batch: 61, Loss: 1.142870306968689, Accuracy: 0.6201171875\n",
      "Batch: 62, Loss: 1.122483253479004, Accuracy: 0.6484375\n",
      "Batch: 63, Loss: 1.145524263381958, Accuracy: 0.6328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 64, Loss: 1.1158812046051025, Accuracy: 0.6357421875\n",
      "Batch: 65, Loss: 1.1695884466171265, Accuracy: 0.6259765625\n",
      "Batch: 66, Loss: 1.076860785484314, Accuracy: 0.6533203125\n",
      "Batch: 67, Loss: 1.2166321277618408, Accuracy: 0.6044921875\n",
      "Batch: 68, Loss: 1.2340821027755737, Accuracy: 0.6328125\n",
      "Batch: 69, Loss: 1.1586329936981201, Accuracy: 0.623046875\n",
      "Batch: 70, Loss: 1.1630239486694336, Accuracy: 0.6396484375\n",
      "Batch: 71, Loss: 1.1697661876678467, Accuracy: 0.619140625\n",
      "Batch: 72, Loss: 1.009136438369751, Accuracy: 0.68359375\n",
      "Batch: 73, Loss: 1.0854226350784302, Accuracy: 0.65625\n",
      "Batch: 74, Loss: 1.0808099508285522, Accuracy: 0.650390625\n",
      "Batch: 75, Loss: 1.015987515449524, Accuracy: 0.68359375\n",
      "Batch: 76, Loss: 1.1644415855407715, Accuracy: 0.623046875\n",
      "Batch: 77, Loss: 1.1092076301574707, Accuracy: 0.650390625\n",
      "Batch: 78, Loss: 1.1083967685699463, Accuracy: 0.65234375\n",
      "Batch: 79, Loss: 1.0133863687515259, Accuracy: 0.689453125\n",
      "Batch: 80, Loss: 1.0577553510665894, Accuracy: 0.642578125\n",
      "Batch: 81, Loss: 1.2202351093292236, Accuracy: 0.578125\n",
      "Batch: 82, Loss: 1.1955910921096802, Accuracy: 0.6025390625\n",
      "Batch: 83, Loss: 1.0192776918411255, Accuracy: 0.669921875\n",
      "Batch: 84, Loss: 1.0874323844909668, Accuracy: 0.6689453125\n",
      "Batch: 85, Loss: 1.0031183958053589, Accuracy: 0.6826171875\n",
      "Batch: 86, Loss: 1.2905720472335815, Accuracy: 0.5947265625\n",
      "Batch: 87, Loss: 1.06324303150177, Accuracy: 0.67578125\n",
      "Batch: 88, Loss: 1.1849184036254883, Accuracy: 0.6328125\n",
      "Batch: 89, Loss: 1.1743767261505127, Accuracy: 0.640625\n",
      "Batch: 90, Loss: 1.0462236404418945, Accuracy: 0.6611328125\n",
      "Batch: 91, Loss: 1.113783359527588, Accuracy: 0.6455078125\n",
      "Batch: 92, Loss: 1.1234917640686035, Accuracy: 0.6376953125\n",
      "Batch: 93, Loss: 1.0693891048431396, Accuracy: 0.6611328125\n",
      "Batch: 94, Loss: 1.0986905097961426, Accuracy: 0.6328125\n",
      "Batch: 95, Loss: 1.1216274499893188, Accuracy: 0.626953125\n",
      "Batch: 96, Loss: 1.1114437580108643, Accuracy: 0.6494140625\n",
      "Batch: 97, Loss: 0.9621587991714478, Accuracy: 0.6806640625\n",
      "Batch: 98, Loss: 1.028969407081604, Accuracy: 0.67578125\n",
      "Batch: 99, Loss: 1.0269556045532227, Accuracy: 0.6640625\n",
      "Batch: 100, Loss: 1.1003367900848389, Accuracy: 0.6513671875\n",
      "Batch: 101, Loss: 1.1791528463363647, Accuracy: 0.607421875\n",
      "Batch: 102, Loss: 1.06124746799469, Accuracy: 0.6416015625\n",
      "Batch: 103, Loss: 1.1352252960205078, Accuracy: 0.6552734375\n",
      "Batch: 104, Loss: 1.0347950458526611, Accuracy: 0.6728515625\n",
      "Batch: 105, Loss: 1.1576216220855713, Accuracy: 0.62109375\n",
      "Batch: 106, Loss: 1.1448979377746582, Accuracy: 0.6484375\n",
      "Batch: 107, Loss: 1.2358672618865967, Accuracy: 0.6044921875\n",
      "Batch: 108, Loss: 1.1543394327163696, Accuracy: 0.62109375\n",
      "Batch: 109, Loss: 1.2679541110992432, Accuracy: 0.5830078125\n",
      "Batch: 110, Loss: 0.9711884260177612, Accuracy: 0.6796875\n",
      "Batch: 111, Loss: 1.1694532632827759, Accuracy: 0.615234375\n",
      "Batch: 112, Loss: 1.1130236387252808, Accuracy: 0.6455078125\n",
      "Batch: 113, Loss: 1.1253622770309448, Accuracy: 0.6494140625\n",
      "Batch: 114, Loss: 1.2611339092254639, Accuracy: 0.5986328125\n",
      "Batch: 115, Loss: 1.263231873512268, Accuracy: 0.611328125\n",
      "Batch: 116, Loss: 1.1965374946594238, Accuracy: 0.611328125\n",
      "Batch: 117, Loss: 1.1966667175292969, Accuracy: 0.619140625\n",
      "Batch: 118, Loss: 1.0010844469070435, Accuracy: 0.677734375\n",
      "Batch: 119, Loss: 1.0055936574935913, Accuracy: 0.6826171875\n",
      "Batch: 120, Loss: 1.1461021900177002, Accuracy: 0.6171875\n",
      "Batch: 121, Loss: 1.2198374271392822, Accuracy: 0.6201171875\n",
      "Batch: 122, Loss: 1.115633487701416, Accuracy: 0.6474609375\n",
      "Batch: 123, Loss: 1.0895793437957764, Accuracy: 0.6572265625\n",
      "Batch: 124, Loss: 1.141904354095459, Accuracy: 0.6337890625\n",
      "Batch: 125, Loss: 1.1812164783477783, Accuracy: 0.6162109375\n",
      "Batch: 126, Loss: 1.1699405908584595, Accuracy: 0.6142578125\n",
      "Batch: 127, Loss: 1.0240600109100342, Accuracy: 0.681640625\n",
      "Batch: 128, Loss: 1.2449562549591064, Accuracy: 0.6201171875\n",
      "Batch: 129, Loss: 1.1007674932479858, Accuracy: 0.638671875\n",
      "Batch: 130, Loss: 1.2684168815612793, Accuracy: 0.5947265625\n",
      "Batch: 131, Loss: 1.1724560260772705, Accuracy: 0.625\n",
      "Batch: 132, Loss: 1.211578369140625, Accuracy: 0.6171875\n",
      "Batch: 133, Loss: 1.0782885551452637, Accuracy: 0.6455078125\n",
      "Batch: 134, Loss: 1.1472432613372803, Accuracy: 0.6396484375\n",
      "Batch: 135, Loss: 1.053361177444458, Accuracy: 0.66796875\n",
      "Batch: 136, Loss: 1.1229026317596436, Accuracy: 0.6494140625\n",
      "Batch: 137, Loss: 1.0557976961135864, Accuracy: 0.6484375\n",
      "Batch: 138, Loss: 0.936315655708313, Accuracy: 0.6806640625\n",
      "Batch: 139, Loss: 1.0101439952850342, Accuracy: 0.6435546875\n",
      "Batch: 140, Loss: 1.0884597301483154, Accuracy: 0.63671875\n",
      "Batch: 141, Loss: 1.1696312427520752, Accuracy: 0.626953125\n",
      "Batch: 142, Loss: 1.1712727546691895, Accuracy: 0.6201171875\n",
      "Batch: 143, Loss: 1.1491872072219849, Accuracy: 0.6259765625\n",
      "Batch: 144, Loss: 1.1438732147216797, Accuracy: 0.63671875\n",
      "Batch: 145, Loss: 1.0869158506393433, Accuracy: 0.62109375\n",
      "Batch: 146, Loss: 1.1706228256225586, Accuracy: 0.611328125\n",
      "Batch: 147, Loss: 1.1433945894241333, Accuracy: 0.626953125\n",
      "Batch: 148, Loss: 1.2648086547851562, Accuracy: 0.56640625\n",
      "Batch: 149, Loss: 1.1454832553863525, Accuracy: 0.623046875\n",
      "Batch: 150, Loss: 1.0603201389312744, Accuracy: 0.6435546875\n",
      "Batch: 151, Loss: 0.9909958243370056, Accuracy: 0.6943359375\n",
      "Epoch 13/90\n",
      "Batch: 1, Loss: 1.4008420705795288, Accuracy: 0.55078125\n",
      "Batch: 2, Loss: 1.1935707330703735, Accuracy: 0.59375\n",
      "Batch: 3, Loss: 1.044204592704773, Accuracy: 0.666015625\n",
      "Batch: 4, Loss: 0.9690190553665161, Accuracy: 0.6904296875\n",
      "Batch: 5, Loss: 1.0246418714523315, Accuracy: 0.6708984375\n",
      "Batch: 6, Loss: 1.1097584962844849, Accuracy: 0.6357421875\n",
      "Batch: 7, Loss: 1.0796637535095215, Accuracy: 0.6396484375\n",
      "Batch: 8, Loss: 1.043122410774231, Accuracy: 0.66015625\n",
      "Batch: 9, Loss: 0.9802913665771484, Accuracy: 0.68359375\n",
      "Batch: 10, Loss: 1.0065726041793823, Accuracy: 0.66796875\n",
      "Batch: 11, Loss: 1.1983586549758911, Accuracy: 0.6064453125\n",
      "Batch: 12, Loss: 1.2251105308532715, Accuracy: 0.6015625\n",
      "Batch: 13, Loss: 0.9301909804344177, Accuracy: 0.6865234375\n",
      "Batch: 14, Loss: 1.185006856918335, Accuracy: 0.61328125\n",
      "Batch: 15, Loss: 1.0244653224945068, Accuracy: 0.6865234375\n",
      "Batch: 16, Loss: 1.023517370223999, Accuracy: 0.68359375\n",
      "Batch: 17, Loss: 1.1577743291854858, Accuracy: 0.6279296875\n",
      "Batch: 18, Loss: 1.1324775218963623, Accuracy: 0.6318359375\n",
      "Batch: 19, Loss: 1.2061299085617065, Accuracy: 0.61328125\n",
      "Batch: 20, Loss: 1.0691883563995361, Accuracy: 0.650390625\n",
      "Batch: 21, Loss: 1.043332815170288, Accuracy: 0.6591796875\n",
      "Batch: 22, Loss: 1.1926225423812866, Accuracy: 0.6123046875\n",
      "Batch: 23, Loss: 1.0736700296401978, Accuracy: 0.6376953125\n",
      "Batch: 24, Loss: 1.086724042892456, Accuracy: 0.6416015625\n",
      "Batch: 25, Loss: 1.095965027809143, Accuracy: 0.6416015625\n",
      "Batch: 26, Loss: 0.9961641430854797, Accuracy: 0.6796875\n",
      "Batch: 27, Loss: 1.0205841064453125, Accuracy: 0.65625\n",
      "Batch: 28, Loss: 1.1355582475662231, Accuracy: 0.611328125\n",
      "Batch: 29, Loss: 1.1175742149353027, Accuracy: 0.623046875\n",
      "Batch: 30, Loss: 1.0700533390045166, Accuracy: 0.6552734375\n",
      "Batch: 31, Loss: 1.0253889560699463, Accuracy: 0.6728515625\n",
      "Batch: 32, Loss: 0.985834538936615, Accuracy: 0.666015625\n",
      "Batch: 33, Loss: 1.205195426940918, Accuracy: 0.6025390625\n",
      "Batch: 34, Loss: 1.2528482675552368, Accuracy: 0.6044921875\n",
      "Batch: 35, Loss: 1.156430959701538, Accuracy: 0.6181640625\n",
      "Batch: 36, Loss: 1.146291971206665, Accuracy: 0.65625\n",
      "Batch: 37, Loss: 1.1003309488296509, Accuracy: 0.62890625\n",
      "Batch: 38, Loss: 1.1141849756240845, Accuracy: 0.63671875\n",
      "Batch: 39, Loss: 1.1339733600616455, Accuracy: 0.6435546875\n",
      "Batch: 40, Loss: 1.1467533111572266, Accuracy: 0.64453125\n",
      "Batch: 41, Loss: 1.1265348196029663, Accuracy: 0.6474609375\n",
      "Batch: 42, Loss: 0.9094940423965454, Accuracy: 0.6923828125\n",
      "Batch: 43, Loss: 1.1254634857177734, Accuracy: 0.6240234375\n",
      "Batch: 44, Loss: 1.1053118705749512, Accuracy: 0.626953125\n",
      "Batch: 45, Loss: 0.9693644046783447, Accuracy: 0.6689453125\n",
      "Batch: 46, Loss: 1.104099988937378, Accuracy: 0.66796875\n",
      "Batch: 47, Loss: 1.0873658657073975, Accuracy: 0.654296875\n",
      "Batch: 48, Loss: 1.0361747741699219, Accuracy: 0.6591796875\n",
      "Batch: 49, Loss: 1.221158742904663, Accuracy: 0.5947265625\n",
      "Batch: 50, Loss: 1.1774468421936035, Accuracy: 0.626953125\n",
      "Batch: 51, Loss: 1.2220916748046875, Accuracy: 0.5966796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 52, Loss: 1.1749587059020996, Accuracy: 0.6318359375\n",
      "Batch: 53, Loss: 0.9947548508644104, Accuracy: 0.6640625\n",
      "Batch: 54, Loss: 1.0761536359786987, Accuracy: 0.65234375\n",
      "Batch: 55, Loss: 1.1447796821594238, Accuracy: 0.607421875\n",
      "Batch: 56, Loss: 1.1509943008422852, Accuracy: 0.6318359375\n",
      "Batch: 57, Loss: 1.0799094438552856, Accuracy: 0.6484375\n",
      "Batch: 58, Loss: 1.185246229171753, Accuracy: 0.64453125\n",
      "Batch: 59, Loss: 1.0103824138641357, Accuracy: 0.6982421875\n",
      "Batch: 60, Loss: 1.0088921785354614, Accuracy: 0.6865234375\n",
      "Batch: 61, Loss: 1.1222091913223267, Accuracy: 0.63671875\n",
      "Batch: 62, Loss: 1.0846432447433472, Accuracy: 0.6513671875\n",
      "Batch: 63, Loss: 1.0939388275146484, Accuracy: 0.6435546875\n",
      "Batch: 64, Loss: 1.0604121685028076, Accuracy: 0.6474609375\n",
      "Batch: 65, Loss: 1.1236822605133057, Accuracy: 0.65234375\n",
      "Batch: 66, Loss: 1.0256152153015137, Accuracy: 0.6806640625\n",
      "Batch: 67, Loss: 1.179464340209961, Accuracy: 0.623046875\n",
      "Batch: 68, Loss: 1.1913609504699707, Accuracy: 0.6435546875\n",
      "Batch: 69, Loss: 1.1118571758270264, Accuracy: 0.6396484375\n",
      "Batch: 70, Loss: 1.1197385787963867, Accuracy: 0.6416015625\n",
      "Batch: 71, Loss: 1.1335564851760864, Accuracy: 0.6328125\n",
      "Batch: 72, Loss: 0.9912186861038208, Accuracy: 0.6787109375\n",
      "Batch: 73, Loss: 1.044792652130127, Accuracy: 0.666015625\n",
      "Batch: 74, Loss: 1.036624550819397, Accuracy: 0.66015625\n",
      "Batch: 75, Loss: 0.9961466789245605, Accuracy: 0.6865234375\n",
      "Batch: 76, Loss: 1.119362235069275, Accuracy: 0.6298828125\n",
      "Batch: 77, Loss: 1.0670230388641357, Accuracy: 0.6669921875\n",
      "Batch: 78, Loss: 1.0784492492675781, Accuracy: 0.666015625\n",
      "Batch: 79, Loss: 0.9799688458442688, Accuracy: 0.7021484375\n",
      "Batch: 80, Loss: 1.021620273590088, Accuracy: 0.6611328125\n",
      "Batch: 81, Loss: 1.2034516334533691, Accuracy: 0.5986328125\n",
      "Batch: 82, Loss: 1.1494696140289307, Accuracy: 0.6201171875\n",
      "Batch: 83, Loss: 0.992002546787262, Accuracy: 0.6923828125\n",
      "Batch: 84, Loss: 1.0408222675323486, Accuracy: 0.6748046875\n",
      "Batch: 85, Loss: 0.9898637533187866, Accuracy: 0.68359375\n",
      "Batch: 86, Loss: 1.2432243824005127, Accuracy: 0.5947265625\n",
      "Batch: 87, Loss: 1.0328680276870728, Accuracy: 0.671875\n",
      "Batch: 88, Loss: 1.1640887260437012, Accuracy: 0.64453125\n",
      "Batch: 89, Loss: 1.1606916189193726, Accuracy: 0.634765625\n",
      "Batch: 90, Loss: 1.0125268697738647, Accuracy: 0.669921875\n",
      "Batch: 91, Loss: 1.0628626346588135, Accuracy: 0.6611328125\n",
      "Batch: 92, Loss: 1.114389181137085, Accuracy: 0.638671875\n",
      "Batch: 93, Loss: 1.029139757156372, Accuracy: 0.671875\n",
      "Batch: 94, Loss: 1.0504347085952759, Accuracy: 0.654296875\n",
      "Batch: 95, Loss: 1.106902837753296, Accuracy: 0.6396484375\n",
      "Batch: 96, Loss: 1.0802552700042725, Accuracy: 0.65234375\n",
      "Batch: 97, Loss: 0.9512803554534912, Accuracy: 0.6865234375\n",
      "Batch: 98, Loss: 0.9780232906341553, Accuracy: 0.6923828125\n",
      "Batch: 99, Loss: 0.9936774373054504, Accuracy: 0.677734375\n",
      "Batch: 100, Loss: 1.077928066253662, Accuracy: 0.654296875\n",
      "Batch: 101, Loss: 1.127145767211914, Accuracy: 0.650390625\n",
      "Batch: 102, Loss: 1.0157067775726318, Accuracy: 0.6572265625\n",
      "Batch: 103, Loss: 1.1233046054840088, Accuracy: 0.6640625\n",
      "Batch: 104, Loss: 1.042330265045166, Accuracy: 0.6669921875\n",
      "Batch: 105, Loss: 1.1229122877120972, Accuracy: 0.638671875\n",
      "Batch: 106, Loss: 1.0737464427947998, Accuracy: 0.6513671875\n",
      "Batch: 107, Loss: 1.13969886302948, Accuracy: 0.6220703125\n",
      "Batch: 108, Loss: 1.121505618095398, Accuracy: 0.6240234375\n",
      "Batch: 109, Loss: 1.2458949089050293, Accuracy: 0.59765625\n",
      "Batch: 110, Loss: 0.917914092540741, Accuracy: 0.6923828125\n",
      "Batch: 111, Loss: 1.1312949657440186, Accuracy: 0.6279296875\n",
      "Batch: 112, Loss: 1.1081724166870117, Accuracy: 0.654296875\n",
      "Batch: 113, Loss: 1.1041691303253174, Accuracy: 0.666015625\n",
      "Batch: 114, Loss: 1.2158775329589844, Accuracy: 0.6123046875\n",
      "Batch: 115, Loss: 1.2238407135009766, Accuracy: 0.623046875\n",
      "Batch: 116, Loss: 1.1406135559082031, Accuracy: 0.630859375\n",
      "Batch: 117, Loss: 1.1730613708496094, Accuracy: 0.615234375\n",
      "Batch: 118, Loss: 0.9693986773490906, Accuracy: 0.6875\n",
      "Batch: 119, Loss: 0.97021484375, Accuracy: 0.6904296875\n",
      "Batch: 120, Loss: 1.090914249420166, Accuracy: 0.65234375\n",
      "Batch: 121, Loss: 1.1511151790618896, Accuracy: 0.630859375\n",
      "Batch: 122, Loss: 1.077093482017517, Accuracy: 0.6591796875\n",
      "Batch: 123, Loss: 1.046533226966858, Accuracy: 0.669921875\n",
      "Batch: 124, Loss: 1.0991508960723877, Accuracy: 0.642578125\n",
      "Batch: 125, Loss: 1.1269474029541016, Accuracy: 0.642578125\n",
      "Batch: 126, Loss: 1.1518925428390503, Accuracy: 0.6103515625\n",
      "Batch: 127, Loss: 1.01442551612854, Accuracy: 0.6806640625\n",
      "Batch: 128, Loss: 1.2057034969329834, Accuracy: 0.626953125\n",
      "Batch: 129, Loss: 1.0312601327896118, Accuracy: 0.671875\n",
      "Batch: 130, Loss: 1.2863399982452393, Accuracy: 0.578125\n",
      "Batch: 131, Loss: 1.1683238744735718, Accuracy: 0.6259765625\n",
      "Batch: 132, Loss: 1.1764386892318726, Accuracy: 0.619140625\n",
      "Batch: 133, Loss: 1.0296629667282104, Accuracy: 0.6650390625\n",
      "Batch: 134, Loss: 1.1193640232086182, Accuracy: 0.6318359375\n",
      "Batch: 135, Loss: 1.0400482416152954, Accuracy: 0.6748046875\n",
      "Batch: 136, Loss: 1.0793145895004272, Accuracy: 0.658203125\n",
      "Batch: 137, Loss: 1.0019454956054688, Accuracy: 0.65625\n",
      "Batch: 138, Loss: 0.8975118398666382, Accuracy: 0.6904296875\n",
      "Batch: 139, Loss: 0.9796444177627563, Accuracy: 0.662109375\n",
      "Batch: 140, Loss: 1.0810320377349854, Accuracy: 0.6396484375\n",
      "Batch: 141, Loss: 1.115682601928711, Accuracy: 0.6396484375\n",
      "Batch: 142, Loss: 1.1680679321289062, Accuracy: 0.625\n",
      "Batch: 143, Loss: 1.1304056644439697, Accuracy: 0.6337890625\n",
      "Batch: 144, Loss: 1.1000051498413086, Accuracy: 0.6455078125\n",
      "Batch: 145, Loss: 1.0415387153625488, Accuracy: 0.6357421875\n",
      "Batch: 146, Loss: 1.1556320190429688, Accuracy: 0.6083984375\n",
      "Batch: 147, Loss: 1.1168056726455688, Accuracy: 0.642578125\n",
      "Batch: 148, Loss: 1.2368643283843994, Accuracy: 0.5888671875\n",
      "Batch: 149, Loss: 1.1072778701782227, Accuracy: 0.6318359375\n",
      "Batch: 150, Loss: 1.0131574869155884, Accuracy: 0.6796875\n",
      "Batch: 151, Loss: 0.9497126340866089, Accuracy: 0.701171875\n",
      "Epoch 14/90\n",
      "Batch: 1, Loss: 1.3445427417755127, Accuracy: 0.5634765625\n",
      "Batch: 2, Loss: 1.1417653560638428, Accuracy: 0.6083984375\n",
      "Batch: 3, Loss: 1.0324125289916992, Accuracy: 0.6552734375\n",
      "Batch: 4, Loss: 0.9577707052230835, Accuracy: 0.6923828125\n",
      "Batch: 5, Loss: 0.992429256439209, Accuracy: 0.6767578125\n",
      "Batch: 6, Loss: 1.0726110935211182, Accuracy: 0.62890625\n",
      "Batch: 7, Loss: 1.0491485595703125, Accuracy: 0.6396484375\n",
      "Batch: 8, Loss: 1.0248057842254639, Accuracy: 0.66015625\n",
      "Batch: 9, Loss: 0.9408700466156006, Accuracy: 0.7041015625\n",
      "Batch: 10, Loss: 0.9855529069900513, Accuracy: 0.6845703125\n",
      "Batch: 11, Loss: 1.1882113218307495, Accuracy: 0.6123046875\n",
      "Batch: 12, Loss: 1.1824374198913574, Accuracy: 0.607421875\n",
      "Batch: 13, Loss: 0.9106661677360535, Accuracy: 0.7060546875\n",
      "Batch: 14, Loss: 1.1675498485565186, Accuracy: 0.6220703125\n",
      "Batch: 15, Loss: 0.9994868040084839, Accuracy: 0.68359375\n",
      "Batch: 16, Loss: 1.0106923580169678, Accuracy: 0.6708984375\n",
      "Batch: 17, Loss: 1.1278414726257324, Accuracy: 0.6376953125\n",
      "Batch: 18, Loss: 1.0911656618118286, Accuracy: 0.63671875\n",
      "Batch: 19, Loss: 1.153191089630127, Accuracy: 0.634765625\n",
      "Batch: 20, Loss: 1.0206559896469116, Accuracy: 0.6787109375\n",
      "Batch: 21, Loss: 1.0263153314590454, Accuracy: 0.66015625\n",
      "Batch: 22, Loss: 1.1270408630371094, Accuracy: 0.6416015625\n",
      "Batch: 23, Loss: 1.0457310676574707, Accuracy: 0.65234375\n",
      "Batch: 24, Loss: 1.0585893392562866, Accuracy: 0.6396484375\n",
      "Batch: 25, Loss: 1.0464074611663818, Accuracy: 0.65234375\n",
      "Batch: 26, Loss: 0.944158136844635, Accuracy: 0.6845703125\n",
      "Batch: 27, Loss: 0.9932384490966797, Accuracy: 0.662109375\n",
      "Batch: 28, Loss: 1.1097354888916016, Accuracy: 0.615234375\n",
      "Batch: 29, Loss: 1.0728778839111328, Accuracy: 0.6494140625\n",
      "Batch: 30, Loss: 1.0370925664901733, Accuracy: 0.669921875\n",
      "Batch: 31, Loss: 1.022183895111084, Accuracy: 0.6689453125\n",
      "Batch: 32, Loss: 0.9836901426315308, Accuracy: 0.6787109375\n",
      "Batch: 33, Loss: 1.161588191986084, Accuracy: 0.6103515625\n",
      "Batch: 34, Loss: 1.224884033203125, Accuracy: 0.6103515625\n",
      "Batch: 35, Loss: 1.099395751953125, Accuracy: 0.6376953125\n",
      "Batch: 36, Loss: 1.1217665672302246, Accuracy: 0.6533203125\n",
      "Batch: 37, Loss: 1.072662115097046, Accuracy: 0.6533203125\n",
      "Batch: 38, Loss: 1.1095311641693115, Accuracy: 0.6279296875\n",
      "Batch: 39, Loss: 1.0961427688598633, Accuracy: 0.64453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 40, Loss: 1.1050981283187866, Accuracy: 0.6552734375\n",
      "Batch: 41, Loss: 1.0832940340042114, Accuracy: 0.654296875\n",
      "Batch: 42, Loss: 0.8769487738609314, Accuracy: 0.708984375\n",
      "Batch: 43, Loss: 1.0651462078094482, Accuracy: 0.6474609375\n",
      "Batch: 44, Loss: 1.0832710266113281, Accuracy: 0.6220703125\n",
      "Batch: 45, Loss: 0.9443143606185913, Accuracy: 0.6826171875\n",
      "Batch: 46, Loss: 1.0557518005371094, Accuracy: 0.67578125\n",
      "Batch: 47, Loss: 1.0298514366149902, Accuracy: 0.6708984375\n",
      "Batch: 48, Loss: 0.9998729228973389, Accuracy: 0.6728515625\n",
      "Batch: 49, Loss: 1.165963888168335, Accuracy: 0.6142578125\n",
      "Batch: 50, Loss: 1.1490106582641602, Accuracy: 0.6181640625\n",
      "Batch: 51, Loss: 1.20579195022583, Accuracy: 0.615234375\n",
      "Batch: 52, Loss: 1.1625280380249023, Accuracy: 0.6279296875\n",
      "Batch: 53, Loss: 0.9586189985275269, Accuracy: 0.669921875\n",
      "Batch: 54, Loss: 1.050620198249817, Accuracy: 0.65625\n",
      "Batch: 55, Loss: 1.1287554502487183, Accuracy: 0.619140625\n",
      "Batch: 56, Loss: 1.1241333484649658, Accuracy: 0.640625\n",
      "Batch: 57, Loss: 1.0503511428833008, Accuracy: 0.6669921875\n",
      "Batch: 58, Loss: 1.1458091735839844, Accuracy: 0.6494140625\n",
      "Batch: 59, Loss: 1.0038487911224365, Accuracy: 0.7041015625\n",
      "Batch: 60, Loss: 0.96735018491745, Accuracy: 0.6982421875\n",
      "Batch: 61, Loss: 1.0838369131088257, Accuracy: 0.654296875\n",
      "Batch: 62, Loss: 1.0445647239685059, Accuracy: 0.6533203125\n",
      "Batch: 63, Loss: 1.0881602764129639, Accuracy: 0.658203125\n",
      "Batch: 64, Loss: 1.0682084560394287, Accuracy: 0.646484375\n",
      "Batch: 65, Loss: 1.087967872619629, Accuracy: 0.6494140625\n",
      "Batch: 66, Loss: 1.0176191329956055, Accuracy: 0.67578125\n",
      "Batch: 67, Loss: 1.1426843404769897, Accuracy: 0.6318359375\n",
      "Batch: 68, Loss: 1.1652722358703613, Accuracy: 0.654296875\n",
      "Batch: 69, Loss: 1.0935578346252441, Accuracy: 0.6474609375\n",
      "Batch: 70, Loss: 1.0903520584106445, Accuracy: 0.66015625\n",
      "Batch: 71, Loss: 1.1052794456481934, Accuracy: 0.638671875\n",
      "Batch: 72, Loss: 0.9715960025787354, Accuracy: 0.677734375\n",
      "Batch: 73, Loss: 1.0267207622528076, Accuracy: 0.673828125\n",
      "Batch: 74, Loss: 1.0135109424591064, Accuracy: 0.6650390625\n",
      "Batch: 75, Loss: 0.9557863473892212, Accuracy: 0.6884765625\n",
      "Batch: 76, Loss: 1.0721397399902344, Accuracy: 0.634765625\n",
      "Batch: 77, Loss: 1.0507447719573975, Accuracy: 0.6484375\n",
      "Batch: 78, Loss: 1.0266268253326416, Accuracy: 0.6787109375\n",
      "Batch: 79, Loss: 0.953217625617981, Accuracy: 0.7021484375\n",
      "Batch: 80, Loss: 1.0222783088684082, Accuracy: 0.65234375\n",
      "Batch: 81, Loss: 1.1790649890899658, Accuracy: 0.6103515625\n",
      "Batch: 82, Loss: 1.117724061012268, Accuracy: 0.6396484375\n",
      "Batch: 83, Loss: 0.9677948951721191, Accuracy: 0.6884765625\n",
      "Batch: 84, Loss: 1.02239191532135, Accuracy: 0.685546875\n",
      "Batch: 85, Loss: 0.9610249996185303, Accuracy: 0.69140625\n",
      "Batch: 86, Loss: 1.2145458459854126, Accuracy: 0.6181640625\n",
      "Batch: 87, Loss: 0.9915682077407837, Accuracy: 0.703125\n",
      "Batch: 88, Loss: 1.1260883808135986, Accuracy: 0.662109375\n",
      "Batch: 89, Loss: 1.1171505451202393, Accuracy: 0.6416015625\n",
      "Batch: 90, Loss: 1.0036675930023193, Accuracy: 0.6748046875\n",
      "Batch: 91, Loss: 1.0653742551803589, Accuracy: 0.650390625\n",
      "Batch: 92, Loss: 1.0788111686706543, Accuracy: 0.6611328125\n",
      "Batch: 93, Loss: 1.0024311542510986, Accuracy: 0.66796875\n",
      "Batch: 94, Loss: 1.0391087532043457, Accuracy: 0.654296875\n",
      "Batch: 95, Loss: 1.0602781772613525, Accuracy: 0.6552734375\n",
      "Batch: 96, Loss: 1.0487914085388184, Accuracy: 0.66796875\n",
      "Batch: 97, Loss: 0.9061887264251709, Accuracy: 0.7001953125\n",
      "Batch: 98, Loss: 0.9590559601783752, Accuracy: 0.69921875\n",
      "Batch: 99, Loss: 0.9875348806381226, Accuracy: 0.6787109375\n",
      "Batch: 100, Loss: 1.0556178092956543, Accuracy: 0.6669921875\n",
      "Batch: 101, Loss: 1.1125296354293823, Accuracy: 0.6396484375\n",
      "Batch: 102, Loss: 1.0108168125152588, Accuracy: 0.6669921875\n",
      "Batch: 103, Loss: 1.0884807109832764, Accuracy: 0.6640625\n",
      "Batch: 104, Loss: 0.9922319650650024, Accuracy: 0.6865234375\n",
      "Batch: 105, Loss: 1.0972343683242798, Accuracy: 0.650390625\n",
      "Batch: 106, Loss: 1.0527944564819336, Accuracy: 0.6533203125\n",
      "Batch: 107, Loss: 1.1362767219543457, Accuracy: 0.6376953125\n",
      "Batch: 108, Loss: 1.0657756328582764, Accuracy: 0.6416015625\n",
      "Batch: 109, Loss: 1.201735258102417, Accuracy: 0.5966796875\n",
      "Batch: 110, Loss: 0.8786025047302246, Accuracy: 0.7109375\n",
      "Batch: 111, Loss: 1.107481598854065, Accuracy: 0.6376953125\n",
      "Batch: 112, Loss: 1.042583703994751, Accuracy: 0.6611328125\n",
      "Batch: 113, Loss: 1.0680670738220215, Accuracy: 0.673828125\n",
      "Batch: 114, Loss: 1.1646828651428223, Accuracy: 0.626953125\n",
      "Batch: 115, Loss: 1.195845603942871, Accuracy: 0.6220703125\n",
      "Batch: 116, Loss: 1.1240851879119873, Accuracy: 0.65234375\n",
      "Batch: 117, Loss: 1.128448486328125, Accuracy: 0.6357421875\n",
      "Batch: 118, Loss: 0.93547123670578, Accuracy: 0.70703125\n",
      "Batch: 119, Loss: 0.941797137260437, Accuracy: 0.705078125\n",
      "Batch: 120, Loss: 1.1100847721099854, Accuracy: 0.6357421875\n",
      "Batch: 121, Loss: 1.1314475536346436, Accuracy: 0.6396484375\n",
      "Batch: 122, Loss: 1.0524169206619263, Accuracy: 0.6748046875\n",
      "Batch: 123, Loss: 1.0369784832000732, Accuracy: 0.6708984375\n",
      "Batch: 124, Loss: 1.0996153354644775, Accuracy: 0.6474609375\n",
      "Batch: 125, Loss: 1.104180932044983, Accuracy: 0.6328125\n",
      "Batch: 126, Loss: 1.083522081375122, Accuracy: 0.6455078125\n",
      "Batch: 127, Loss: 0.9635621309280396, Accuracy: 0.7099609375\n",
      "Batch: 128, Loss: 1.1822181940078735, Accuracy: 0.6328125\n",
      "Batch: 129, Loss: 1.0533121824264526, Accuracy: 0.6572265625\n",
      "Batch: 130, Loss: 1.230987548828125, Accuracy: 0.595703125\n",
      "Batch: 131, Loss: 1.1232383251190186, Accuracy: 0.638671875\n",
      "Batch: 132, Loss: 1.1656643152236938, Accuracy: 0.6142578125\n",
      "Batch: 133, Loss: 0.9972496628761292, Accuracy: 0.6494140625\n",
      "Batch: 134, Loss: 1.0921510457992554, Accuracy: 0.638671875\n",
      "Batch: 135, Loss: 0.9825806617736816, Accuracy: 0.6796875\n",
      "Batch: 136, Loss: 1.0652992725372314, Accuracy: 0.6640625\n",
      "Batch: 137, Loss: 0.9900009036064148, Accuracy: 0.658203125\n",
      "Batch: 138, Loss: 0.8856184482574463, Accuracy: 0.6904296875\n",
      "Batch: 139, Loss: 0.9486755132675171, Accuracy: 0.6865234375\n",
      "Batch: 140, Loss: 1.0441794395446777, Accuracy: 0.65234375\n",
      "Batch: 141, Loss: 1.0976555347442627, Accuracy: 0.654296875\n",
      "Batch: 142, Loss: 1.1196391582489014, Accuracy: 0.6376953125\n",
      "Batch: 143, Loss: 1.0870710611343384, Accuracy: 0.6484375\n",
      "Batch: 144, Loss: 1.0721112489700317, Accuracy: 0.6650390625\n",
      "Batch: 145, Loss: 1.0232630968093872, Accuracy: 0.6474609375\n",
      "Batch: 146, Loss: 1.1136574745178223, Accuracy: 0.6337890625\n",
      "Batch: 147, Loss: 1.0884170532226562, Accuracy: 0.64453125\n",
      "Batch: 148, Loss: 1.2264803647994995, Accuracy: 0.5869140625\n",
      "Batch: 149, Loss: 1.065117597579956, Accuracy: 0.6357421875\n",
      "Batch: 150, Loss: 1.000708818435669, Accuracy: 0.662109375\n",
      "Batch: 151, Loss: 0.9259235858917236, Accuracy: 0.7021484375\n",
      "Epoch 15/90\n",
      "Batch: 1, Loss: 1.3303594589233398, Accuracy: 0.5732421875\n",
      "Batch: 2, Loss: 1.1137828826904297, Accuracy: 0.62109375\n",
      "Batch: 3, Loss: 0.9799755811691284, Accuracy: 0.673828125\n",
      "Batch: 4, Loss: 0.9167019724845886, Accuracy: 0.7119140625\n",
      "Batch: 5, Loss: 0.9699775576591492, Accuracy: 0.6884765625\n",
      "Batch: 6, Loss: 1.0430482625961304, Accuracy: 0.650390625\n",
      "Batch: 7, Loss: 1.04557466506958, Accuracy: 0.66015625\n",
      "Batch: 8, Loss: 0.9939270615577698, Accuracy: 0.666015625\n",
      "Batch: 9, Loss: 0.93923020362854, Accuracy: 0.693359375\n",
      "Batch: 10, Loss: 0.961938738822937, Accuracy: 0.6962890625\n",
      "Batch: 11, Loss: 1.1459845304489136, Accuracy: 0.623046875\n",
      "Batch: 12, Loss: 1.1466952562332153, Accuracy: 0.6337890625\n",
      "Batch: 13, Loss: 0.8856552243232727, Accuracy: 0.7021484375\n",
      "Batch: 14, Loss: 1.145484209060669, Accuracy: 0.62109375\n",
      "Batch: 15, Loss: 0.9762749075889587, Accuracy: 0.6904296875\n",
      "Batch: 16, Loss: 0.9890941381454468, Accuracy: 0.685546875\n",
      "Batch: 17, Loss: 1.0626888275146484, Accuracy: 0.650390625\n",
      "Batch: 18, Loss: 1.082532286643982, Accuracy: 0.642578125\n",
      "Batch: 19, Loss: 1.1487863063812256, Accuracy: 0.6298828125\n",
      "Batch: 20, Loss: 0.9982201457023621, Accuracy: 0.6826171875\n",
      "Batch: 21, Loss: 0.9979228377342224, Accuracy: 0.6767578125\n",
      "Batch: 22, Loss: 1.1166574954986572, Accuracy: 0.6435546875\n",
      "Batch: 23, Loss: 1.0207321643829346, Accuracy: 0.65625\n",
      "Batch: 24, Loss: 1.0356700420379639, Accuracy: 0.6640625\n",
      "Batch: 25, Loss: 1.0386667251586914, Accuracy: 0.666015625\n",
      "Batch: 26, Loss: 0.9110665321350098, Accuracy: 0.69921875\n",
      "Batch: 27, Loss: 0.9664669632911682, Accuracy: 0.6630859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 28, Loss: 1.0662260055541992, Accuracy: 0.634765625\n",
      "Batch: 29, Loss: 1.0723941326141357, Accuracy: 0.64453125\n",
      "Batch: 30, Loss: 0.9985161423683167, Accuracy: 0.6875\n",
      "Batch: 31, Loss: 0.9642906188964844, Accuracy: 0.6796875\n",
      "Batch: 32, Loss: 0.9511657953262329, Accuracy: 0.693359375\n",
      "Batch: 33, Loss: 1.1084556579589844, Accuracy: 0.646484375\n",
      "Batch: 34, Loss: 1.1850272417068481, Accuracy: 0.630859375\n",
      "Batch: 35, Loss: 1.0753332376480103, Accuracy: 0.640625\n",
      "Batch: 36, Loss: 1.0805785655975342, Accuracy: 0.65625\n",
      "Batch: 37, Loss: 1.035205602645874, Accuracy: 0.6572265625\n",
      "Batch: 38, Loss: 1.066462755203247, Accuracy: 0.638671875\n",
      "Batch: 39, Loss: 1.0586249828338623, Accuracy: 0.654296875\n",
      "Batch: 40, Loss: 1.0867167711257935, Accuracy: 0.6552734375\n",
      "Batch: 41, Loss: 1.0380215644836426, Accuracy: 0.673828125\n",
      "Batch: 42, Loss: 0.8381588459014893, Accuracy: 0.72265625\n",
      "Batch: 43, Loss: 1.081039547920227, Accuracy: 0.6474609375\n",
      "Batch: 44, Loss: 1.0610665082931519, Accuracy: 0.6396484375\n",
      "Batch: 45, Loss: 0.9273443222045898, Accuracy: 0.6982421875\n",
      "Batch: 46, Loss: 1.0179575681686401, Accuracy: 0.6591796875\n",
      "Batch: 47, Loss: 1.017181396484375, Accuracy: 0.6845703125\n",
      "Batch: 48, Loss: 0.9603999257087708, Accuracy: 0.685546875\n",
      "Batch: 49, Loss: 1.1619176864624023, Accuracy: 0.62890625\n",
      "Batch: 50, Loss: 1.1223604679107666, Accuracy: 0.64453125\n",
      "Batch: 51, Loss: 1.1800472736358643, Accuracy: 0.6171875\n",
      "Batch: 52, Loss: 1.1163995265960693, Accuracy: 0.6455078125\n",
      "Batch: 53, Loss: 0.9577779769897461, Accuracy: 0.671875\n",
      "Batch: 54, Loss: 1.0307971239089966, Accuracy: 0.6748046875\n",
      "Batch: 55, Loss: 1.1034002304077148, Accuracy: 0.6259765625\n",
      "Batch: 56, Loss: 1.0664993524551392, Accuracy: 0.669921875\n",
      "Batch: 57, Loss: 1.0341719388961792, Accuracy: 0.6640625\n",
      "Batch: 58, Loss: 1.120471477508545, Accuracy: 0.6689453125\n",
      "Batch: 59, Loss: 0.9784009456634521, Accuracy: 0.7001953125\n",
      "Batch: 60, Loss: 0.9462981224060059, Accuracy: 0.6953125\n",
      "Batch: 61, Loss: 1.0548981428146362, Accuracy: 0.650390625\n",
      "Batch: 62, Loss: 1.0119245052337646, Accuracy: 0.6787109375\n",
      "Batch: 63, Loss: 1.0293811559677124, Accuracy: 0.666015625\n",
      "Batch: 64, Loss: 1.0227458477020264, Accuracy: 0.65625\n",
      "Batch: 65, Loss: 1.0540071725845337, Accuracy: 0.6474609375\n",
      "Batch: 66, Loss: 0.9859508872032166, Accuracy: 0.6826171875\n",
      "Batch: 67, Loss: 1.148127794265747, Accuracy: 0.6552734375\n",
      "Batch: 68, Loss: 1.1355615854263306, Accuracy: 0.650390625\n",
      "Batch: 69, Loss: 1.0548405647277832, Accuracy: 0.65625\n",
      "Batch: 70, Loss: 1.0522375106811523, Accuracy: 0.671875\n",
      "Batch: 71, Loss: 1.0706448554992676, Accuracy: 0.6640625\n",
      "Batch: 72, Loss: 0.9323351383209229, Accuracy: 0.7109375\n",
      "Batch: 73, Loss: 1.0057704448699951, Accuracy: 0.6806640625\n",
      "Batch: 74, Loss: 0.9956225156784058, Accuracy: 0.6708984375\n",
      "Batch: 75, Loss: 0.9469980001449585, Accuracy: 0.697265625\n",
      "Batch: 76, Loss: 1.0610573291778564, Accuracy: 0.642578125\n",
      "Batch: 77, Loss: 1.0000441074371338, Accuracy: 0.677734375\n",
      "Batch: 78, Loss: 0.9974671602249146, Accuracy: 0.6845703125\n",
      "Batch: 79, Loss: 0.9211342930793762, Accuracy: 0.7119140625\n",
      "Batch: 80, Loss: 0.9952161312103271, Accuracy: 0.6552734375\n",
      "Batch: 81, Loss: 1.1456257104873657, Accuracy: 0.61328125\n",
      "Batch: 82, Loss: 1.076725721359253, Accuracy: 0.6416015625\n",
      "Batch: 83, Loss: 0.9239042401313782, Accuracy: 0.705078125\n",
      "Batch: 84, Loss: 1.0064527988433838, Accuracy: 0.6845703125\n",
      "Batch: 85, Loss: 0.9196082353591919, Accuracy: 0.708984375\n",
      "Batch: 86, Loss: 1.1854584217071533, Accuracy: 0.6298828125\n",
      "Batch: 87, Loss: 0.970270037651062, Accuracy: 0.712890625\n",
      "Batch: 88, Loss: 1.0887727737426758, Accuracy: 0.681640625\n",
      "Batch: 89, Loss: 1.0947705507278442, Accuracy: 0.6552734375\n",
      "Batch: 90, Loss: 0.963889479637146, Accuracy: 0.697265625\n",
      "Batch: 91, Loss: 1.024613857269287, Accuracy: 0.671875\n",
      "Batch: 92, Loss: 1.0558326244354248, Accuracy: 0.650390625\n",
      "Batch: 93, Loss: 0.9917371273040771, Accuracy: 0.65625\n",
      "Batch: 94, Loss: 0.990727961063385, Accuracy: 0.677734375\n",
      "Batch: 95, Loss: 1.0589005947113037, Accuracy: 0.6484375\n",
      "Batch: 96, Loss: 1.0216363668441772, Accuracy: 0.6630859375\n",
      "Batch: 97, Loss: 0.8975629210472107, Accuracy: 0.7041015625\n",
      "Batch: 98, Loss: 0.9224029779434204, Accuracy: 0.7060546875\n",
      "Batch: 99, Loss: 0.9475418329238892, Accuracy: 0.69140625\n",
      "Batch: 100, Loss: 1.0162549018859863, Accuracy: 0.6728515625\n",
      "Batch: 101, Loss: 1.0824906826019287, Accuracy: 0.6455078125\n",
      "Batch: 102, Loss: 0.9795588850975037, Accuracy: 0.6826171875\n",
      "Batch: 103, Loss: 1.0394055843353271, Accuracy: 0.6787109375\n",
      "Batch: 104, Loss: 0.9827048778533936, Accuracy: 0.681640625\n",
      "Batch: 105, Loss: 1.0680842399597168, Accuracy: 0.640625\n",
      "Batch: 106, Loss: 1.0349011421203613, Accuracy: 0.646484375\n",
      "Batch: 107, Loss: 1.0782275199890137, Accuracy: 0.6552734375\n",
      "Batch: 108, Loss: 1.0386121273040771, Accuracy: 0.666015625\n",
      "Batch: 109, Loss: 1.1547678709030151, Accuracy: 0.6171875\n",
      "Batch: 110, Loss: 0.8978549838066101, Accuracy: 0.69921875\n",
      "Batch: 111, Loss: 1.057034969329834, Accuracy: 0.6416015625\n",
      "Batch: 112, Loss: 1.0122283697128296, Accuracy: 0.68359375\n",
      "Batch: 113, Loss: 1.040956735610962, Accuracy: 0.662109375\n",
      "Batch: 114, Loss: 1.1388713121414185, Accuracy: 0.6337890625\n",
      "Batch: 115, Loss: 1.1633274555206299, Accuracy: 0.650390625\n",
      "Batch: 116, Loss: 1.0902924537658691, Accuracy: 0.65625\n",
      "Batch: 117, Loss: 1.1220592260360718, Accuracy: 0.6416015625\n",
      "Batch: 118, Loss: 0.9540762901306152, Accuracy: 0.6982421875\n",
      "Batch: 119, Loss: 0.9409559369087219, Accuracy: 0.7001953125\n",
      "Batch: 120, Loss: 1.05306077003479, Accuracy: 0.658203125\n",
      "Batch: 121, Loss: 1.089799165725708, Accuracy: 0.6435546875\n",
      "Batch: 122, Loss: 1.0262198448181152, Accuracy: 0.6640625\n",
      "Batch: 123, Loss: 0.9767100811004639, Accuracy: 0.6923828125\n",
      "Batch: 124, Loss: 1.0701853036880493, Accuracy: 0.650390625\n",
      "Batch: 125, Loss: 1.0719537734985352, Accuracy: 0.6298828125\n",
      "Batch: 126, Loss: 1.0749568939208984, Accuracy: 0.650390625\n",
      "Batch: 127, Loss: 0.9372269511222839, Accuracy: 0.697265625\n",
      "Batch: 128, Loss: 1.181260585784912, Accuracy: 0.6328125\n",
      "Batch: 129, Loss: 1.0031441450119019, Accuracy: 0.671875\n",
      "Batch: 130, Loss: 1.1972849369049072, Accuracy: 0.607421875\n",
      "Batch: 131, Loss: 1.0910006761550903, Accuracy: 0.65234375\n",
      "Batch: 132, Loss: 1.12513267993927, Accuracy: 0.619140625\n",
      "Batch: 133, Loss: 0.9680038690567017, Accuracy: 0.68359375\n",
      "Batch: 134, Loss: 1.0527698993682861, Accuracy: 0.6455078125\n",
      "Batch: 135, Loss: 0.9773288369178772, Accuracy: 0.681640625\n",
      "Batch: 136, Loss: 1.0531790256500244, Accuracy: 0.6611328125\n",
      "Batch: 137, Loss: 0.9554755687713623, Accuracy: 0.6640625\n",
      "Batch: 138, Loss: 0.8797622919082642, Accuracy: 0.6923828125\n",
      "Batch: 139, Loss: 0.9478663802146912, Accuracy: 0.68359375\n",
      "Batch: 140, Loss: 1.0334556102752686, Accuracy: 0.6484375\n",
      "Batch: 141, Loss: 1.085521936416626, Accuracy: 0.64453125\n",
      "Batch: 142, Loss: 1.1086409091949463, Accuracy: 0.6416015625\n",
      "Batch: 143, Loss: 1.0598219633102417, Accuracy: 0.65625\n",
      "Batch: 144, Loss: 1.0447555780410767, Accuracy: 0.6728515625\n",
      "Batch: 145, Loss: 1.002515196800232, Accuracy: 0.64453125\n",
      "Batch: 146, Loss: 1.0646696090698242, Accuracy: 0.6591796875\n",
      "Batch: 147, Loss: 1.0529460906982422, Accuracy: 0.6552734375\n",
      "Batch: 148, Loss: 1.151719093322754, Accuracy: 0.6142578125\n",
      "Batch: 149, Loss: 1.0206390619277954, Accuracy: 0.646484375\n",
      "Batch: 150, Loss: 0.9661813378334045, Accuracy: 0.6689453125\n",
      "Batch: 151, Loss: 0.8820106983184814, Accuracy: 0.7236328125\n",
      "Epoch 16/90\n",
      "Batch: 1, Loss: 1.2901211977005005, Accuracy: 0.5703125\n",
      "Batch: 2, Loss: 1.1041879653930664, Accuracy: 0.603515625\n",
      "Batch: 3, Loss: 0.9666198492050171, Accuracy: 0.677734375\n",
      "Batch: 4, Loss: 0.9090737104415894, Accuracy: 0.705078125\n",
      "Batch: 5, Loss: 0.952704906463623, Accuracy: 0.7001953125\n",
      "Batch: 6, Loss: 1.0291225910186768, Accuracy: 0.6708984375\n",
      "Batch: 7, Loss: 1.0057716369628906, Accuracy: 0.6630859375\n",
      "Batch: 8, Loss: 0.9676265716552734, Accuracy: 0.6767578125\n",
      "Batch: 9, Loss: 0.9129592180252075, Accuracy: 0.7099609375\n",
      "Batch: 10, Loss: 0.9151716232299805, Accuracy: 0.701171875\n",
      "Batch: 11, Loss: 1.1257606744766235, Accuracy: 0.6259765625\n",
      "Batch: 12, Loss: 1.1027777194976807, Accuracy: 0.6318359375\n",
      "Batch: 13, Loss: 0.8472796082496643, Accuracy: 0.6982421875\n",
      "Batch: 14, Loss: 1.1109724044799805, Accuracy: 0.6396484375\n",
      "Batch: 15, Loss: 0.9569549560546875, Accuracy: 0.705078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 16, Loss: 0.952492892742157, Accuracy: 0.6904296875\n",
      "Batch: 17, Loss: 1.0453165769577026, Accuracy: 0.6484375\n",
      "Batch: 18, Loss: 1.0443699359893799, Accuracy: 0.6640625\n",
      "Batch: 19, Loss: 1.0979392528533936, Accuracy: 0.6484375\n",
      "Batch: 20, Loss: 0.9800795316696167, Accuracy: 0.6796875\n",
      "Batch: 21, Loss: 0.9709628224372864, Accuracy: 0.67578125\n",
      "Batch: 22, Loss: 1.0940067768096924, Accuracy: 0.6416015625\n",
      "Batch: 23, Loss: 0.9899075031280518, Accuracy: 0.66796875\n",
      "Batch: 24, Loss: 1.0232534408569336, Accuracy: 0.6484375\n",
      "Batch: 25, Loss: 0.9952367544174194, Accuracy: 0.6728515625\n",
      "Batch: 26, Loss: 0.8918660879135132, Accuracy: 0.712890625\n",
      "Batch: 27, Loss: 0.9391791820526123, Accuracy: 0.681640625\n",
      "Batch: 28, Loss: 1.0512099266052246, Accuracy: 0.6455078125\n",
      "Batch: 29, Loss: 1.0164613723754883, Accuracy: 0.6708984375\n",
      "Batch: 30, Loss: 0.9575032591819763, Accuracy: 0.693359375\n",
      "Batch: 31, Loss: 0.957854688167572, Accuracy: 0.69140625\n",
      "Batch: 32, Loss: 0.9391500949859619, Accuracy: 0.6796875\n",
      "Batch: 33, Loss: 1.1093229055404663, Accuracy: 0.6328125\n",
      "Batch: 34, Loss: 1.163910150527954, Accuracy: 0.6201171875\n",
      "Batch: 35, Loss: 1.0731892585754395, Accuracy: 0.6484375\n",
      "Batch: 36, Loss: 1.075758457183838, Accuracy: 0.6572265625\n",
      "Batch: 37, Loss: 0.9959373474121094, Accuracy: 0.6845703125\n",
      "Batch: 38, Loss: 1.0234084129333496, Accuracy: 0.666015625\n",
      "Batch: 39, Loss: 1.036918044090271, Accuracy: 0.669921875\n",
      "Batch: 40, Loss: 1.0669798851013184, Accuracy: 0.6826171875\n",
      "Batch: 41, Loss: 1.008805513381958, Accuracy: 0.6787109375\n",
      "Batch: 42, Loss: 0.8274210691452026, Accuracy: 0.7197265625\n",
      "Batch: 43, Loss: 1.0496330261230469, Accuracy: 0.654296875\n",
      "Batch: 44, Loss: 1.0480141639709473, Accuracy: 0.642578125\n",
      "Batch: 45, Loss: 0.9039485454559326, Accuracy: 0.6904296875\n",
      "Batch: 46, Loss: 1.0228126049041748, Accuracy: 0.6806640625\n",
      "Batch: 47, Loss: 0.9836451411247253, Accuracy: 0.7001953125\n",
      "Batch: 48, Loss: 0.9152143001556396, Accuracy: 0.708984375\n",
      "Batch: 49, Loss: 1.1089928150177002, Accuracy: 0.6328125\n",
      "Batch: 50, Loss: 1.0845906734466553, Accuracy: 0.640625\n",
      "Batch: 51, Loss: 1.1032755374908447, Accuracy: 0.6435546875\n",
      "Batch: 52, Loss: 1.1070088148117065, Accuracy: 0.6484375\n",
      "Batch: 53, Loss: 0.9351397156715393, Accuracy: 0.689453125\n",
      "Batch: 54, Loss: 1.025396704673767, Accuracy: 0.67578125\n",
      "Batch: 55, Loss: 1.082908034324646, Accuracy: 0.6376953125\n",
      "Batch: 56, Loss: 1.0666075944900513, Accuracy: 0.6748046875\n",
      "Batch: 57, Loss: 1.00754714012146, Accuracy: 0.6806640625\n",
      "Batch: 58, Loss: 1.1046769618988037, Accuracy: 0.6689453125\n",
      "Batch: 59, Loss: 0.9620057344436646, Accuracy: 0.6953125\n",
      "Batch: 60, Loss: 0.9009428024291992, Accuracy: 0.703125\n",
      "Batch: 61, Loss: 1.0328373908996582, Accuracy: 0.662109375\n",
      "Batch: 62, Loss: 0.9932166337966919, Accuracy: 0.6796875\n",
      "Batch: 63, Loss: 1.0301623344421387, Accuracy: 0.666015625\n",
      "Batch: 64, Loss: 1.0082311630249023, Accuracy: 0.671875\n",
      "Batch: 65, Loss: 1.0232281684875488, Accuracy: 0.6748046875\n",
      "Batch: 66, Loss: 0.9627106189727783, Accuracy: 0.69921875\n",
      "Batch: 67, Loss: 1.077268123626709, Accuracy: 0.64453125\n",
      "Batch: 68, Loss: 1.1019761562347412, Accuracy: 0.6708984375\n",
      "Batch: 69, Loss: 1.038752794265747, Accuracy: 0.6630859375\n",
      "Batch: 70, Loss: 1.0378057956695557, Accuracy: 0.6748046875\n",
      "Batch: 71, Loss: 1.0443470478057861, Accuracy: 0.65625\n",
      "Batch: 72, Loss: 0.9144010543823242, Accuracy: 0.6962890625\n",
      "Batch: 73, Loss: 0.9749054908752441, Accuracy: 0.6953125\n",
      "Batch: 74, Loss: 0.9608149528503418, Accuracy: 0.697265625\n",
      "Batch: 75, Loss: 0.9081941843032837, Accuracy: 0.7080078125\n",
      "Batch: 76, Loss: 1.0565385818481445, Accuracy: 0.650390625\n",
      "Batch: 77, Loss: 0.9843624234199524, Accuracy: 0.66796875\n",
      "Batch: 78, Loss: 0.9954207539558411, Accuracy: 0.6953125\n",
      "Batch: 79, Loss: 0.9163572192192078, Accuracy: 0.71875\n",
      "Batch: 80, Loss: 0.9398549795150757, Accuracy: 0.6787109375\n",
      "Batch: 81, Loss: 1.1272635459899902, Accuracy: 0.611328125\n",
      "Batch: 82, Loss: 1.0597786903381348, Accuracy: 0.650390625\n",
      "Batch: 83, Loss: 0.9006993174552917, Accuracy: 0.6982421875\n",
      "Batch: 84, Loss: 1.0033468008041382, Accuracy: 0.6728515625\n",
      "Batch: 85, Loss: 0.919313907623291, Accuracy: 0.716796875\n",
      "Batch: 86, Loss: 1.1881145238876343, Accuracy: 0.6181640625\n",
      "Batch: 87, Loss: 0.9646240472793579, Accuracy: 0.693359375\n",
      "Batch: 88, Loss: 1.0677814483642578, Accuracy: 0.658203125\n",
      "Batch: 89, Loss: 1.0658111572265625, Accuracy: 0.6767578125\n",
      "Batch: 90, Loss: 0.9442447423934937, Accuracy: 0.6865234375\n",
      "Batch: 91, Loss: 1.00794517993927, Accuracy: 0.6591796875\n",
      "Batch: 92, Loss: 0.999720573425293, Accuracy: 0.671875\n",
      "Batch: 93, Loss: 0.9597153663635254, Accuracy: 0.689453125\n",
      "Batch: 94, Loss: 0.9820852279663086, Accuracy: 0.6806640625\n",
      "Batch: 95, Loss: 1.0556384325027466, Accuracy: 0.6435546875\n",
      "Batch: 96, Loss: 0.9920021891593933, Accuracy: 0.681640625\n",
      "Batch: 97, Loss: 0.8494619727134705, Accuracy: 0.7158203125\n",
      "Batch: 98, Loss: 0.9176033735275269, Accuracy: 0.7099609375\n",
      "Batch: 99, Loss: 0.9566076993942261, Accuracy: 0.689453125\n",
      "Batch: 100, Loss: 0.9822340607643127, Accuracy: 0.6884765625\n",
      "Batch: 101, Loss: 1.0775885581970215, Accuracy: 0.6396484375\n",
      "Batch: 102, Loss: 0.9606114029884338, Accuracy: 0.6826171875\n",
      "Batch: 103, Loss: 1.040849208831787, Accuracy: 0.6748046875\n",
      "Batch: 104, Loss: 0.959568202495575, Accuracy: 0.6806640625\n",
      "Batch: 105, Loss: 1.0317432880401611, Accuracy: 0.67578125\n",
      "Batch: 106, Loss: 0.9855730533599854, Accuracy: 0.689453125\n",
      "Batch: 107, Loss: 1.044580101966858, Accuracy: 0.6630859375\n",
      "Batch: 108, Loss: 1.0082463026046753, Accuracy: 0.658203125\n",
      "Batch: 109, Loss: 1.1301703453063965, Accuracy: 0.625\n",
      "Batch: 110, Loss: 0.8639959692955017, Accuracy: 0.7001953125\n",
      "Batch: 111, Loss: 1.0480165481567383, Accuracy: 0.6416015625\n",
      "Batch: 112, Loss: 0.9981730580329895, Accuracy: 0.6865234375\n",
      "Batch: 113, Loss: 1.023245096206665, Accuracy: 0.6865234375\n",
      "Batch: 114, Loss: 1.1186952590942383, Accuracy: 0.6396484375\n",
      "Batch: 115, Loss: 1.1461329460144043, Accuracy: 0.6552734375\n",
      "Batch: 116, Loss: 1.0759133100509644, Accuracy: 0.66015625\n",
      "Batch: 117, Loss: 1.1110786199569702, Accuracy: 0.658203125\n",
      "Batch: 118, Loss: 0.917251467704773, Accuracy: 0.7099609375\n",
      "Batch: 119, Loss: 0.8949868679046631, Accuracy: 0.7138671875\n",
      "Batch: 120, Loss: 1.0511053800582886, Accuracy: 0.646484375\n",
      "Batch: 121, Loss: 1.0770201683044434, Accuracy: 0.666015625\n",
      "Batch: 122, Loss: 0.9760259985923767, Accuracy: 0.689453125\n",
      "Batch: 123, Loss: 0.9856033325195312, Accuracy: 0.689453125\n",
      "Batch: 124, Loss: 1.0494636297225952, Accuracy: 0.6533203125\n",
      "Batch: 125, Loss: 1.0303456783294678, Accuracy: 0.66796875\n",
      "Batch: 126, Loss: 1.0423798561096191, Accuracy: 0.65234375\n",
      "Batch: 127, Loss: 0.9172608852386475, Accuracy: 0.703125\n",
      "Batch: 128, Loss: 1.1266683340072632, Accuracy: 0.650390625\n",
      "Batch: 129, Loss: 0.994365930557251, Accuracy: 0.685546875\n",
      "Batch: 130, Loss: 1.1837960481643677, Accuracy: 0.62890625\n",
      "Batch: 131, Loss: 1.063753366470337, Accuracy: 0.6572265625\n",
      "Batch: 132, Loss: 1.1131551265716553, Accuracy: 0.630859375\n",
      "Batch: 133, Loss: 0.9532994031906128, Accuracy: 0.6767578125\n",
      "Batch: 134, Loss: 1.0669364929199219, Accuracy: 0.650390625\n",
      "Batch: 135, Loss: 0.9320907592773438, Accuracy: 0.697265625\n",
      "Batch: 136, Loss: 1.0247516632080078, Accuracy: 0.6611328125\n",
      "Batch: 137, Loss: 0.9424746632575989, Accuracy: 0.6845703125\n",
      "Batch: 138, Loss: 0.8414735794067383, Accuracy: 0.7099609375\n",
      "Batch: 139, Loss: 0.9050514698028564, Accuracy: 0.6904296875\n",
      "Batch: 140, Loss: 1.0003976821899414, Accuracy: 0.6552734375\n",
      "Batch: 141, Loss: 1.0500209331512451, Accuracy: 0.6796875\n",
      "Batch: 142, Loss: 1.0720709562301636, Accuracy: 0.6416015625\n",
      "Batch: 143, Loss: 1.0401545763015747, Accuracy: 0.6630859375\n",
      "Batch: 144, Loss: 1.0389587879180908, Accuracy: 0.6689453125\n",
      "Batch: 145, Loss: 0.9889233112335205, Accuracy: 0.6455078125\n",
      "Batch: 146, Loss: 1.0488207340240479, Accuracy: 0.6591796875\n",
      "Batch: 147, Loss: 1.029419183731079, Accuracy: 0.6669921875\n",
      "Batch: 148, Loss: 1.1401786804199219, Accuracy: 0.6298828125\n",
      "Batch: 149, Loss: 0.99747234582901, Accuracy: 0.6728515625\n",
      "Batch: 150, Loss: 0.934717059135437, Accuracy: 0.69140625\n",
      "Batch: 151, Loss: 0.8664533495903015, Accuracy: 0.7294921875\n",
      "Epoch 17/90\n",
      "Batch: 1, Loss: 1.2472646236419678, Accuracy: 0.6064453125\n",
      "Batch: 2, Loss: 1.0828512907028198, Accuracy: 0.625\n",
      "Batch: 3, Loss: 0.9608557224273682, Accuracy: 0.6845703125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 4, Loss: 0.869312047958374, Accuracy: 0.712890625\n",
      "Batch: 5, Loss: 0.951743483543396, Accuracy: 0.6962890625\n",
      "Batch: 6, Loss: 1.009110689163208, Accuracy: 0.6572265625\n",
      "Batch: 7, Loss: 0.9715709090232849, Accuracy: 0.6650390625\n",
      "Batch: 8, Loss: 0.9376028776168823, Accuracy: 0.685546875\n",
      "Batch: 9, Loss: 0.8777158260345459, Accuracy: 0.728515625\n",
      "Batch: 10, Loss: 0.9050368666648865, Accuracy: 0.7099609375\n",
      "Batch: 11, Loss: 1.0944548845291138, Accuracy: 0.6337890625\n",
      "Batch: 12, Loss: 1.069944143295288, Accuracy: 0.6533203125\n",
      "Batch: 13, Loss: 0.8601915836334229, Accuracy: 0.7294921875\n",
      "Batch: 14, Loss: 1.0936064720153809, Accuracy: 0.6318359375\n",
      "Batch: 15, Loss: 0.9566304683685303, Accuracy: 0.7041015625\n",
      "Batch: 16, Loss: 0.963797926902771, Accuracy: 0.701171875\n",
      "Batch: 17, Loss: 1.0366054773330688, Accuracy: 0.654296875\n",
      "Batch: 18, Loss: 1.0278046131134033, Accuracy: 0.6572265625\n",
      "Batch: 19, Loss: 1.0558059215545654, Accuracy: 0.6640625\n",
      "Batch: 20, Loss: 0.9628784656524658, Accuracy: 0.69921875\n",
      "Batch: 21, Loss: 0.9547446966171265, Accuracy: 0.68359375\n",
      "Batch: 22, Loss: 1.0702893733978271, Accuracy: 0.662109375\n",
      "Batch: 23, Loss: 0.9901168346405029, Accuracy: 0.6650390625\n",
      "Batch: 24, Loss: 0.9850397109985352, Accuracy: 0.6650390625\n",
      "Batch: 25, Loss: 0.9992742538452148, Accuracy: 0.669921875\n",
      "Batch: 26, Loss: 0.8697890043258667, Accuracy: 0.71875\n",
      "Batch: 27, Loss: 0.9190592765808105, Accuracy: 0.673828125\n",
      "Batch: 28, Loss: 1.0155882835388184, Accuracy: 0.6669921875\n",
      "Batch: 29, Loss: 1.0179282426834106, Accuracy: 0.6630859375\n",
      "Batch: 30, Loss: 0.9206348061561584, Accuracy: 0.7119140625\n",
      "Batch: 31, Loss: 0.92387855052948, Accuracy: 0.6953125\n",
      "Batch: 32, Loss: 0.9219611287117004, Accuracy: 0.7041015625\n",
      "Batch: 33, Loss: 1.089280605316162, Accuracy: 0.6357421875\n",
      "Batch: 34, Loss: 1.1361571550369263, Accuracy: 0.630859375\n",
      "Batch: 35, Loss: 1.0390963554382324, Accuracy: 0.669921875\n",
      "Batch: 36, Loss: 1.0537548065185547, Accuracy: 0.6689453125\n",
      "Batch: 37, Loss: 0.964122474193573, Accuracy: 0.6796875\n",
      "Batch: 38, Loss: 1.038530707359314, Accuracy: 0.6533203125\n",
      "Batch: 39, Loss: 1.0422428846359253, Accuracy: 0.662109375\n",
      "Batch: 40, Loss: 1.0227831602096558, Accuracy: 0.677734375\n",
      "Batch: 41, Loss: 0.9731786847114563, Accuracy: 0.693359375\n",
      "Batch: 42, Loss: 0.7914830446243286, Accuracy: 0.73828125\n",
      "Batch: 43, Loss: 1.0273985862731934, Accuracy: 0.6572265625\n",
      "Batch: 44, Loss: 1.005853533744812, Accuracy: 0.6591796875\n",
      "Batch: 45, Loss: 0.8803837299346924, Accuracy: 0.693359375\n",
      "Batch: 46, Loss: 0.9720224142074585, Accuracy: 0.7021484375\n",
      "Batch: 47, Loss: 0.9441314935684204, Accuracy: 0.7109375\n",
      "Batch: 48, Loss: 0.8957357406616211, Accuracy: 0.7080078125\n",
      "Batch: 49, Loss: 1.072709560394287, Accuracy: 0.66015625\n",
      "Batch: 50, Loss: 1.0276415348052979, Accuracy: 0.673828125\n",
      "Batch: 51, Loss: 1.1107205152511597, Accuracy: 0.6474609375\n",
      "Batch: 52, Loss: 1.0711703300476074, Accuracy: 0.6494140625\n",
      "Batch: 53, Loss: 0.9044259786605835, Accuracy: 0.6923828125\n",
      "Batch: 54, Loss: 1.0006290674209595, Accuracy: 0.67578125\n",
      "Batch: 55, Loss: 1.0534172058105469, Accuracy: 0.6484375\n",
      "Batch: 56, Loss: 1.0332037210464478, Accuracy: 0.677734375\n",
      "Batch: 57, Loss: 0.9544943571090698, Accuracy: 0.6962890625\n",
      "Batch: 58, Loss: 1.0580146312713623, Accuracy: 0.677734375\n",
      "Batch: 59, Loss: 0.9238333702087402, Accuracy: 0.7109375\n",
      "Batch: 60, Loss: 0.9101170897483826, Accuracy: 0.7080078125\n",
      "Batch: 61, Loss: 1.0150556564331055, Accuracy: 0.66015625\n",
      "Batch: 62, Loss: 0.9591864347457886, Accuracy: 0.6923828125\n",
      "Batch: 63, Loss: 0.9811551570892334, Accuracy: 0.6787109375\n",
      "Batch: 64, Loss: 0.9766328930854797, Accuracy: 0.677734375\n",
      "Batch: 65, Loss: 1.0230309963226318, Accuracy: 0.6689453125\n",
      "Batch: 66, Loss: 0.9381853342056274, Accuracy: 0.705078125\n",
      "Batch: 67, Loss: 1.0844817161560059, Accuracy: 0.6376953125\n",
      "Batch: 68, Loss: 1.0948830842971802, Accuracy: 0.662109375\n",
      "Batch: 69, Loss: 1.0331647396087646, Accuracy: 0.6591796875\n",
      "Batch: 70, Loss: 0.9929546117782593, Accuracy: 0.6865234375\n",
      "Batch: 71, Loss: 1.0185686349868774, Accuracy: 0.6630859375\n",
      "Batch: 72, Loss: 0.887402355670929, Accuracy: 0.705078125\n",
      "Batch: 73, Loss: 0.9395709037780762, Accuracy: 0.6884765625\n",
      "Batch: 74, Loss: 0.9510855078697205, Accuracy: 0.703125\n",
      "Batch: 75, Loss: 0.9190232753753662, Accuracy: 0.703125\n",
      "Batch: 76, Loss: 0.9961179494857788, Accuracy: 0.666015625\n",
      "Batch: 77, Loss: 0.9541743993759155, Accuracy: 0.6826171875\n",
      "Batch: 78, Loss: 0.9187533259391785, Accuracy: 0.70703125\n",
      "Batch: 79, Loss: 0.8775395154953003, Accuracy: 0.7333984375\n",
      "Batch: 80, Loss: 0.9310728311538696, Accuracy: 0.685546875\n",
      "Batch: 81, Loss: 1.081925868988037, Accuracy: 0.6279296875\n",
      "Batch: 82, Loss: 1.0219908952713013, Accuracy: 0.68359375\n",
      "Batch: 83, Loss: 0.8520692586898804, Accuracy: 0.720703125\n",
      "Batch: 84, Loss: 0.9454794526100159, Accuracy: 0.697265625\n",
      "Batch: 85, Loss: 0.8650542497634888, Accuracy: 0.7119140625\n",
      "Batch: 86, Loss: 1.1652798652648926, Accuracy: 0.6376953125\n",
      "Batch: 87, Loss: 0.9194303750991821, Accuracy: 0.71484375\n",
      "Batch: 88, Loss: 1.0408328771591187, Accuracy: 0.6884765625\n",
      "Batch: 89, Loss: 1.050857663154602, Accuracy: 0.6630859375\n",
      "Batch: 90, Loss: 0.9130501747131348, Accuracy: 0.701171875\n",
      "Batch: 91, Loss: 0.9688980579376221, Accuracy: 0.6845703125\n",
      "Batch: 92, Loss: 0.9770891666412354, Accuracy: 0.6953125\n",
      "Batch: 93, Loss: 0.9404684901237488, Accuracy: 0.71484375\n",
      "Batch: 94, Loss: 0.9470054507255554, Accuracy: 0.685546875\n",
      "Batch: 95, Loss: 0.9873762130737305, Accuracy: 0.666015625\n",
      "Batch: 96, Loss: 0.9931854009628296, Accuracy: 0.6806640625\n",
      "Batch: 97, Loss: 0.8185298442840576, Accuracy: 0.7314453125\n",
      "Batch: 98, Loss: 0.9034215807914734, Accuracy: 0.70703125\n",
      "Batch: 99, Loss: 0.9249575734138489, Accuracy: 0.6982421875\n",
      "Batch: 100, Loss: 0.9578344225883484, Accuracy: 0.689453125\n",
      "Batch: 101, Loss: 1.038482427597046, Accuracy: 0.6640625\n",
      "Batch: 102, Loss: 0.9462975263595581, Accuracy: 0.7001953125\n",
      "Batch: 103, Loss: 0.9877256155014038, Accuracy: 0.6904296875\n",
      "Batch: 104, Loss: 0.9397473335266113, Accuracy: 0.6884765625\n",
      "Batch: 105, Loss: 1.0169180631637573, Accuracy: 0.662109375\n",
      "Batch: 106, Loss: 0.969719409942627, Accuracy: 0.6904296875\n",
      "Batch: 107, Loss: 1.0156141519546509, Accuracy: 0.654296875\n",
      "Batch: 108, Loss: 0.9894432425498962, Accuracy: 0.666015625\n",
      "Batch: 109, Loss: 1.117221474647522, Accuracy: 0.6357421875\n",
      "Batch: 110, Loss: 0.8440169095993042, Accuracy: 0.732421875\n",
      "Batch: 111, Loss: 1.019417405128479, Accuracy: 0.6708984375\n",
      "Batch: 112, Loss: 0.9658816456794739, Accuracy: 0.6904296875\n",
      "Batch: 113, Loss: 0.9698478579521179, Accuracy: 0.68359375\n",
      "Batch: 114, Loss: 1.1002269983291626, Accuracy: 0.6474609375\n",
      "Batch: 115, Loss: 1.0878061056137085, Accuracy: 0.6572265625\n",
      "Batch: 116, Loss: 1.0291297435760498, Accuracy: 0.669921875\n",
      "Batch: 117, Loss: 1.0665372610092163, Accuracy: 0.6572265625\n",
      "Batch: 118, Loss: 0.8882186412811279, Accuracy: 0.720703125\n",
      "Batch: 119, Loss: 0.8567991256713867, Accuracy: 0.736328125\n",
      "Batch: 120, Loss: 1.0162615776062012, Accuracy: 0.6708984375\n",
      "Batch: 121, Loss: 1.053978443145752, Accuracy: 0.658203125\n",
      "Batch: 122, Loss: 0.9587730169296265, Accuracy: 0.681640625\n",
      "Batch: 123, Loss: 0.9377201199531555, Accuracy: 0.69921875\n",
      "Batch: 124, Loss: 1.0342298746109009, Accuracy: 0.6474609375\n",
      "Batch: 125, Loss: 1.0133171081542969, Accuracy: 0.6787109375\n",
      "Batch: 126, Loss: 1.0207479000091553, Accuracy: 0.671875\n",
      "Batch: 127, Loss: 0.8912620544433594, Accuracy: 0.70703125\n",
      "Batch: 128, Loss: 1.0883287191390991, Accuracy: 0.6650390625\n",
      "Batch: 129, Loss: 0.9731741547584534, Accuracy: 0.69140625\n",
      "Batch: 130, Loss: 1.164023518562317, Accuracy: 0.6171875\n",
      "Batch: 131, Loss: 1.0522470474243164, Accuracy: 0.6611328125\n",
      "Batch: 132, Loss: 1.0740300416946411, Accuracy: 0.65234375\n",
      "Batch: 133, Loss: 0.9358813762664795, Accuracy: 0.68359375\n",
      "Batch: 134, Loss: 0.9882909059524536, Accuracy: 0.6630859375\n",
      "Batch: 135, Loss: 0.8871639370918274, Accuracy: 0.7080078125\n",
      "Batch: 136, Loss: 0.9757435917854309, Accuracy: 0.685546875\n",
      "Batch: 137, Loss: 0.9242362976074219, Accuracy: 0.6796875\n",
      "Batch: 138, Loss: 0.8352434635162354, Accuracy: 0.7001953125\n",
      "Batch: 139, Loss: 0.8695597052574158, Accuracy: 0.7158203125\n",
      "Batch: 140, Loss: 0.9846106767654419, Accuracy: 0.67578125\n",
      "Batch: 141, Loss: 1.036513090133667, Accuracy: 0.6728515625\n",
      "Batch: 142, Loss: 1.055582880973816, Accuracy: 0.6552734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 143, Loss: 0.9944336414337158, Accuracy: 0.6796875\n",
      "Batch: 144, Loss: 1.007551670074463, Accuracy: 0.671875\n",
      "Batch: 145, Loss: 0.9347918033599854, Accuracy: 0.6787109375\n",
      "Batch: 146, Loss: 1.0225752592086792, Accuracy: 0.6787109375\n",
      "Batch: 147, Loss: 1.0073624849319458, Accuracy: 0.6748046875\n",
      "Batch: 148, Loss: 1.0999010801315308, Accuracy: 0.642578125\n",
      "Batch: 149, Loss: 0.9608944058418274, Accuracy: 0.6708984375\n",
      "Batch: 150, Loss: 0.9217948913574219, Accuracy: 0.7021484375\n",
      "Batch: 151, Loss: 0.874011754989624, Accuracy: 0.72265625\n",
      "Epoch 18/90\n",
      "Batch: 1, Loss: 1.2394182682037354, Accuracy: 0.6103515625\n",
      "Batch: 2, Loss: 1.0643633604049683, Accuracy: 0.630859375\n",
      "Batch: 3, Loss: 0.9256719350814819, Accuracy: 0.6962890625\n",
      "Batch: 4, Loss: 0.8720018863677979, Accuracy: 0.71484375\n",
      "Batch: 5, Loss: 0.8956080675125122, Accuracy: 0.7119140625\n",
      "Batch: 6, Loss: 1.0167157649993896, Accuracy: 0.6533203125\n",
      "Batch: 7, Loss: 0.9588886499404907, Accuracy: 0.6728515625\n",
      "Batch: 8, Loss: 0.9057896733283997, Accuracy: 0.685546875\n",
      "Batch: 9, Loss: 0.8675771951675415, Accuracy: 0.720703125\n",
      "Batch: 10, Loss: 0.8776484131813049, Accuracy: 0.7109375\n",
      "Batch: 11, Loss: 1.0723001956939697, Accuracy: 0.6416015625\n",
      "Batch: 12, Loss: 1.04160737991333, Accuracy: 0.6728515625\n",
      "Batch: 13, Loss: 0.8301397562026978, Accuracy: 0.720703125\n",
      "Batch: 14, Loss: 1.0909090042114258, Accuracy: 0.642578125\n",
      "Batch: 15, Loss: 0.8953198194503784, Accuracy: 0.7255859375\n",
      "Batch: 16, Loss: 0.9438319206237793, Accuracy: 0.7001953125\n",
      "Batch: 17, Loss: 1.0080912113189697, Accuracy: 0.677734375\n",
      "Batch: 18, Loss: 1.0218141078948975, Accuracy: 0.6591796875\n",
      "Batch: 19, Loss: 1.0360238552093506, Accuracy: 0.6845703125\n",
      "Batch: 20, Loss: 0.9053767919540405, Accuracy: 0.708984375\n",
      "Batch: 21, Loss: 0.9079196453094482, Accuracy: 0.7119140625\n",
      "Batch: 22, Loss: 1.0601340532302856, Accuracy: 0.6484375\n",
      "Batch: 23, Loss: 0.9708249568939209, Accuracy: 0.6826171875\n",
      "Batch: 24, Loss: 0.9768809676170349, Accuracy: 0.6806640625\n",
      "Batch: 25, Loss: 0.9842111468315125, Accuracy: 0.6767578125\n",
      "Batch: 26, Loss: 0.8293553590774536, Accuracy: 0.7236328125\n",
      "Batch: 27, Loss: 0.8705958127975464, Accuracy: 0.701171875\n",
      "Batch: 28, Loss: 1.01438570022583, Accuracy: 0.6484375\n",
      "Batch: 29, Loss: 0.9806555509567261, Accuracy: 0.6708984375\n",
      "Batch: 30, Loss: 0.8997300863265991, Accuracy: 0.7109375\n",
      "Batch: 31, Loss: 0.8896324038505554, Accuracy: 0.7099609375\n",
      "Batch: 32, Loss: 0.8975363373756409, Accuracy: 0.7177734375\n",
      "Batch: 33, Loss: 1.053309440612793, Accuracy: 0.6396484375\n",
      "Batch: 34, Loss: 1.1100044250488281, Accuracy: 0.6357421875\n",
      "Batch: 35, Loss: 1.015514612197876, Accuracy: 0.6796875\n",
      "Batch: 36, Loss: 1.0302226543426514, Accuracy: 0.6796875\n",
      "Batch: 37, Loss: 0.9780526161193848, Accuracy: 0.685546875\n",
      "Batch: 38, Loss: 0.9937852621078491, Accuracy: 0.6591796875\n",
      "Batch: 39, Loss: 1.005302906036377, Accuracy: 0.68359375\n",
      "Batch: 40, Loss: 1.001513123512268, Accuracy: 0.69140625\n",
      "Batch: 41, Loss: 0.9721314907073975, Accuracy: 0.6953125\n",
      "Batch: 42, Loss: 0.7857533693313599, Accuracy: 0.73828125\n",
      "Batch: 43, Loss: 1.0093352794647217, Accuracy: 0.6494140625\n",
      "Batch: 44, Loss: 1.0057039260864258, Accuracy: 0.6611328125\n",
      "Batch: 45, Loss: 0.8680804967880249, Accuracy: 0.7158203125\n",
      "Batch: 46, Loss: 0.9655817747116089, Accuracy: 0.6875\n",
      "Batch: 47, Loss: 0.9238811731338501, Accuracy: 0.7060546875\n",
      "Batch: 48, Loss: 0.8701852560043335, Accuracy: 0.703125\n",
      "Batch: 49, Loss: 1.066476583480835, Accuracy: 0.6455078125\n",
      "Batch: 50, Loss: 1.0325429439544678, Accuracy: 0.6689453125\n",
      "Batch: 51, Loss: 1.0754579305648804, Accuracy: 0.6552734375\n",
      "Batch: 52, Loss: 1.0286240577697754, Accuracy: 0.6640625\n",
      "Batch: 53, Loss: 0.9172722101211548, Accuracy: 0.6953125\n",
      "Batch: 54, Loss: 0.9701075553894043, Accuracy: 0.6826171875\n",
      "Batch: 55, Loss: 1.0361766815185547, Accuracy: 0.6484375\n",
      "Batch: 56, Loss: 1.0353949069976807, Accuracy: 0.68359375\n",
      "Batch: 57, Loss: 0.9357064962387085, Accuracy: 0.7119140625\n",
      "Batch: 58, Loss: 1.05659818649292, Accuracy: 0.67578125\n",
      "Batch: 59, Loss: 0.9181143045425415, Accuracy: 0.71484375\n",
      "Batch: 60, Loss: 0.8867976069450378, Accuracy: 0.716796875\n",
      "Batch: 61, Loss: 0.995011568069458, Accuracy: 0.662109375\n",
      "Batch: 62, Loss: 0.9433718919754028, Accuracy: 0.6826171875\n",
      "Batch: 63, Loss: 0.9906673431396484, Accuracy: 0.6865234375\n",
      "Batch: 64, Loss: 0.9464491605758667, Accuracy: 0.6826171875\n",
      "Batch: 65, Loss: 0.9699603915214539, Accuracy: 0.7080078125\n",
      "Batch: 66, Loss: 0.9214757680892944, Accuracy: 0.7041015625\n",
      "Batch: 67, Loss: 1.059016227722168, Accuracy: 0.6572265625\n",
      "Batch: 68, Loss: 1.0562524795532227, Accuracy: 0.68359375\n",
      "Batch: 69, Loss: 0.9746658802032471, Accuracy: 0.66796875\n",
      "Batch: 70, Loss: 0.9511370658874512, Accuracy: 0.69921875\n",
      "Batch: 71, Loss: 1.01407790184021, Accuracy: 0.66796875\n",
      "Batch: 72, Loss: 0.87253737449646, Accuracy: 0.701171875\n",
      "Batch: 73, Loss: 0.9093332886695862, Accuracy: 0.701171875\n",
      "Batch: 74, Loss: 0.9209597706794739, Accuracy: 0.69140625\n",
      "Batch: 75, Loss: 0.8720247745513916, Accuracy: 0.7265625\n",
      "Batch: 76, Loss: 0.9874975681304932, Accuracy: 0.6669921875\n",
      "Batch: 77, Loss: 0.9277006983757019, Accuracy: 0.693359375\n",
      "Batch: 78, Loss: 0.9140520691871643, Accuracy: 0.712890625\n",
      "Batch: 79, Loss: 0.8502750396728516, Accuracy: 0.732421875\n",
      "Batch: 80, Loss: 0.919312596321106, Accuracy: 0.703125\n",
      "Batch: 81, Loss: 1.0559041500091553, Accuracy: 0.6416015625\n",
      "Batch: 82, Loss: 0.9911800026893616, Accuracy: 0.66796875\n",
      "Batch: 83, Loss: 0.8595415949821472, Accuracy: 0.712890625\n",
      "Batch: 84, Loss: 0.9528799653053284, Accuracy: 0.69140625\n",
      "Batch: 85, Loss: 0.8652703166007996, Accuracy: 0.7314453125\n",
      "Batch: 86, Loss: 1.1059050559997559, Accuracy: 0.650390625\n",
      "Batch: 87, Loss: 0.911620557308197, Accuracy: 0.7060546875\n",
      "Batch: 88, Loss: 1.0177409648895264, Accuracy: 0.6953125\n",
      "Batch: 89, Loss: 1.0053802728652954, Accuracy: 0.67578125\n",
      "Batch: 90, Loss: 0.8939943313598633, Accuracy: 0.701171875\n",
      "Batch: 91, Loss: 0.9441649913787842, Accuracy: 0.6875\n",
      "Batch: 92, Loss: 0.9656175374984741, Accuracy: 0.6923828125\n",
      "Batch: 93, Loss: 0.8947018384933472, Accuracy: 0.7119140625\n",
      "Batch: 94, Loss: 0.9091763496398926, Accuracy: 0.7109375\n",
      "Batch: 95, Loss: 0.9708324670791626, Accuracy: 0.6669921875\n",
      "Batch: 96, Loss: 0.9591173529624939, Accuracy: 0.685546875\n",
      "Batch: 97, Loss: 0.7952524423599243, Accuracy: 0.73828125\n",
      "Batch: 98, Loss: 0.8846422433853149, Accuracy: 0.71875\n",
      "Batch: 99, Loss: 0.9129850268363953, Accuracy: 0.701171875\n",
      "Batch: 100, Loss: 0.9654138088226318, Accuracy: 0.681640625\n",
      "Batch: 101, Loss: 1.0046907663345337, Accuracy: 0.673828125\n",
      "Batch: 102, Loss: 0.9347258806228638, Accuracy: 0.6904296875\n",
      "Batch: 103, Loss: 0.9943994283676147, Accuracy: 0.69921875\n",
      "Batch: 104, Loss: 0.892169713973999, Accuracy: 0.7041015625\n",
      "Batch: 105, Loss: 0.9833226203918457, Accuracy: 0.6865234375\n",
      "Batch: 106, Loss: 0.9303774833679199, Accuracy: 0.703125\n",
      "Batch: 107, Loss: 1.0231101512908936, Accuracy: 0.6748046875\n",
      "Batch: 108, Loss: 0.953365683555603, Accuracy: 0.681640625\n",
      "Batch: 109, Loss: 1.0866453647613525, Accuracy: 0.6396484375\n",
      "Batch: 110, Loss: 0.8239917755126953, Accuracy: 0.71875\n",
      "Batch: 111, Loss: 1.0045236349105835, Accuracy: 0.6748046875\n",
      "Batch: 112, Loss: 0.956157922744751, Accuracy: 0.6943359375\n",
      "Batch: 113, Loss: 0.9855728149414062, Accuracy: 0.6953125\n",
      "Batch: 114, Loss: 1.0527558326721191, Accuracy: 0.658203125\n",
      "Batch: 115, Loss: 1.0990371704101562, Accuracy: 0.662109375\n",
      "Batch: 116, Loss: 0.9999103546142578, Accuracy: 0.681640625\n",
      "Batch: 117, Loss: 1.0553503036499023, Accuracy: 0.6689453125\n",
      "Batch: 118, Loss: 0.8738595843315125, Accuracy: 0.71875\n",
      "Batch: 119, Loss: 0.8575674295425415, Accuracy: 0.7216796875\n",
      "Batch: 120, Loss: 0.9826316833496094, Accuracy: 0.6728515625\n",
      "Batch: 121, Loss: 1.018966794013977, Accuracy: 0.6591796875\n",
      "Batch: 122, Loss: 0.9262427091598511, Accuracy: 0.6953125\n",
      "Batch: 123, Loss: 0.9214723110198975, Accuracy: 0.7021484375\n",
      "Batch: 124, Loss: 1.0180678367614746, Accuracy: 0.6630859375\n",
      "Batch: 125, Loss: 1.00921630859375, Accuracy: 0.66015625\n",
      "Batch: 126, Loss: 0.9909065365791321, Accuracy: 0.6806640625\n",
      "Batch: 127, Loss: 0.8485861420631409, Accuracy: 0.72265625\n",
      "Batch: 128, Loss: 1.081093192100525, Accuracy: 0.66015625\n",
      "Batch: 129, Loss: 0.943205714225769, Accuracy: 0.6884765625\n",
      "Batch: 130, Loss: 1.1401262283325195, Accuracy: 0.646484375\n",
      "Batch: 131, Loss: 1.0419968366622925, Accuracy: 0.662109375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 132, Loss: 1.0360891819000244, Accuracy: 0.6708984375\n",
      "Batch: 133, Loss: 0.9270926117897034, Accuracy: 0.6884765625\n",
      "Batch: 134, Loss: 0.9600487947463989, Accuracy: 0.6796875\n",
      "Batch: 135, Loss: 0.8840575218200684, Accuracy: 0.705078125\n",
      "Batch: 136, Loss: 0.9438146948814392, Accuracy: 0.6865234375\n",
      "Batch: 137, Loss: 0.9097414016723633, Accuracy: 0.6884765625\n",
      "Batch: 138, Loss: 0.8154608607292175, Accuracy: 0.71875\n",
      "Batch: 139, Loss: 0.8666418790817261, Accuracy: 0.70703125\n",
      "Batch: 140, Loss: 0.9620605111122131, Accuracy: 0.6748046875\n",
      "Batch: 141, Loss: 1.008748173713684, Accuracy: 0.666015625\n",
      "Batch: 142, Loss: 1.0239912271499634, Accuracy: 0.6650390625\n",
      "Batch: 143, Loss: 0.9666880965232849, Accuracy: 0.673828125\n",
      "Batch: 144, Loss: 0.9597556591033936, Accuracy: 0.685546875\n",
      "Batch: 145, Loss: 0.9122070074081421, Accuracy: 0.705078125\n",
      "Batch: 146, Loss: 0.9788862466812134, Accuracy: 0.6875\n",
      "Batch: 147, Loss: 0.9914470911026001, Accuracy: 0.677734375\n",
      "Batch: 148, Loss: 1.0959391593933105, Accuracy: 0.6416015625\n",
      "Batch: 149, Loss: 0.9596785306930542, Accuracy: 0.6787109375\n",
      "Batch: 150, Loss: 0.8867814540863037, Accuracy: 0.7060546875\n",
      "Batch: 151, Loss: 0.8103158473968506, Accuracy: 0.7431640625\n",
      "Epoch 19/90\n",
      "Batch: 1, Loss: 1.192327618598938, Accuracy: 0.607421875\n",
      "Batch: 2, Loss: 1.0462572574615479, Accuracy: 0.6396484375\n",
      "Batch: 3, Loss: 0.9052832126617432, Accuracy: 0.69921875\n",
      "Batch: 4, Loss: 0.8346402049064636, Accuracy: 0.728515625\n",
      "Batch: 5, Loss: 0.8821990489959717, Accuracy: 0.724609375\n",
      "Batch: 6, Loss: 0.9602543711662292, Accuracy: 0.673828125\n",
      "Batch: 7, Loss: 0.935509443283081, Accuracy: 0.6845703125\n",
      "Batch: 8, Loss: 0.8988780975341797, Accuracy: 0.7060546875\n",
      "Batch: 9, Loss: 0.8498908281326294, Accuracy: 0.724609375\n",
      "Batch: 10, Loss: 0.8605891466140747, Accuracy: 0.72265625\n",
      "Batch: 11, Loss: 1.0492331981658936, Accuracy: 0.6552734375\n",
      "Batch: 12, Loss: 1.0465086698532104, Accuracy: 0.65625\n",
      "Batch: 13, Loss: 0.796937108039856, Accuracy: 0.73046875\n",
      "Batch: 14, Loss: 1.0516725778579712, Accuracy: 0.646484375\n",
      "Batch: 15, Loss: 0.8819547295570374, Accuracy: 0.72265625\n",
      "Batch: 16, Loss: 0.8892168998718262, Accuracy: 0.72265625\n",
      "Batch: 17, Loss: 0.9890278577804565, Accuracy: 0.6630859375\n",
      "Batch: 18, Loss: 0.9949353337287903, Accuracy: 0.673828125\n",
      "Batch: 19, Loss: 1.0291366577148438, Accuracy: 0.6796875\n",
      "Batch: 20, Loss: 0.8710355758666992, Accuracy: 0.724609375\n",
      "Batch: 21, Loss: 0.8908844590187073, Accuracy: 0.712890625\n",
      "Batch: 22, Loss: 1.0179330110549927, Accuracy: 0.6669921875\n",
      "Batch: 23, Loss: 0.9614797830581665, Accuracy: 0.6982421875\n",
      "Batch: 24, Loss: 0.9319052696228027, Accuracy: 0.685546875\n",
      "Batch: 25, Loss: 0.9509820342063904, Accuracy: 0.6962890625\n",
      "Batch: 26, Loss: 0.8288919925689697, Accuracy: 0.7197265625\n",
      "Batch: 27, Loss: 0.8778631687164307, Accuracy: 0.6904296875\n",
      "Batch: 28, Loss: 0.9611645340919495, Accuracy: 0.6689453125\n",
      "Batch: 29, Loss: 0.9427077174186707, Accuracy: 0.6650390625\n",
      "Batch: 30, Loss: 0.8688909411430359, Accuracy: 0.7177734375\n",
      "Batch: 31, Loss: 0.8517829179763794, Accuracy: 0.7197265625\n",
      "Batch: 32, Loss: 0.8749395608901978, Accuracy: 0.7021484375\n",
      "Batch: 33, Loss: 1.0412535667419434, Accuracy: 0.6572265625\n",
      "Batch: 34, Loss: 1.083107829093933, Accuracy: 0.65234375\n",
      "Batch: 35, Loss: 0.9895935654640198, Accuracy: 0.677734375\n",
      "Batch: 36, Loss: 1.0150740146636963, Accuracy: 0.6806640625\n",
      "Batch: 37, Loss: 0.9372236132621765, Accuracy: 0.6884765625\n",
      "Batch: 38, Loss: 0.9677910804748535, Accuracy: 0.669921875\n",
      "Batch: 39, Loss: 0.9486762285232544, Accuracy: 0.69921875\n",
      "Batch: 40, Loss: 0.9768838286399841, Accuracy: 0.693359375\n",
      "Batch: 41, Loss: 0.9437786340713501, Accuracy: 0.697265625\n",
      "Batch: 42, Loss: 0.7290903329849243, Accuracy: 0.744140625\n",
      "Batch: 43, Loss: 0.9971739053726196, Accuracy: 0.6611328125\n",
      "Batch: 44, Loss: 0.9838488101959229, Accuracy: 0.6845703125\n",
      "Batch: 45, Loss: 0.8313064575195312, Accuracy: 0.728515625\n",
      "Batch: 46, Loss: 0.9362645745277405, Accuracy: 0.703125\n",
      "Batch: 47, Loss: 0.9109592437744141, Accuracy: 0.7177734375\n",
      "Batch: 48, Loss: 0.8586989641189575, Accuracy: 0.720703125\n",
      "Batch: 49, Loss: 1.0425026416778564, Accuracy: 0.658203125\n",
      "Batch: 50, Loss: 1.0189318656921387, Accuracy: 0.6640625\n",
      "Batch: 51, Loss: 1.0503337383270264, Accuracy: 0.669921875\n",
      "Batch: 52, Loss: 0.9960916638374329, Accuracy: 0.6708984375\n",
      "Batch: 53, Loss: 0.8666641712188721, Accuracy: 0.69921875\n",
      "Batch: 54, Loss: 0.9382197856903076, Accuracy: 0.69140625\n",
      "Batch: 55, Loss: 1.0325344800949097, Accuracy: 0.6474609375\n",
      "Batch: 56, Loss: 0.9933764934539795, Accuracy: 0.6865234375\n",
      "Batch: 57, Loss: 0.9260885119438171, Accuracy: 0.69921875\n",
      "Batch: 58, Loss: 1.0029144287109375, Accuracy: 0.685546875\n",
      "Batch: 59, Loss: 0.9152149558067322, Accuracy: 0.7177734375\n",
      "Batch: 60, Loss: 0.8519105911254883, Accuracy: 0.7099609375\n",
      "Batch: 61, Loss: 0.9602088928222656, Accuracy: 0.677734375\n",
      "Batch: 62, Loss: 0.9143704771995544, Accuracy: 0.6982421875\n",
      "Batch: 63, Loss: 0.9386236667633057, Accuracy: 0.6962890625\n",
      "Batch: 64, Loss: 0.9479796290397644, Accuracy: 0.68359375\n",
      "Batch: 65, Loss: 0.9758564233779907, Accuracy: 0.6962890625\n",
      "Batch: 66, Loss: 0.8987017869949341, Accuracy: 0.705078125\n",
      "Batch: 67, Loss: 1.0328681468963623, Accuracy: 0.666015625\n",
      "Batch: 68, Loss: 1.0166255235671997, Accuracy: 0.6806640625\n",
      "Batch: 69, Loss: 0.96781325340271, Accuracy: 0.6689453125\n",
      "Batch: 70, Loss: 0.9506165385246277, Accuracy: 0.7099609375\n",
      "Batch: 71, Loss: 0.9838537573814392, Accuracy: 0.6875\n",
      "Batch: 72, Loss: 0.8405575752258301, Accuracy: 0.71484375\n",
      "Batch: 73, Loss: 0.8847129344940186, Accuracy: 0.7099609375\n",
      "Batch: 74, Loss: 0.8721978664398193, Accuracy: 0.7158203125\n",
      "Batch: 75, Loss: 0.8480639457702637, Accuracy: 0.7275390625\n",
      "Batch: 76, Loss: 0.9569107294082642, Accuracy: 0.673828125\n",
      "Batch: 77, Loss: 0.898068904876709, Accuracy: 0.7021484375\n",
      "Batch: 78, Loss: 0.8792737722396851, Accuracy: 0.7255859375\n",
      "Batch: 79, Loss: 0.8465483784675598, Accuracy: 0.7392578125\n",
      "Batch: 80, Loss: 0.8925319910049438, Accuracy: 0.6904296875\n",
      "Batch: 81, Loss: 1.0188095569610596, Accuracy: 0.6552734375\n",
      "Batch: 82, Loss: 0.9718301296234131, Accuracy: 0.6826171875\n",
      "Batch: 83, Loss: 0.8409135341644287, Accuracy: 0.7255859375\n",
      "Batch: 84, Loss: 0.9028160572052002, Accuracy: 0.7265625\n",
      "Batch: 85, Loss: 0.8432750105857849, Accuracy: 0.7265625\n",
      "Batch: 86, Loss: 1.0899112224578857, Accuracy: 0.6484375\n",
      "Batch: 87, Loss: 0.8947207927703857, Accuracy: 0.72265625\n",
      "Batch: 88, Loss: 0.9938524961471558, Accuracy: 0.689453125\n",
      "Batch: 89, Loss: 0.998633861541748, Accuracy: 0.6865234375\n",
      "Batch: 90, Loss: 0.8650118708610535, Accuracy: 0.72265625\n",
      "Batch: 91, Loss: 0.9439327716827393, Accuracy: 0.6923828125\n",
      "Batch: 92, Loss: 0.939995527267456, Accuracy: 0.6953125\n",
      "Batch: 93, Loss: 0.8791916370391846, Accuracy: 0.7021484375\n",
      "Batch: 94, Loss: 0.9086819887161255, Accuracy: 0.6962890625\n",
      "Batch: 95, Loss: 0.9621041417121887, Accuracy: 0.66796875\n",
      "Batch: 96, Loss: 0.9321895241737366, Accuracy: 0.6962890625\n",
      "Batch: 97, Loss: 0.7982136011123657, Accuracy: 0.736328125\n",
      "Batch: 98, Loss: 0.8546500205993652, Accuracy: 0.7353515625\n",
      "Batch: 99, Loss: 0.8657223582267761, Accuracy: 0.7265625\n",
      "Batch: 100, Loss: 0.9281595945358276, Accuracy: 0.7060546875\n",
      "Batch: 101, Loss: 0.9835386276245117, Accuracy: 0.6767578125\n",
      "Batch: 102, Loss: 0.8993257284164429, Accuracy: 0.7119140625\n",
      "Batch: 103, Loss: 0.9526987075805664, Accuracy: 0.7021484375\n",
      "Batch: 104, Loss: 0.8908951282501221, Accuracy: 0.6962890625\n",
      "Batch: 105, Loss: 0.9799037575721741, Accuracy: 0.6875\n",
      "Batch: 106, Loss: 0.9064065217971802, Accuracy: 0.7021484375\n",
      "Batch: 107, Loss: 0.948482871055603, Accuracy: 0.6845703125\n",
      "Batch: 108, Loss: 0.9510658383369446, Accuracy: 0.671875\n",
      "Batch: 109, Loss: 1.0641775131225586, Accuracy: 0.6279296875\n",
      "Batch: 110, Loss: 0.814682126045227, Accuracy: 0.736328125\n",
      "Batch: 111, Loss: 0.9912463426589966, Accuracy: 0.6669921875\n",
      "Batch: 112, Loss: 0.9239733219146729, Accuracy: 0.7060546875\n",
      "Batch: 113, Loss: 0.9659861922264099, Accuracy: 0.6865234375\n",
      "Batch: 114, Loss: 1.0463790893554688, Accuracy: 0.65625\n",
      "Batch: 115, Loss: 1.054435133934021, Accuracy: 0.6669921875\n",
      "Batch: 116, Loss: 0.9822300672531128, Accuracy: 0.68359375\n",
      "Batch: 117, Loss: 1.0021932125091553, Accuracy: 0.6748046875\n",
      "Batch: 118, Loss: 0.8506067395210266, Accuracy: 0.73046875\n",
      "Batch: 119, Loss: 0.7921386361122131, Accuracy: 0.7490234375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 120, Loss: 0.9841293692588806, Accuracy: 0.6884765625\n",
      "Batch: 121, Loss: 0.9824116230010986, Accuracy: 0.6875\n",
      "Batch: 122, Loss: 0.9118492603302002, Accuracy: 0.7001953125\n",
      "Batch: 123, Loss: 0.8857792019844055, Accuracy: 0.7275390625\n",
      "Batch: 124, Loss: 0.9478505849838257, Accuracy: 0.671875\n",
      "Batch: 125, Loss: 0.9692709445953369, Accuracy: 0.6689453125\n",
      "Batch: 126, Loss: 0.9700889587402344, Accuracy: 0.6806640625\n",
      "Batch: 127, Loss: 0.8317638635635376, Accuracy: 0.736328125\n",
      "Batch: 128, Loss: 1.0374341011047363, Accuracy: 0.66796875\n",
      "Batch: 129, Loss: 0.9244271516799927, Accuracy: 0.6962890625\n",
      "Batch: 130, Loss: 1.1013150215148926, Accuracy: 0.650390625\n",
      "Batch: 131, Loss: 0.978948712348938, Accuracy: 0.6689453125\n",
      "Batch: 132, Loss: 1.036048412322998, Accuracy: 0.6611328125\n",
      "Batch: 133, Loss: 0.8836352229118347, Accuracy: 0.697265625\n",
      "Batch: 134, Loss: 0.9590286016464233, Accuracy: 0.6796875\n",
      "Batch: 135, Loss: 0.8608580827713013, Accuracy: 0.720703125\n",
      "Batch: 136, Loss: 0.9515997171401978, Accuracy: 0.7060546875\n",
      "Batch: 137, Loss: 0.8900302052497864, Accuracy: 0.697265625\n",
      "Batch: 138, Loss: 0.7992203831672668, Accuracy: 0.7197265625\n",
      "Batch: 139, Loss: 0.8564555644989014, Accuracy: 0.7197265625\n",
      "Batch: 140, Loss: 0.9368985295295715, Accuracy: 0.677734375\n",
      "Batch: 141, Loss: 0.9858798980712891, Accuracy: 0.6826171875\n",
      "Batch: 142, Loss: 1.015313982963562, Accuracy: 0.6748046875\n",
      "Batch: 143, Loss: 0.9710100889205933, Accuracy: 0.685546875\n",
      "Batch: 144, Loss: 0.9613443613052368, Accuracy: 0.6767578125\n",
      "Batch: 145, Loss: 0.8991777896881104, Accuracy: 0.68359375\n",
      "Batch: 146, Loss: 0.9701647758483887, Accuracy: 0.689453125\n",
      "Batch: 147, Loss: 0.9757007360458374, Accuracy: 0.671875\n",
      "Batch: 148, Loss: 1.0828115940093994, Accuracy: 0.63671875\n",
      "Batch: 149, Loss: 0.9403020143508911, Accuracy: 0.6796875\n",
      "Batch: 150, Loss: 0.867942750453949, Accuracy: 0.7080078125\n",
      "Batch: 151, Loss: 0.8215476274490356, Accuracy: 0.7373046875\n",
      "Epoch 20/90\n",
      "Batch: 1, Loss: 1.1675708293914795, Accuracy: 0.6240234375\n",
      "Batch: 2, Loss: 1.0107184648513794, Accuracy: 0.658203125\n",
      "Batch: 3, Loss: 0.8881512880325317, Accuracy: 0.697265625\n",
      "Batch: 4, Loss: 0.8220016360282898, Accuracy: 0.7255859375\n",
      "Batch: 5, Loss: 0.8400171399116516, Accuracy: 0.7216796875\n",
      "Batch: 6, Loss: 0.940885603427887, Accuracy: 0.69140625\n",
      "Batch: 7, Loss: 0.9313696026802063, Accuracy: 0.677734375\n",
      "Batch: 8, Loss: 0.8664312958717346, Accuracy: 0.70703125\n",
      "Batch: 9, Loss: 0.8447374105453491, Accuracy: 0.7353515625\n",
      "Batch: 10, Loss: 0.8394191265106201, Accuracy: 0.724609375\n",
      "Batch: 11, Loss: 1.0326447486877441, Accuracy: 0.6552734375\n",
      "Batch: 12, Loss: 1.006540298461914, Accuracy: 0.6630859375\n",
      "Batch: 13, Loss: 0.7835159301757812, Accuracy: 0.732421875\n",
      "Batch: 14, Loss: 1.0377516746520996, Accuracy: 0.6396484375\n",
      "Batch: 15, Loss: 0.8547565937042236, Accuracy: 0.7275390625\n",
      "Batch: 16, Loss: 0.8990048170089722, Accuracy: 0.705078125\n",
      "Batch: 17, Loss: 0.9711349010467529, Accuracy: 0.68359375\n",
      "Batch: 18, Loss: 0.9704546928405762, Accuracy: 0.6875\n",
      "Batch: 19, Loss: 1.02471125125885, Accuracy: 0.6708984375\n",
      "Batch: 20, Loss: 0.8802143335342407, Accuracy: 0.728515625\n",
      "Batch: 21, Loss: 0.8772075772285461, Accuracy: 0.716796875\n",
      "Batch: 22, Loss: 0.9860392808914185, Accuracy: 0.6865234375\n",
      "Batch: 23, Loss: 0.9316794872283936, Accuracy: 0.689453125\n",
      "Batch: 24, Loss: 0.920437216758728, Accuracy: 0.697265625\n",
      "Batch: 25, Loss: 0.9560573101043701, Accuracy: 0.6962890625\n",
      "Batch: 26, Loss: 0.8005008101463318, Accuracy: 0.7314453125\n",
      "Batch: 27, Loss: 0.8485862016677856, Accuracy: 0.7119140625\n",
      "Batch: 28, Loss: 0.9461740255355835, Accuracy: 0.6865234375\n",
      "Batch: 29, Loss: 0.9052258729934692, Accuracy: 0.720703125\n",
      "Batch: 30, Loss: 0.8522189259529114, Accuracy: 0.71875\n",
      "Batch: 31, Loss: 0.8433327078819275, Accuracy: 0.7236328125\n",
      "Batch: 32, Loss: 0.8447031378746033, Accuracy: 0.71875\n",
      "Batch: 33, Loss: 0.9818066358566284, Accuracy: 0.6728515625\n",
      "Batch: 34, Loss: 1.056321620941162, Accuracy: 0.6630859375\n",
      "Batch: 35, Loss: 0.9636552333831787, Accuracy: 0.6865234375\n",
      "Batch: 36, Loss: 0.9728730320930481, Accuracy: 0.6943359375\n",
      "Batch: 37, Loss: 0.9412415623664856, Accuracy: 0.6982421875\n",
      "Batch: 38, Loss: 0.9849412441253662, Accuracy: 0.669921875\n",
      "Batch: 39, Loss: 0.9410498142242432, Accuracy: 0.693359375\n",
      "Batch: 40, Loss: 0.9305845499038696, Accuracy: 0.7099609375\n",
      "Batch: 41, Loss: 0.9118657112121582, Accuracy: 0.7236328125\n",
      "Batch: 42, Loss: 0.7351428866386414, Accuracy: 0.7470703125\n",
      "Batch: 43, Loss: 0.9700611233711243, Accuracy: 0.6748046875\n",
      "Batch: 44, Loss: 0.9738506078720093, Accuracy: 0.677734375\n",
      "Batch: 45, Loss: 0.8136667013168335, Accuracy: 0.71875\n",
      "Batch: 46, Loss: 0.9029843807220459, Accuracy: 0.70703125\n",
      "Batch: 47, Loss: 0.8774023652076721, Accuracy: 0.7275390625\n",
      "Batch: 48, Loss: 0.8249683380126953, Accuracy: 0.7294921875\n",
      "Batch: 49, Loss: 0.9860777854919434, Accuracy: 0.68359375\n",
      "Batch: 50, Loss: 0.9918232560157776, Accuracy: 0.6845703125\n",
      "Batch: 51, Loss: 1.0137593746185303, Accuracy: 0.6611328125\n",
      "Batch: 52, Loss: 0.9818447828292847, Accuracy: 0.6875\n",
      "Batch: 53, Loss: 0.8388615846633911, Accuracy: 0.7265625\n",
      "Batch: 54, Loss: 0.9190828800201416, Accuracy: 0.7021484375\n",
      "Batch: 55, Loss: 0.991680920124054, Accuracy: 0.6708984375\n",
      "Batch: 56, Loss: 0.9473787546157837, Accuracy: 0.697265625\n",
      "Batch: 57, Loss: 0.9061183929443359, Accuracy: 0.69921875\n",
      "Batch: 58, Loss: 1.0011606216430664, Accuracy: 0.6982421875\n",
      "Batch: 59, Loss: 0.8941910862922668, Accuracy: 0.7109375\n",
      "Batch: 60, Loss: 0.8481748104095459, Accuracy: 0.7333984375\n",
      "Batch: 61, Loss: 0.9515658617019653, Accuracy: 0.6865234375\n",
      "Batch: 62, Loss: 0.907600998878479, Accuracy: 0.708984375\n",
      "Batch: 63, Loss: 0.9499543905258179, Accuracy: 0.69921875\n",
      "Batch: 64, Loss: 0.9156020879745483, Accuracy: 0.7060546875\n",
      "Batch: 65, Loss: 0.9437912106513977, Accuracy: 0.7119140625\n",
      "Batch: 66, Loss: 0.8767651915550232, Accuracy: 0.724609375\n",
      "Batch: 67, Loss: 1.0192654132843018, Accuracy: 0.6611328125\n",
      "Batch: 68, Loss: 1.0058634281158447, Accuracy: 0.6806640625\n",
      "Batch: 69, Loss: 0.9511818885803223, Accuracy: 0.6904296875\n",
      "Batch: 70, Loss: 0.9161456823348999, Accuracy: 0.7109375\n",
      "Batch: 71, Loss: 0.9651776552200317, Accuracy: 0.6767578125\n",
      "Batch: 72, Loss: 0.8202293515205383, Accuracy: 0.72265625\n",
      "Batch: 73, Loss: 0.8646003603935242, Accuracy: 0.7236328125\n",
      "Batch: 74, Loss: 0.8559202551841736, Accuracy: 0.7216796875\n",
      "Batch: 75, Loss: 0.8167926669120789, Accuracy: 0.734375\n",
      "Batch: 76, Loss: 0.9439164400100708, Accuracy: 0.6767578125\n",
      "Batch: 77, Loss: 0.902729868888855, Accuracy: 0.7109375\n",
      "Batch: 78, Loss: 0.8640035390853882, Accuracy: 0.72265625\n",
      "Batch: 79, Loss: 0.8112564086914062, Accuracy: 0.7470703125\n",
      "Batch: 80, Loss: 0.8537457585334778, Accuracy: 0.6982421875\n",
      "Batch: 81, Loss: 1.0087451934814453, Accuracy: 0.658203125\n",
      "Batch: 82, Loss: 0.9508792161941528, Accuracy: 0.7001953125\n",
      "Batch: 83, Loss: 0.8206164836883545, Accuracy: 0.7392578125\n",
      "Batch: 84, Loss: 0.894025981426239, Accuracy: 0.716796875\n",
      "Batch: 85, Loss: 0.7995107173919678, Accuracy: 0.751953125\n",
      "Batch: 86, Loss: 1.0056746006011963, Accuracy: 0.6875\n",
      "Batch: 87, Loss: 0.8560859560966492, Accuracy: 0.71875\n",
      "Batch: 88, Loss: 0.962922215461731, Accuracy: 0.701171875\n",
      "Batch: 89, Loss: 0.9654490947723389, Accuracy: 0.6904296875\n",
      "Batch: 90, Loss: 0.8540347218513489, Accuracy: 0.7158203125\n",
      "Batch: 91, Loss: 0.9005818367004395, Accuracy: 0.701171875\n",
      "Batch: 92, Loss: 0.9026823043823242, Accuracy: 0.705078125\n",
      "Batch: 93, Loss: 0.8702417612075806, Accuracy: 0.716796875\n",
      "Batch: 94, Loss: 0.8846355676651001, Accuracy: 0.7099609375\n",
      "Batch: 95, Loss: 0.945318341255188, Accuracy: 0.6826171875\n",
      "Batch: 96, Loss: 0.9250925779342651, Accuracy: 0.6943359375\n",
      "Batch: 97, Loss: 0.7472999095916748, Accuracy: 0.74609375\n",
      "Batch: 98, Loss: 0.8362607359886169, Accuracy: 0.7294921875\n",
      "Batch: 99, Loss: 0.8687262535095215, Accuracy: 0.7177734375\n",
      "Batch: 100, Loss: 0.9172932505607605, Accuracy: 0.71484375\n",
      "Batch: 101, Loss: 0.9855327606201172, Accuracy: 0.6728515625\n",
      "Batch: 102, Loss: 0.8835012912750244, Accuracy: 0.7197265625\n",
      "Batch: 103, Loss: 0.9137781858444214, Accuracy: 0.71484375\n",
      "Batch: 104, Loss: 0.8764390349388123, Accuracy: 0.7041015625\n",
      "Batch: 105, Loss: 0.9252668619155884, Accuracy: 0.7119140625\n",
      "Batch: 106, Loss: 0.891710638999939, Accuracy: 0.7109375\n",
      "Batch: 107, Loss: 0.9252373576164246, Accuracy: 0.7060546875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 108, Loss: 0.9095383286476135, Accuracy: 0.69140625\n",
      "Batch: 109, Loss: 0.9888007044792175, Accuracy: 0.68359375\n",
      "Batch: 110, Loss: 0.8125295639038086, Accuracy: 0.72265625\n",
      "Batch: 111, Loss: 0.9661014080047607, Accuracy: 0.673828125\n",
      "Batch: 112, Loss: 0.8906921148300171, Accuracy: 0.7099609375\n",
      "Batch: 113, Loss: 0.9201523065567017, Accuracy: 0.7080078125\n",
      "Batch: 114, Loss: 0.9949862957000732, Accuracy: 0.6796875\n",
      "Batch: 115, Loss: 1.0457018613815308, Accuracy: 0.67578125\n",
      "Batch: 116, Loss: 0.988417387008667, Accuracy: 0.6767578125\n",
      "Batch: 117, Loss: 0.9776254296302795, Accuracy: 0.6865234375\n",
      "Batch: 118, Loss: 0.8181588649749756, Accuracy: 0.728515625\n",
      "Batch: 119, Loss: 0.7900809049606323, Accuracy: 0.740234375\n",
      "Batch: 120, Loss: 0.9397141933441162, Accuracy: 0.6884765625\n",
      "Batch: 121, Loss: 0.968569815158844, Accuracy: 0.6806640625\n",
      "Batch: 122, Loss: 0.8637810349464417, Accuracy: 0.7314453125\n",
      "Batch: 123, Loss: 0.8543239831924438, Accuracy: 0.7197265625\n",
      "Batch: 124, Loss: 0.945852518081665, Accuracy: 0.6923828125\n",
      "Batch: 125, Loss: 0.9711935520172119, Accuracy: 0.685546875\n",
      "Batch: 126, Loss: 0.9373106360435486, Accuracy: 0.6796875\n",
      "Batch: 127, Loss: 0.8010860085487366, Accuracy: 0.751953125\n",
      "Batch: 128, Loss: 1.0105887651443481, Accuracy: 0.68359375\n",
      "Batch: 129, Loss: 0.9009596705436707, Accuracy: 0.7060546875\n",
      "Batch: 130, Loss: 1.0698593854904175, Accuracy: 0.6572265625\n",
      "Batch: 131, Loss: 0.9568936228752136, Accuracy: 0.693359375\n",
      "Batch: 132, Loss: 0.985945463180542, Accuracy: 0.6865234375\n",
      "Batch: 133, Loss: 0.8607414960861206, Accuracy: 0.7099609375\n",
      "Batch: 134, Loss: 0.913409948348999, Accuracy: 0.693359375\n",
      "Batch: 135, Loss: 0.8231839537620544, Accuracy: 0.73828125\n",
      "Batch: 136, Loss: 0.9178417325019836, Accuracy: 0.7060546875\n",
      "Batch: 137, Loss: 0.8722786903381348, Accuracy: 0.7158203125\n",
      "Batch: 138, Loss: 0.785211980342865, Accuracy: 0.73828125\n",
      "Batch: 139, Loss: 0.8303917646408081, Accuracy: 0.720703125\n",
      "Batch: 140, Loss: 0.9246187210083008, Accuracy: 0.6904296875\n",
      "Batch: 141, Loss: 0.9579097032546997, Accuracy: 0.703125\n",
      "Batch: 142, Loss: 0.9747782945632935, Accuracy: 0.6767578125\n",
      "Batch: 143, Loss: 0.9382885098457336, Accuracy: 0.6787109375\n",
      "Batch: 144, Loss: 0.928874135017395, Accuracy: 0.6953125\n",
      "Batch: 145, Loss: 0.8863722681999207, Accuracy: 0.697265625\n",
      "Batch: 146, Loss: 0.9530450105667114, Accuracy: 0.69140625\n",
      "Batch: 147, Loss: 0.9520847797393799, Accuracy: 0.685546875\n",
      "Batch: 148, Loss: 1.0386971235275269, Accuracy: 0.6484375\n",
      "Batch: 149, Loss: 0.9123637676239014, Accuracy: 0.6875\n",
      "Batch: 150, Loss: 0.8485405445098877, Accuracy: 0.70703125\n",
      "Batch: 151, Loss: 0.7787352204322815, Accuracy: 0.7509765625\n",
      "Saved Weights at epoch 20 to file Weights_20.h5\n",
      "Epoch 21/90\n",
      "Batch: 1, Loss: 1.1358795166015625, Accuracy: 0.640625\n",
      "Batch: 2, Loss: 0.9952012300491333, Accuracy: 0.6640625\n",
      "Batch: 3, Loss: 0.8561571836471558, Accuracy: 0.7158203125\n",
      "Batch: 4, Loss: 0.7845423221588135, Accuracy: 0.728515625\n",
      "Batch: 5, Loss: 0.826227605342865, Accuracy: 0.73046875\n",
      "Batch: 6, Loss: 0.9353326559066772, Accuracy: 0.6884765625\n",
      "Batch: 7, Loss: 0.9093363881111145, Accuracy: 0.6953125\n",
      "Batch: 8, Loss: 0.870032548904419, Accuracy: 0.7041015625\n",
      "Batch: 9, Loss: 0.8240060210227966, Accuracy: 0.7421875\n",
      "Batch: 10, Loss: 0.830864667892456, Accuracy: 0.7353515625\n",
      "Batch: 11, Loss: 1.0132973194122314, Accuracy: 0.67578125\n",
      "Batch: 12, Loss: 0.972901463508606, Accuracy: 0.6875\n",
      "Batch: 13, Loss: 0.7622945308685303, Accuracy: 0.7529296875\n",
      "Batch: 14, Loss: 1.0274381637573242, Accuracy: 0.6591796875\n",
      "Batch: 15, Loss: 0.8557586669921875, Accuracy: 0.740234375\n",
      "Batch: 16, Loss: 0.8752429485321045, Accuracy: 0.7119140625\n",
      "Batch: 17, Loss: 0.9322453737258911, Accuracy: 0.6845703125\n",
      "Batch: 18, Loss: 0.9232968091964722, Accuracy: 0.6865234375\n",
      "Batch: 19, Loss: 1.012476921081543, Accuracy: 0.6787109375\n",
      "Batch: 20, Loss: 0.8200134038925171, Accuracy: 0.7421875\n",
      "Batch: 21, Loss: 0.8542966842651367, Accuracy: 0.7177734375\n",
      "Batch: 22, Loss: 0.9502206444740295, Accuracy: 0.6943359375\n",
      "Batch: 23, Loss: 0.9427921772003174, Accuracy: 0.693359375\n",
      "Batch: 24, Loss: 0.9336858987808228, Accuracy: 0.6953125\n",
      "Batch: 25, Loss: 0.9066194891929626, Accuracy: 0.705078125\n",
      "Batch: 26, Loss: 0.7853925824165344, Accuracy: 0.7373046875\n",
      "Batch: 27, Loss: 0.8202167749404907, Accuracy: 0.720703125\n",
      "Batch: 28, Loss: 0.9215652942657471, Accuracy: 0.685546875\n",
      "Batch: 29, Loss: 0.8972989320755005, Accuracy: 0.7021484375\n",
      "Batch: 30, Loss: 0.8400399684906006, Accuracy: 0.734375\n",
      "Batch: 31, Loss: 0.830337405204773, Accuracy: 0.736328125\n",
      "Batch: 32, Loss: 0.8249021172523499, Accuracy: 0.7265625\n",
      "Batch: 33, Loss: 0.9611177444458008, Accuracy: 0.6796875\n",
      "Batch: 34, Loss: 1.0167694091796875, Accuracy: 0.6767578125\n",
      "Batch: 35, Loss: 0.9462259411811829, Accuracy: 0.6826171875\n",
      "Batch: 36, Loss: 0.9570744037628174, Accuracy: 0.705078125\n",
      "Batch: 37, Loss: 0.8770676255226135, Accuracy: 0.716796875\n",
      "Batch: 38, Loss: 0.9420452117919922, Accuracy: 0.697265625\n",
      "Batch: 39, Loss: 0.9204221367835999, Accuracy: 0.7109375\n",
      "Batch: 40, Loss: 0.9314423203468323, Accuracy: 0.7177734375\n",
      "Batch: 41, Loss: 0.9000312685966492, Accuracy: 0.724609375\n",
      "Batch: 42, Loss: 0.7072041034698486, Accuracy: 0.751953125\n",
      "Batch: 43, Loss: 0.9227584600448608, Accuracy: 0.6787109375\n",
      "Batch: 44, Loss: 0.9305657148361206, Accuracy: 0.693359375\n",
      "Batch: 45, Loss: 0.8052991628646851, Accuracy: 0.7451171875\n",
      "Batch: 46, Loss: 0.8879569172859192, Accuracy: 0.712890625\n",
      "Batch: 47, Loss: 0.8423823118209839, Accuracy: 0.7275390625\n",
      "Batch: 48, Loss: 0.8004120588302612, Accuracy: 0.7412109375\n",
      "Batch: 49, Loss: 0.9729231595993042, Accuracy: 0.6796875\n",
      "Batch: 50, Loss: 0.9447239637374878, Accuracy: 0.6953125\n",
      "Batch: 51, Loss: 0.9739390015602112, Accuracy: 0.6796875\n",
      "Batch: 52, Loss: 0.9307448863983154, Accuracy: 0.6884765625\n",
      "Batch: 53, Loss: 0.8243192434310913, Accuracy: 0.7216796875\n",
      "Batch: 54, Loss: 0.8800386190414429, Accuracy: 0.6962890625\n",
      "Batch: 55, Loss: 0.9705715775489807, Accuracy: 0.6826171875\n",
      "Batch: 56, Loss: 0.9628502130508423, Accuracy: 0.689453125\n",
      "Batch: 57, Loss: 0.879164457321167, Accuracy: 0.72265625\n",
      "Batch: 58, Loss: 0.9623989462852478, Accuracy: 0.7060546875\n",
      "Batch: 59, Loss: 0.8940296769142151, Accuracy: 0.720703125\n",
      "Batch: 60, Loss: 0.8175886273384094, Accuracy: 0.7392578125\n",
      "Batch: 61, Loss: 0.9107285737991333, Accuracy: 0.6982421875\n",
      "Batch: 62, Loss: 0.8657811284065247, Accuracy: 0.7216796875\n",
      "Batch: 63, Loss: 0.9195165634155273, Accuracy: 0.7041015625\n",
      "Batch: 64, Loss: 0.9140715599060059, Accuracy: 0.6982421875\n",
      "Batch: 65, Loss: 0.9270268678665161, Accuracy: 0.720703125\n",
      "Batch: 66, Loss: 0.8603971004486084, Accuracy: 0.736328125\n",
      "Batch: 67, Loss: 0.9756039977073669, Accuracy: 0.6826171875\n",
      "Batch: 68, Loss: 0.976150631904602, Accuracy: 0.68359375\n",
      "Batch: 69, Loss: 0.9241228103637695, Accuracy: 0.6962890625\n",
      "Batch: 70, Loss: 0.8719903826713562, Accuracy: 0.7294921875\n",
      "Batch: 71, Loss: 0.9490408897399902, Accuracy: 0.6923828125\n",
      "Batch: 72, Loss: 0.8027794361114502, Accuracy: 0.732421875\n",
      "Batch: 73, Loss: 0.8348757028579712, Accuracy: 0.732421875\n",
      "Batch: 74, Loss: 0.8232565522193909, Accuracy: 0.7470703125\n",
      "Batch: 75, Loss: 0.7939841151237488, Accuracy: 0.7490234375\n",
      "Batch: 76, Loss: 0.8955153822898865, Accuracy: 0.69921875\n",
      "Batch: 77, Loss: 0.8622628450393677, Accuracy: 0.728515625\n",
      "Batch: 78, Loss: 0.8512225151062012, Accuracy: 0.724609375\n",
      "Batch: 79, Loss: 0.7945092916488647, Accuracy: 0.7509765625\n",
      "Batch: 80, Loss: 0.8397579193115234, Accuracy: 0.7236328125\n",
      "Batch: 81, Loss: 0.9692336320877075, Accuracy: 0.6796875\n",
      "Batch: 82, Loss: 0.9202573299407959, Accuracy: 0.7021484375\n",
      "Batch: 83, Loss: 0.8001294136047363, Accuracy: 0.748046875\n",
      "Batch: 84, Loss: 0.8661354780197144, Accuracy: 0.7255859375\n",
      "Batch: 85, Loss: 0.8024773597717285, Accuracy: 0.740234375\n",
      "Batch: 86, Loss: 1.026202917098999, Accuracy: 0.6923828125\n",
      "Batch: 87, Loss: 0.8463228940963745, Accuracy: 0.73046875\n",
      "Batch: 88, Loss: 0.9195603728294373, Accuracy: 0.701171875\n",
      "Batch: 89, Loss: 0.9557153582572937, Accuracy: 0.70703125\n",
      "Batch: 90, Loss: 0.8214288949966431, Accuracy: 0.732421875\n",
      "Batch: 91, Loss: 0.8898898959159851, Accuracy: 0.697265625\n",
      "Batch: 92, Loss: 0.8888503313064575, Accuracy: 0.6962890625\n",
      "Batch: 93, Loss: 0.8389293551445007, Accuracy: 0.7373046875\n",
      "Batch: 94, Loss: 0.8313694000244141, Accuracy: 0.724609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 95, Loss: 0.9381828308105469, Accuracy: 0.6748046875\n",
      "Batch: 96, Loss: 0.8868496417999268, Accuracy: 0.7021484375\n",
      "Batch: 97, Loss: 0.7245336771011353, Accuracy: 0.7509765625\n",
      "Batch: 98, Loss: 0.8200097680091858, Accuracy: 0.7373046875\n",
      "Batch: 99, Loss: 0.8208841681480408, Accuracy: 0.7294921875\n",
      "Batch: 100, Loss: 0.8933777809143066, Accuracy: 0.7255859375\n",
      "Batch: 101, Loss: 0.9453319311141968, Accuracy: 0.6875\n",
      "Batch: 102, Loss: 0.8605923652648926, Accuracy: 0.716796875\n",
      "Batch: 103, Loss: 0.8951061964035034, Accuracy: 0.7158203125\n",
      "Batch: 104, Loss: 0.8510642647743225, Accuracy: 0.7236328125\n",
      "Batch: 105, Loss: 0.9132082462310791, Accuracy: 0.7138671875\n",
      "Batch: 106, Loss: 0.8617637157440186, Accuracy: 0.7236328125\n",
      "Batch: 107, Loss: 0.9039446115493774, Accuracy: 0.7041015625\n",
      "Batch: 108, Loss: 0.881345272064209, Accuracy: 0.7041015625\n",
      "Batch: 109, Loss: 1.0281426906585693, Accuracy: 0.66015625\n",
      "Batch: 110, Loss: 0.79192054271698, Accuracy: 0.736328125\n",
      "Batch: 111, Loss: 0.9622341394424438, Accuracy: 0.669921875\n",
      "Batch: 112, Loss: 0.8919561505317688, Accuracy: 0.7109375\n",
      "Batch: 113, Loss: 0.9096857309341431, Accuracy: 0.7158203125\n",
      "Batch: 114, Loss: 0.9797254800796509, Accuracy: 0.68359375\n",
      "Batch: 115, Loss: 1.0078611373901367, Accuracy: 0.6943359375\n",
      "Batch: 116, Loss: 0.9372653961181641, Accuracy: 0.6962890625\n",
      "Batch: 117, Loss: 0.9702621698379517, Accuracy: 0.6875\n",
      "Batch: 118, Loss: 0.8063176870346069, Accuracy: 0.7392578125\n",
      "Batch: 119, Loss: 0.7506042122840881, Accuracy: 0.7509765625\n",
      "Batch: 120, Loss: 0.9171538352966309, Accuracy: 0.712890625\n",
      "Batch: 121, Loss: 0.9425749778747559, Accuracy: 0.6953125\n",
      "Batch: 122, Loss: 0.8578839302062988, Accuracy: 0.7197265625\n",
      "Batch: 123, Loss: 0.8446441888809204, Accuracy: 0.7333984375\n",
      "Batch: 124, Loss: 0.9378994703292847, Accuracy: 0.6943359375\n",
      "Batch: 125, Loss: 0.950061559677124, Accuracy: 0.6962890625\n",
      "Batch: 126, Loss: 0.9351106882095337, Accuracy: 0.6962890625\n",
      "Batch: 127, Loss: 0.8009966611862183, Accuracy: 0.744140625\n",
      "Batch: 128, Loss: 1.0052686929702759, Accuracy: 0.68359375\n",
      "Batch: 129, Loss: 0.8640798330307007, Accuracy: 0.7216796875\n",
      "Batch: 130, Loss: 1.0048032999038696, Accuracy: 0.6748046875\n",
      "Batch: 131, Loss: 0.9494456052780151, Accuracy: 0.6796875\n",
      "Batch: 132, Loss: 0.9530534744262695, Accuracy: 0.671875\n",
      "Batch: 133, Loss: 0.8351373672485352, Accuracy: 0.7216796875\n",
      "Batch: 134, Loss: 0.9074463248252869, Accuracy: 0.697265625\n",
      "Batch: 135, Loss: 0.8059988021850586, Accuracy: 0.7275390625\n",
      "Batch: 136, Loss: 0.9135088920593262, Accuracy: 0.7236328125\n",
      "Batch: 137, Loss: 0.8704862594604492, Accuracy: 0.7041015625\n",
      "Batch: 138, Loss: 0.7604277729988098, Accuracy: 0.7451171875\n",
      "Batch: 139, Loss: 0.8136663436889648, Accuracy: 0.7236328125\n",
      "Batch: 140, Loss: 0.9075597524642944, Accuracy: 0.693359375\n",
      "Batch: 141, Loss: 0.9677584171295166, Accuracy: 0.6806640625\n",
      "Batch: 142, Loss: 0.952217698097229, Accuracy: 0.6943359375\n",
      "Batch: 143, Loss: 0.9218052625656128, Accuracy: 0.6884765625\n",
      "Batch: 144, Loss: 0.9002934098243713, Accuracy: 0.71484375\n",
      "Batch: 145, Loss: 0.8492250442504883, Accuracy: 0.7138671875\n",
      "Batch: 146, Loss: 0.9231926798820496, Accuracy: 0.7001953125\n",
      "Batch: 147, Loss: 0.9279597997665405, Accuracy: 0.693359375\n",
      "Batch: 148, Loss: 1.0384669303894043, Accuracy: 0.6552734375\n",
      "Batch: 149, Loss: 0.8848274946212769, Accuracy: 0.7099609375\n",
      "Batch: 150, Loss: 0.8650835156440735, Accuracy: 0.7177734375\n",
      "Batch: 151, Loss: 0.7694989442825317, Accuracy: 0.75390625\n",
      "Epoch 22/90\n",
      "Batch: 1, Loss: 1.1307328939437866, Accuracy: 0.6396484375\n",
      "Batch: 2, Loss: 0.9832015037536621, Accuracy: 0.658203125\n",
      "Batch: 3, Loss: 0.8373830318450928, Accuracy: 0.716796875\n",
      "Batch: 4, Loss: 0.7699188590049744, Accuracy: 0.7529296875\n",
      "Batch: 5, Loss: 0.819148063659668, Accuracy: 0.7275390625\n",
      "Batch: 6, Loss: 0.9002481698989868, Accuracy: 0.70703125\n",
      "Batch: 7, Loss: 0.9021506309509277, Accuracy: 0.6787109375\n",
      "Batch: 8, Loss: 0.857093870639801, Accuracy: 0.716796875\n",
      "Batch: 9, Loss: 0.8314317464828491, Accuracy: 0.73046875\n",
      "Batch: 10, Loss: 0.7881118059158325, Accuracy: 0.7470703125\n",
      "Batch: 11, Loss: 0.9657827615737915, Accuracy: 0.6796875\n",
      "Batch: 12, Loss: 0.9647969007492065, Accuracy: 0.69140625\n",
      "Batch: 13, Loss: 0.7349342703819275, Accuracy: 0.7548828125\n",
      "Batch: 14, Loss: 0.9979532957077026, Accuracy: 0.6494140625\n",
      "Batch: 15, Loss: 0.8329399824142456, Accuracy: 0.7333984375\n",
      "Batch: 16, Loss: 0.8630800247192383, Accuracy: 0.71875\n",
      "Batch: 17, Loss: 0.9245503544807434, Accuracy: 0.7060546875\n",
      "Batch: 18, Loss: 0.9322186708450317, Accuracy: 0.69140625\n",
      "Batch: 19, Loss: 0.9727345705032349, Accuracy: 0.6845703125\n",
      "Batch: 20, Loss: 0.8110889196395874, Accuracy: 0.740234375\n",
      "Batch: 21, Loss: 0.8486573696136475, Accuracy: 0.72265625\n",
      "Batch: 22, Loss: 0.9457962512969971, Accuracy: 0.703125\n",
      "Batch: 23, Loss: 0.896539032459259, Accuracy: 0.69921875\n",
      "Batch: 24, Loss: 0.886300802230835, Accuracy: 0.6982421875\n",
      "Batch: 25, Loss: 0.9130381345748901, Accuracy: 0.7109375\n",
      "Batch: 26, Loss: 0.7649383544921875, Accuracy: 0.7529296875\n",
      "Batch: 27, Loss: 0.8264594078063965, Accuracy: 0.7138671875\n",
      "Batch: 28, Loss: 0.928097128868103, Accuracy: 0.6806640625\n",
      "Batch: 29, Loss: 0.8682094812393188, Accuracy: 0.7109375\n",
      "Batch: 30, Loss: 0.8244255185127258, Accuracy: 0.7451171875\n",
      "Batch: 31, Loss: 0.8055205941200256, Accuracy: 0.728515625\n",
      "Batch: 32, Loss: 0.7942162156105042, Accuracy: 0.7470703125\n",
      "Batch: 33, Loss: 0.9301614761352539, Accuracy: 0.68359375\n",
      "Batch: 34, Loss: 0.984699010848999, Accuracy: 0.662109375\n",
      "Batch: 35, Loss: 0.9372871518135071, Accuracy: 0.69921875\n",
      "Batch: 36, Loss: 0.929792046546936, Accuracy: 0.7021484375\n",
      "Batch: 37, Loss: 0.8643723726272583, Accuracy: 0.7138671875\n",
      "Batch: 38, Loss: 0.9332965612411499, Accuracy: 0.69921875\n",
      "Batch: 39, Loss: 0.9056001901626587, Accuracy: 0.705078125\n",
      "Batch: 40, Loss: 0.8768153190612793, Accuracy: 0.7158203125\n",
      "Batch: 41, Loss: 0.8543485403060913, Accuracy: 0.7255859375\n",
      "Batch: 42, Loss: 0.6838051676750183, Accuracy: 0.7705078125\n",
      "Batch: 43, Loss: 0.9099634885787964, Accuracy: 0.697265625\n",
      "Batch: 44, Loss: 0.9152853488922119, Accuracy: 0.6923828125\n",
      "Batch: 45, Loss: 0.773154616355896, Accuracy: 0.75390625\n",
      "Batch: 46, Loss: 0.858178973197937, Accuracy: 0.724609375\n",
      "Batch: 47, Loss: 0.8197935819625854, Accuracy: 0.7333984375\n",
      "Batch: 48, Loss: 0.7933149933815002, Accuracy: 0.7353515625\n",
      "Batch: 49, Loss: 0.9494394659996033, Accuracy: 0.6953125\n",
      "Batch: 50, Loss: 0.9061510562896729, Accuracy: 0.7138671875\n",
      "Batch: 51, Loss: 0.9558995962142944, Accuracy: 0.689453125\n",
      "Batch: 52, Loss: 0.9274167418479919, Accuracy: 0.6923828125\n",
      "Batch: 53, Loss: 0.793133020401001, Accuracy: 0.7236328125\n",
      "Batch: 54, Loss: 0.8715789914131165, Accuracy: 0.712890625\n",
      "Batch: 55, Loss: 0.9655159711837769, Accuracy: 0.6767578125\n",
      "Batch: 56, Loss: 0.9179210662841797, Accuracy: 0.7099609375\n",
      "Batch: 57, Loss: 0.8456372618675232, Accuracy: 0.724609375\n",
      "Batch: 58, Loss: 0.9685112237930298, Accuracy: 0.697265625\n",
      "Batch: 59, Loss: 0.8633034825325012, Accuracy: 0.734375\n",
      "Batch: 60, Loss: 0.8087853789329529, Accuracy: 0.751953125\n",
      "Batch: 61, Loss: 0.9222961664199829, Accuracy: 0.7001953125\n",
      "Batch: 62, Loss: 0.8517765998840332, Accuracy: 0.7265625\n",
      "Batch: 63, Loss: 0.9049457311630249, Accuracy: 0.7119140625\n",
      "Batch: 64, Loss: 0.8855979442596436, Accuracy: 0.7119140625\n",
      "Batch: 65, Loss: 0.9023106098175049, Accuracy: 0.70703125\n",
      "Batch: 66, Loss: 0.8489780426025391, Accuracy: 0.7255859375\n",
      "Batch: 67, Loss: 0.9443028569221497, Accuracy: 0.68359375\n",
      "Batch: 68, Loss: 0.9702612161636353, Accuracy: 0.7041015625\n",
      "Batch: 69, Loss: 0.9041335582733154, Accuracy: 0.705078125\n",
      "Batch: 70, Loss: 0.870023250579834, Accuracy: 0.7314453125\n",
      "Batch: 71, Loss: 0.8990291357040405, Accuracy: 0.701171875\n",
      "Batch: 72, Loss: 0.7838608026504517, Accuracy: 0.751953125\n",
      "Batch: 73, Loss: 0.8188418745994568, Accuracy: 0.73828125\n",
      "Batch: 74, Loss: 0.7909867763519287, Accuracy: 0.728515625\n",
      "Batch: 75, Loss: 0.7630120515823364, Accuracy: 0.7568359375\n",
      "Batch: 76, Loss: 0.8850658535957336, Accuracy: 0.6923828125\n",
      "Batch: 77, Loss: 0.8448344469070435, Accuracy: 0.7421875\n",
      "Batch: 78, Loss: 0.8136647939682007, Accuracy: 0.7431640625\n",
      "Batch: 79, Loss: 0.7721279859542847, Accuracy: 0.7666015625\n",
      "Batch: 80, Loss: 0.8407029509544373, Accuracy: 0.724609375\n",
      "Batch: 81, Loss: 0.9694307446479797, Accuracy: 0.6640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 82, Loss: 0.8993345499038696, Accuracy: 0.7109375\n",
      "Batch: 83, Loss: 0.7937053442001343, Accuracy: 0.7451171875\n",
      "Batch: 84, Loss: 0.8369672894477844, Accuracy: 0.7353515625\n",
      "Batch: 85, Loss: 0.8046256303787231, Accuracy: 0.7412109375\n",
      "Batch: 86, Loss: 0.9826713800430298, Accuracy: 0.6904296875\n",
      "Batch: 87, Loss: 0.8177144527435303, Accuracy: 0.724609375\n",
      "Batch: 88, Loss: 0.9162620306015015, Accuracy: 0.708984375\n",
      "Batch: 89, Loss: 0.9178718328475952, Accuracy: 0.70703125\n",
      "Batch: 90, Loss: 0.8215880990028381, Accuracy: 0.7236328125\n",
      "Batch: 91, Loss: 0.8723873496055603, Accuracy: 0.7119140625\n",
      "Batch: 92, Loss: 0.8828513622283936, Accuracy: 0.7119140625\n",
      "Batch: 93, Loss: 0.8130943775177002, Accuracy: 0.728515625\n",
      "Batch: 94, Loss: 0.8362892866134644, Accuracy: 0.724609375\n",
      "Batch: 95, Loss: 0.9004287719726562, Accuracy: 0.693359375\n",
      "Batch: 96, Loss: 0.8709378242492676, Accuracy: 0.7197265625\n",
      "Batch: 97, Loss: 0.7167227268218994, Accuracy: 0.7626953125\n",
      "Batch: 98, Loss: 0.7776654958724976, Accuracy: 0.7529296875\n",
      "Batch: 99, Loss: 0.8246358633041382, Accuracy: 0.72265625\n",
      "Batch: 100, Loss: 0.8696969747543335, Accuracy: 0.7255859375\n",
      "Batch: 101, Loss: 0.9462822675704956, Accuracy: 0.6982421875\n",
      "Batch: 102, Loss: 0.8195029497146606, Accuracy: 0.7294921875\n",
      "Batch: 103, Loss: 0.8859337568283081, Accuracy: 0.71875\n",
      "Batch: 104, Loss: 0.8379155993461609, Accuracy: 0.7177734375\n",
      "Batch: 105, Loss: 0.9164145588874817, Accuracy: 0.703125\n",
      "Batch: 106, Loss: 0.8493751883506775, Accuracy: 0.7412109375\n",
      "Batch: 107, Loss: 0.9048099517822266, Accuracy: 0.7021484375\n",
      "Batch: 108, Loss: 0.8818018436431885, Accuracy: 0.71875\n",
      "Batch: 109, Loss: 0.9787282943725586, Accuracy: 0.654296875\n",
      "Batch: 110, Loss: 0.7508666515350342, Accuracy: 0.7578125\n",
      "Batch: 111, Loss: 0.9175652265548706, Accuracy: 0.69140625\n",
      "Batch: 112, Loss: 0.8897582292556763, Accuracy: 0.7080078125\n",
      "Batch: 113, Loss: 0.8986741304397583, Accuracy: 0.712890625\n",
      "Batch: 114, Loss: 0.9954501390457153, Accuracy: 0.681640625\n",
      "Batch: 115, Loss: 1.0070574283599854, Accuracy: 0.67578125\n",
      "Batch: 116, Loss: 0.9052730798721313, Accuracy: 0.70703125\n",
      "Batch: 117, Loss: 0.9430525302886963, Accuracy: 0.697265625\n",
      "Batch: 118, Loss: 0.7945325970649719, Accuracy: 0.7529296875\n",
      "Batch: 119, Loss: 0.7397401332855225, Accuracy: 0.7568359375\n",
      "Batch: 120, Loss: 0.8880023956298828, Accuracy: 0.7041015625\n",
      "Batch: 121, Loss: 0.9153372049331665, Accuracy: 0.6904296875\n",
      "Batch: 122, Loss: 0.8445101976394653, Accuracy: 0.7265625\n",
      "Batch: 123, Loss: 0.8302224278450012, Accuracy: 0.73046875\n",
      "Batch: 124, Loss: 0.917418897151947, Accuracy: 0.6875\n",
      "Batch: 125, Loss: 0.9075257182121277, Accuracy: 0.7099609375\n",
      "Batch: 126, Loss: 0.9196224212646484, Accuracy: 0.69140625\n",
      "Batch: 127, Loss: 0.7875226736068726, Accuracy: 0.7490234375\n",
      "Batch: 128, Loss: 0.9656625986099243, Accuracy: 0.69140625\n",
      "Batch: 129, Loss: 0.8650733232498169, Accuracy: 0.7373046875\n",
      "Batch: 130, Loss: 1.012432336807251, Accuracy: 0.6669921875\n",
      "Batch: 131, Loss: 0.9185078144073486, Accuracy: 0.6796875\n",
      "Batch: 132, Loss: 0.9663472175598145, Accuracy: 0.6884765625\n",
      "Batch: 133, Loss: 0.8375043272972107, Accuracy: 0.7265625\n",
      "Batch: 134, Loss: 0.8825327157974243, Accuracy: 0.701171875\n",
      "Batch: 135, Loss: 0.7876743078231812, Accuracy: 0.7373046875\n",
      "Batch: 136, Loss: 0.8735949993133545, Accuracy: 0.6943359375\n",
      "Batch: 137, Loss: 0.8190567493438721, Accuracy: 0.734375\n",
      "Batch: 138, Loss: 0.764418363571167, Accuracy: 0.7470703125\n",
      "Batch: 139, Loss: 0.8026678562164307, Accuracy: 0.72265625\n",
      "Batch: 140, Loss: 0.8696351051330566, Accuracy: 0.716796875\n",
      "Batch: 141, Loss: 0.936987578868866, Accuracy: 0.6875\n",
      "Batch: 142, Loss: 0.9339940547943115, Accuracy: 0.701171875\n",
      "Batch: 143, Loss: 0.86883944272995, Accuracy: 0.7236328125\n",
      "Batch: 144, Loss: 0.8924912810325623, Accuracy: 0.712890625\n",
      "Batch: 145, Loss: 0.8517864942550659, Accuracy: 0.7109375\n",
      "Batch: 146, Loss: 0.916709840297699, Accuracy: 0.7119140625\n",
      "Batch: 147, Loss: 0.9335657358169556, Accuracy: 0.6875\n",
      "Batch: 148, Loss: 0.9880217909812927, Accuracy: 0.669921875\n",
      "Batch: 149, Loss: 0.8584668636322021, Accuracy: 0.7197265625\n",
      "Batch: 150, Loss: 0.8563142418861389, Accuracy: 0.7236328125\n",
      "Batch: 151, Loss: 0.7398492097854614, Accuracy: 0.7646484375\n",
      "Epoch 23/90\n",
      "Batch: 1, Loss: 1.1226611137390137, Accuracy: 0.642578125\n",
      "Batch: 2, Loss: 0.9733210206031799, Accuracy: 0.6640625\n",
      "Batch: 3, Loss: 0.8492580652236938, Accuracy: 0.7177734375\n",
      "Batch: 4, Loss: 0.7689559459686279, Accuracy: 0.75390625\n",
      "Batch: 5, Loss: 0.803760290145874, Accuracy: 0.736328125\n",
      "Batch: 6, Loss: 0.8915629386901855, Accuracy: 0.693359375\n",
      "Batch: 7, Loss: 0.8646240234375, Accuracy: 0.69921875\n",
      "Batch: 8, Loss: 0.8108368515968323, Accuracy: 0.7421875\n",
      "Batch: 9, Loss: 0.8017994165420532, Accuracy: 0.7412109375\n",
      "Batch: 10, Loss: 0.8080534338951111, Accuracy: 0.73828125\n",
      "Batch: 11, Loss: 0.9668388366699219, Accuracy: 0.6767578125\n",
      "Batch: 12, Loss: 0.9521942138671875, Accuracy: 0.693359375\n",
      "Batch: 13, Loss: 0.7279988527297974, Accuracy: 0.765625\n",
      "Batch: 14, Loss: 0.9934834241867065, Accuracy: 0.6728515625\n",
      "Batch: 15, Loss: 0.8155125379562378, Accuracy: 0.755859375\n",
      "Batch: 16, Loss: 0.8695986270904541, Accuracy: 0.7216796875\n",
      "Batch: 17, Loss: 0.8972790241241455, Accuracy: 0.6953125\n",
      "Batch: 18, Loss: 0.9174007177352905, Accuracy: 0.6962890625\n",
      "Batch: 19, Loss: 0.9284923076629639, Accuracy: 0.7080078125\n",
      "Batch: 20, Loss: 0.781368613243103, Accuracy: 0.75390625\n",
      "Batch: 21, Loss: 0.8212437033653259, Accuracy: 0.7294921875\n",
      "Batch: 22, Loss: 0.9114841222763062, Accuracy: 0.7138671875\n",
      "Batch: 23, Loss: 0.8826426267623901, Accuracy: 0.708984375\n",
      "Batch: 24, Loss: 0.8488515615463257, Accuracy: 0.7060546875\n",
      "Batch: 25, Loss: 0.8650984764099121, Accuracy: 0.720703125\n",
      "Batch: 26, Loss: 0.7562919855117798, Accuracy: 0.75\n",
      "Batch: 27, Loss: 0.8048105239868164, Accuracy: 0.7236328125\n",
      "Batch: 28, Loss: 0.8777135610580444, Accuracy: 0.7099609375\n",
      "Batch: 29, Loss: 0.8495057225227356, Accuracy: 0.71875\n",
      "Batch: 30, Loss: 0.7826588749885559, Accuracy: 0.7470703125\n",
      "Batch: 31, Loss: 0.7753835320472717, Accuracy: 0.75\n",
      "Batch: 32, Loss: 0.784967303276062, Accuracy: 0.7431640625\n",
      "Batch: 33, Loss: 0.9198125600814819, Accuracy: 0.7041015625\n",
      "Batch: 34, Loss: 0.9931635856628418, Accuracy: 0.685546875\n",
      "Batch: 35, Loss: 0.8966197967529297, Accuracy: 0.701171875\n",
      "Batch: 36, Loss: 0.9038084149360657, Accuracy: 0.720703125\n",
      "Batch: 37, Loss: 0.8395150899887085, Accuracy: 0.7392578125\n",
      "Batch: 38, Loss: 0.8991987705230713, Accuracy: 0.703125\n",
      "Batch: 39, Loss: 0.8911993503570557, Accuracy: 0.6943359375\n",
      "Batch: 40, Loss: 0.8719553351402283, Accuracy: 0.7236328125\n",
      "Batch: 41, Loss: 0.8422694206237793, Accuracy: 0.736328125\n",
      "Batch: 42, Loss: 0.6686789989471436, Accuracy: 0.7724609375\n",
      "Batch: 43, Loss: 0.8848280906677246, Accuracy: 0.7041015625\n",
      "Batch: 44, Loss: 0.9012997150421143, Accuracy: 0.7158203125\n",
      "Batch: 45, Loss: 0.7627915143966675, Accuracy: 0.7451171875\n",
      "Batch: 46, Loss: 0.8306760191917419, Accuracy: 0.732421875\n",
      "Batch: 47, Loss: 0.8161807656288147, Accuracy: 0.7412109375\n",
      "Batch: 48, Loss: 0.7912876009941101, Accuracy: 0.7275390625\n",
      "Batch: 49, Loss: 0.9293139576911926, Accuracy: 0.701171875\n",
      "Batch: 50, Loss: 0.9087101221084595, Accuracy: 0.7158203125\n",
      "Batch: 51, Loss: 0.9153609275817871, Accuracy: 0.6943359375\n",
      "Batch: 52, Loss: 0.8877513408660889, Accuracy: 0.7255859375\n",
      "Batch: 53, Loss: 0.7988383769989014, Accuracy: 0.7314453125\n",
      "Batch: 54, Loss: 0.8797965049743652, Accuracy: 0.7119140625\n",
      "Batch: 55, Loss: 0.9577001929283142, Accuracy: 0.6806640625\n",
      "Batch: 56, Loss: 0.9107720851898193, Accuracy: 0.7041015625\n",
      "Batch: 57, Loss: 0.8355259299278259, Accuracy: 0.73046875\n",
      "Batch: 58, Loss: 0.9270733594894409, Accuracy: 0.7177734375\n",
      "Batch: 59, Loss: 0.8628785610198975, Accuracy: 0.732421875\n",
      "Batch: 60, Loss: 0.7737276554107666, Accuracy: 0.74609375\n",
      "Batch: 61, Loss: 0.8774773478507996, Accuracy: 0.708984375\n",
      "Batch: 62, Loss: 0.8351949453353882, Accuracy: 0.7353515625\n",
      "Batch: 63, Loss: 0.8810408115386963, Accuracy: 0.7109375\n",
      "Batch: 64, Loss: 0.8686947822570801, Accuracy: 0.7060546875\n",
      "Batch: 65, Loss: 0.9031198024749756, Accuracy: 0.724609375\n",
      "Batch: 66, Loss: 0.8145913481712341, Accuracy: 0.7509765625\n",
      "Batch: 67, Loss: 0.9484707713127136, Accuracy: 0.6962890625\n",
      "Batch: 68, Loss: 0.9423471093177795, Accuracy: 0.7001953125\n",
      "Batch: 69, Loss: 0.8815494179725647, Accuracy: 0.712890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 70, Loss: 0.8356367945671082, Accuracy: 0.7431640625\n",
      "Batch: 71, Loss: 0.8762354254722595, Accuracy: 0.7080078125\n",
      "Batch: 72, Loss: 0.7837719917297363, Accuracy: 0.7353515625\n",
      "Batch: 73, Loss: 0.7861508131027222, Accuracy: 0.751953125\n",
      "Batch: 74, Loss: 0.811227560043335, Accuracy: 0.7392578125\n",
      "Batch: 75, Loss: 0.7659408450126648, Accuracy: 0.7626953125\n",
      "Batch: 76, Loss: 0.8707831501960754, Accuracy: 0.703125\n",
      "Batch: 77, Loss: 0.8250616192817688, Accuracy: 0.736328125\n",
      "Batch: 78, Loss: 0.7963624000549316, Accuracy: 0.751953125\n",
      "Batch: 79, Loss: 0.7810614109039307, Accuracy: 0.7578125\n",
      "Batch: 80, Loss: 0.8135315179824829, Accuracy: 0.7255859375\n",
      "Batch: 81, Loss: 0.9598851203918457, Accuracy: 0.6748046875\n",
      "Batch: 82, Loss: 0.9074296951293945, Accuracy: 0.6943359375\n",
      "Batch: 83, Loss: 0.7710994482040405, Accuracy: 0.7587890625\n",
      "Batch: 84, Loss: 0.8262580633163452, Accuracy: 0.736328125\n",
      "Batch: 85, Loss: 0.7743027210235596, Accuracy: 0.75\n",
      "Batch: 86, Loss: 0.9620354771614075, Accuracy: 0.6845703125\n",
      "Batch: 87, Loss: 0.7942620515823364, Accuracy: 0.7529296875\n",
      "Batch: 88, Loss: 0.9061283469200134, Accuracy: 0.712890625\n",
      "Batch: 89, Loss: 0.8910782337188721, Accuracy: 0.7060546875\n",
      "Batch: 90, Loss: 0.7781797647476196, Accuracy: 0.7431640625\n",
      "Batch: 91, Loss: 0.8283743858337402, Accuracy: 0.7294921875\n",
      "Batch: 92, Loss: 0.8324463963508606, Accuracy: 0.73046875\n",
      "Batch: 93, Loss: 0.8101029396057129, Accuracy: 0.73046875\n",
      "Batch: 94, Loss: 0.8490446209907532, Accuracy: 0.720703125\n",
      "Batch: 95, Loss: 0.8901469707489014, Accuracy: 0.6953125\n",
      "Batch: 96, Loss: 0.8842778205871582, Accuracy: 0.7236328125\n",
      "Batch: 97, Loss: 0.7178821563720703, Accuracy: 0.75\n",
      "Batch: 98, Loss: 0.7953347563743591, Accuracy: 0.7353515625\n",
      "Batch: 99, Loss: 0.7950717210769653, Accuracy: 0.724609375\n",
      "Batch: 100, Loss: 0.8548855781555176, Accuracy: 0.7314453125\n",
      "Batch: 101, Loss: 0.9117105603218079, Accuracy: 0.708984375\n",
      "Batch: 102, Loss: 0.8211544752120972, Accuracy: 0.7236328125\n",
      "Batch: 103, Loss: 0.8685535788536072, Accuracy: 0.7197265625\n",
      "Batch: 104, Loss: 0.820976972579956, Accuracy: 0.71875\n",
      "Batch: 105, Loss: 0.8920881748199463, Accuracy: 0.7119140625\n",
      "Batch: 106, Loss: 0.8401616811752319, Accuracy: 0.7314453125\n",
      "Batch: 107, Loss: 0.8693718910217285, Accuracy: 0.7109375\n",
      "Batch: 108, Loss: 0.8615209460258484, Accuracy: 0.7021484375\n",
      "Batch: 109, Loss: 0.9729837775230408, Accuracy: 0.658203125\n",
      "Batch: 110, Loss: 0.757872998714447, Accuracy: 0.75\n",
      "Batch: 111, Loss: 0.9100621938705444, Accuracy: 0.689453125\n",
      "Batch: 112, Loss: 0.8735716342926025, Accuracy: 0.728515625\n",
      "Batch: 113, Loss: 0.8765497803688049, Accuracy: 0.7158203125\n",
      "Batch: 114, Loss: 0.9410881996154785, Accuracy: 0.6787109375\n",
      "Batch: 115, Loss: 0.9921211004257202, Accuracy: 0.6865234375\n",
      "Batch: 116, Loss: 0.8741782903671265, Accuracy: 0.7255859375\n",
      "Batch: 117, Loss: 0.9009618759155273, Accuracy: 0.703125\n",
      "Batch: 118, Loss: 0.764235258102417, Accuracy: 0.7529296875\n",
      "Batch: 119, Loss: 0.7172688245773315, Accuracy: 0.775390625\n",
      "Batch: 120, Loss: 0.8810920715332031, Accuracy: 0.6962890625\n",
      "Batch: 121, Loss: 0.9006971120834351, Accuracy: 0.6982421875\n",
      "Batch: 122, Loss: 0.8345614671707153, Accuracy: 0.736328125\n",
      "Batch: 123, Loss: 0.8124641180038452, Accuracy: 0.734375\n",
      "Batch: 124, Loss: 0.9178332090377808, Accuracy: 0.6923828125\n",
      "Batch: 125, Loss: 0.8996517658233643, Accuracy: 0.7119140625\n",
      "Batch: 126, Loss: 0.9125268459320068, Accuracy: 0.7080078125\n",
      "Batch: 127, Loss: 0.7919074892997742, Accuracy: 0.7451171875\n",
      "Batch: 128, Loss: 0.9514573216438293, Accuracy: 0.7001953125\n",
      "Batch: 129, Loss: 0.8122701048851013, Accuracy: 0.7265625\n",
      "Batch: 130, Loss: 0.9859210252761841, Accuracy: 0.677734375\n",
      "Batch: 131, Loss: 0.9139804840087891, Accuracy: 0.7138671875\n",
      "Batch: 132, Loss: 0.9254084229469299, Accuracy: 0.69140625\n",
      "Batch: 133, Loss: 0.8153269290924072, Accuracy: 0.732421875\n",
      "Batch: 134, Loss: 0.8578630685806274, Accuracy: 0.716796875\n",
      "Batch: 135, Loss: 0.7596489787101746, Accuracy: 0.7646484375\n",
      "Batch: 136, Loss: 0.8638479113578796, Accuracy: 0.7236328125\n",
      "Batch: 137, Loss: 0.8247756958007812, Accuracy: 0.7109375\n",
      "Batch: 138, Loss: 0.7745755314826965, Accuracy: 0.7333984375\n",
      "Batch: 139, Loss: 0.7926995158195496, Accuracy: 0.7177734375\n",
      "Batch: 140, Loss: 0.8594527244567871, Accuracy: 0.70703125\n",
      "Batch: 141, Loss: 0.8972676992416382, Accuracy: 0.7041015625\n",
      "Batch: 142, Loss: 0.9439176321029663, Accuracy: 0.6923828125\n",
      "Batch: 143, Loss: 0.8748899102210999, Accuracy: 0.7099609375\n",
      "Batch: 144, Loss: 0.866904616355896, Accuracy: 0.71484375\n",
      "Batch: 145, Loss: 0.8298824429512024, Accuracy: 0.708984375\n",
      "Batch: 146, Loss: 0.8791326284408569, Accuracy: 0.7197265625\n",
      "Batch: 147, Loss: 0.8855254650115967, Accuracy: 0.7060546875\n",
      "Batch: 148, Loss: 0.9748415350914001, Accuracy: 0.6708984375\n",
      "Batch: 149, Loss: 0.8329812288284302, Accuracy: 0.7099609375\n",
      "Batch: 150, Loss: 0.8045274615287781, Accuracy: 0.73046875\n",
      "Batch: 151, Loss: 0.7348736524581909, Accuracy: 0.7470703125\n",
      "Epoch 24/90\n",
      "Batch: 1, Loss: 1.116048812866211, Accuracy: 0.65234375\n",
      "Batch: 2, Loss: 0.9491560459136963, Accuracy: 0.6845703125\n",
      "Batch: 3, Loss: 0.8081125617027283, Accuracy: 0.728515625\n",
      "Batch: 4, Loss: 0.7446001172065735, Accuracy: 0.7724609375\n",
      "Batch: 5, Loss: 0.7750501036643982, Accuracy: 0.7451171875\n",
      "Batch: 6, Loss: 0.8705036640167236, Accuracy: 0.7158203125\n",
      "Batch: 7, Loss: 0.8545050621032715, Accuracy: 0.712890625\n",
      "Batch: 8, Loss: 0.8094149231910706, Accuracy: 0.7421875\n",
      "Batch: 9, Loss: 0.8142141699790955, Accuracy: 0.7392578125\n",
      "Batch: 10, Loss: 0.7799786329269409, Accuracy: 0.74609375\n",
      "Batch: 11, Loss: 0.9209455847740173, Accuracy: 0.6982421875\n",
      "Batch: 12, Loss: 0.8924838304519653, Accuracy: 0.7109375\n",
      "Batch: 13, Loss: 0.705322265625, Accuracy: 0.7587890625\n",
      "Batch: 14, Loss: 0.9706316590309143, Accuracy: 0.67578125\n",
      "Batch: 15, Loss: 0.80386883020401, Accuracy: 0.7509765625\n",
      "Batch: 16, Loss: 0.8150733113288879, Accuracy: 0.7333984375\n",
      "Batch: 17, Loss: 0.8938717842102051, Accuracy: 0.703125\n",
      "Batch: 18, Loss: 0.8925960659980774, Accuracy: 0.705078125\n",
      "Batch: 19, Loss: 0.9122258424758911, Accuracy: 0.7177734375\n",
      "Batch: 20, Loss: 0.7754803895950317, Accuracy: 0.7509765625\n",
      "Batch: 21, Loss: 0.7962602376937866, Accuracy: 0.7421875\n",
      "Batch: 22, Loss: 0.9131251573562622, Accuracy: 0.7060546875\n",
      "Batch: 23, Loss: 0.8628860712051392, Accuracy: 0.7197265625\n",
      "Batch: 24, Loss: 0.8529287576675415, Accuracy: 0.7109375\n",
      "Batch: 25, Loss: 0.8555475473403931, Accuracy: 0.7216796875\n",
      "Batch: 26, Loss: 0.7347090244293213, Accuracy: 0.75390625\n",
      "Batch: 27, Loss: 0.7861042022705078, Accuracy: 0.73046875\n",
      "Batch: 28, Loss: 0.8683810830116272, Accuracy: 0.7080078125\n",
      "Batch: 29, Loss: 0.8158054351806641, Accuracy: 0.7158203125\n",
      "Batch: 30, Loss: 0.7664932012557983, Accuracy: 0.759765625\n",
      "Batch: 31, Loss: 0.7669540643692017, Accuracy: 0.7470703125\n",
      "Batch: 32, Loss: 0.7297467589378357, Accuracy: 0.759765625\n",
      "Batch: 33, Loss: 0.9084426164627075, Accuracy: 0.7060546875\n",
      "Batch: 34, Loss: 0.9559875130653381, Accuracy: 0.6923828125\n",
      "Batch: 35, Loss: 0.860427975654602, Accuracy: 0.7041015625\n",
      "Batch: 36, Loss: 0.9140748977661133, Accuracy: 0.7158203125\n",
      "Batch: 37, Loss: 0.8282279968261719, Accuracy: 0.7275390625\n",
      "Batch: 38, Loss: 0.8628147840499878, Accuracy: 0.7158203125\n",
      "Batch: 39, Loss: 0.87895667552948, Accuracy: 0.705078125\n",
      "Batch: 40, Loss: 0.8410696387290955, Accuracy: 0.732421875\n",
      "Batch: 41, Loss: 0.794825553894043, Accuracy: 0.75\n",
      "Batch: 42, Loss: 0.6462299227714539, Accuracy: 0.779296875\n",
      "Batch: 43, Loss: 0.8802694082260132, Accuracy: 0.7060546875\n",
      "Batch: 44, Loss: 0.8883510828018188, Accuracy: 0.71484375\n",
      "Batch: 45, Loss: 0.7325347065925598, Accuracy: 0.7607421875\n",
      "Batch: 46, Loss: 0.7966700196266174, Accuracy: 0.74609375\n",
      "Batch: 47, Loss: 0.7976791858673096, Accuracy: 0.7666015625\n",
      "Batch: 48, Loss: 0.7445448040962219, Accuracy: 0.74609375\n",
      "Batch: 49, Loss: 0.8966077566146851, Accuracy: 0.69921875\n",
      "Batch: 50, Loss: 0.8890286087989807, Accuracy: 0.7109375\n",
      "Batch: 51, Loss: 0.8809367418289185, Accuracy: 0.7197265625\n",
      "Batch: 52, Loss: 0.8452690839767456, Accuracy: 0.7255859375\n",
      "Batch: 53, Loss: 0.7637326717376709, Accuracy: 0.7431640625\n",
      "Batch: 54, Loss: 0.8472955226898193, Accuracy: 0.7265625\n",
      "Batch: 55, Loss: 0.9246690273284912, Accuracy: 0.681640625\n",
      "Batch: 56, Loss: 0.8836530447006226, Accuracy: 0.7119140625\n",
      "Batch: 57, Loss: 0.8182250261306763, Accuracy: 0.7294921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 58, Loss: 0.8899288177490234, Accuracy: 0.728515625\n",
      "Batch: 59, Loss: 0.8205193877220154, Accuracy: 0.7275390625\n",
      "Batch: 60, Loss: 0.7705919742584229, Accuracy: 0.7568359375\n",
      "Batch: 61, Loss: 0.8482128977775574, Accuracy: 0.7177734375\n",
      "Batch: 62, Loss: 0.7929543852806091, Accuracy: 0.7470703125\n",
      "Batch: 63, Loss: 0.8745294213294983, Accuracy: 0.71484375\n",
      "Batch: 64, Loss: 0.8625301122665405, Accuracy: 0.7294921875\n",
      "Batch: 65, Loss: 0.8455376029014587, Accuracy: 0.734375\n",
      "Batch: 66, Loss: 0.8206062316894531, Accuracy: 0.7451171875\n",
      "Batch: 67, Loss: 0.9286211133003235, Accuracy: 0.6884765625\n",
      "Batch: 68, Loss: 0.9474334716796875, Accuracy: 0.693359375\n",
      "Batch: 69, Loss: 0.854337751865387, Accuracy: 0.7177734375\n",
      "Batch: 70, Loss: 0.8269808292388916, Accuracy: 0.73828125\n",
      "Batch: 71, Loss: 0.8759934902191162, Accuracy: 0.705078125\n",
      "Batch: 72, Loss: 0.7628363370895386, Accuracy: 0.7490234375\n",
      "Batch: 73, Loss: 0.7594716548919678, Accuracy: 0.7646484375\n",
      "Batch: 74, Loss: 0.7453687191009521, Accuracy: 0.7626953125\n",
      "Batch: 75, Loss: 0.7561743259429932, Accuracy: 0.7578125\n",
      "Batch: 76, Loss: 0.87077796459198, Accuracy: 0.703125\n",
      "Batch: 77, Loss: 0.7896848320960999, Accuracy: 0.7578125\n",
      "Batch: 78, Loss: 0.780301570892334, Accuracy: 0.74609375\n",
      "Batch: 79, Loss: 0.7435381412506104, Accuracy: 0.767578125\n",
      "Batch: 80, Loss: 0.8008330464363098, Accuracy: 0.7275390625\n",
      "Batch: 81, Loss: 0.9147070050239563, Accuracy: 0.681640625\n",
      "Batch: 82, Loss: 0.8881304264068604, Accuracy: 0.720703125\n",
      "Batch: 83, Loss: 0.743930459022522, Accuracy: 0.767578125\n",
      "Batch: 84, Loss: 0.8342663049697876, Accuracy: 0.7353515625\n",
      "Batch: 85, Loss: 0.7595164775848389, Accuracy: 0.7548828125\n",
      "Batch: 86, Loss: 0.9693318605422974, Accuracy: 0.7041015625\n",
      "Batch: 87, Loss: 0.793245255947113, Accuracy: 0.7529296875\n",
      "Batch: 88, Loss: 0.8811851739883423, Accuracy: 0.716796875\n",
      "Batch: 89, Loss: 0.8671747446060181, Accuracy: 0.72265625\n",
      "Batch: 90, Loss: 0.7979397773742676, Accuracy: 0.7421875\n",
      "Batch: 91, Loss: 0.8109111785888672, Accuracy: 0.7275390625\n",
      "Batch: 92, Loss: 0.8586963415145874, Accuracy: 0.7177734375\n",
      "Batch: 93, Loss: 0.8093158006668091, Accuracy: 0.7314453125\n",
      "Batch: 94, Loss: 0.8076757192611694, Accuracy: 0.7197265625\n",
      "Batch: 95, Loss: 0.8764815330505371, Accuracy: 0.7021484375\n",
      "Batch: 96, Loss: 0.8625576496124268, Accuracy: 0.7353515625\n",
      "Batch: 97, Loss: 0.6841487288475037, Accuracy: 0.7626953125\n",
      "Batch: 98, Loss: 0.7851894497871399, Accuracy: 0.7490234375\n",
      "Batch: 99, Loss: 0.7967923283576965, Accuracy: 0.7314453125\n",
      "Batch: 100, Loss: 0.8481970429420471, Accuracy: 0.72265625\n",
      "Batch: 101, Loss: 0.8936689496040344, Accuracy: 0.7119140625\n",
      "Batch: 102, Loss: 0.8059019446372986, Accuracy: 0.7275390625\n",
      "Batch: 103, Loss: 0.8640950918197632, Accuracy: 0.7099609375\n",
      "Batch: 104, Loss: 0.8101025819778442, Accuracy: 0.724609375\n",
      "Batch: 105, Loss: 0.8499742746353149, Accuracy: 0.720703125\n",
      "Batch: 106, Loss: 0.8187071084976196, Accuracy: 0.7451171875\n",
      "Batch: 107, Loss: 0.8429758548736572, Accuracy: 0.7265625\n",
      "Batch: 108, Loss: 0.8167731761932373, Accuracy: 0.7294921875\n",
      "Batch: 109, Loss: 0.9342981576919556, Accuracy: 0.6787109375\n",
      "Batch: 110, Loss: 0.7568732500076294, Accuracy: 0.7587890625\n",
      "Batch: 111, Loss: 0.8747202157974243, Accuracy: 0.7158203125\n",
      "Batch: 112, Loss: 0.8280370235443115, Accuracy: 0.7333984375\n",
      "Batch: 113, Loss: 0.8306989669799805, Accuracy: 0.7109375\n",
      "Batch: 114, Loss: 0.910743236541748, Accuracy: 0.6962890625\n",
      "Batch: 115, Loss: 0.9294652938842773, Accuracy: 0.70703125\n",
      "Batch: 116, Loss: 0.8583563566207886, Accuracy: 0.7138671875\n",
      "Batch: 117, Loss: 0.9084812998771667, Accuracy: 0.7021484375\n",
      "Batch: 118, Loss: 0.7447254657745361, Accuracy: 0.7529296875\n",
      "Batch: 119, Loss: 0.6974568963050842, Accuracy: 0.76171875\n",
      "Batch: 120, Loss: 0.8521661758422852, Accuracy: 0.720703125\n",
      "Batch: 121, Loss: 0.8961267471313477, Accuracy: 0.7041015625\n",
      "Batch: 122, Loss: 0.7965342998504639, Accuracy: 0.7392578125\n",
      "Batch: 123, Loss: 0.7760993838310242, Accuracy: 0.7451171875\n",
      "Batch: 124, Loss: 0.8499239087104797, Accuracy: 0.7099609375\n",
      "Batch: 125, Loss: 0.8844050765037537, Accuracy: 0.70703125\n",
      "Batch: 126, Loss: 0.8910645246505737, Accuracy: 0.7099609375\n",
      "Batch: 127, Loss: 0.7714119553565979, Accuracy: 0.7568359375\n",
      "Batch: 128, Loss: 0.9113232493400574, Accuracy: 0.705078125\n",
      "Batch: 129, Loss: 0.8124451637268066, Accuracy: 0.7421875\n",
      "Batch: 130, Loss: 0.9850004315376282, Accuracy: 0.6787109375\n",
      "Batch: 131, Loss: 0.8959449529647827, Accuracy: 0.7109375\n",
      "Batch: 132, Loss: 0.9058597087860107, Accuracy: 0.69921875\n",
      "Batch: 133, Loss: 0.7873865962028503, Accuracy: 0.734375\n",
      "Batch: 134, Loss: 0.8905029296875, Accuracy: 0.7001953125\n",
      "Batch: 135, Loss: 0.7739489674568176, Accuracy: 0.74609375\n",
      "Batch: 136, Loss: 0.8690323233604431, Accuracy: 0.724609375\n",
      "Batch: 137, Loss: 0.8381136655807495, Accuracy: 0.7265625\n",
      "Batch: 138, Loss: 0.731865644454956, Accuracy: 0.7568359375\n",
      "Batch: 139, Loss: 0.7751445770263672, Accuracy: 0.7421875\n",
      "Batch: 140, Loss: 0.8338532447814941, Accuracy: 0.7314453125\n",
      "Batch: 141, Loss: 0.9298714995384216, Accuracy: 0.697265625\n",
      "Batch: 142, Loss: 0.9101613163948059, Accuracy: 0.703125\n",
      "Batch: 143, Loss: 0.8618295192718506, Accuracy: 0.7197265625\n",
      "Batch: 144, Loss: 0.8561563491821289, Accuracy: 0.71484375\n",
      "Batch: 145, Loss: 0.8188427090644836, Accuracy: 0.7099609375\n",
      "Batch: 146, Loss: 0.8718957901000977, Accuracy: 0.7158203125\n",
      "Batch: 147, Loss: 0.8703372478485107, Accuracy: 0.708984375\n",
      "Batch: 148, Loss: 0.9443166255950928, Accuracy: 0.6923828125\n",
      "Batch: 149, Loss: 0.8307163119316101, Accuracy: 0.7255859375\n",
      "Batch: 150, Loss: 0.8040751218795776, Accuracy: 0.7314453125\n",
      "Batch: 151, Loss: 0.7285638451576233, Accuracy: 0.767578125\n",
      "Epoch 25/90\n",
      "Batch: 1, Loss: 1.080461025238037, Accuracy: 0.662109375\n",
      "Batch: 2, Loss: 0.9338772296905518, Accuracy: 0.6845703125\n",
      "Batch: 3, Loss: 0.8245358467102051, Accuracy: 0.71484375\n",
      "Batch: 4, Loss: 0.7305858135223389, Accuracy: 0.76171875\n",
      "Batch: 5, Loss: 0.7858629822731018, Accuracy: 0.7392578125\n",
      "Batch: 6, Loss: 0.8695938587188721, Accuracy: 0.69140625\n",
      "Batch: 7, Loss: 0.8571496605873108, Accuracy: 0.70703125\n",
      "Batch: 8, Loss: 0.7967538833618164, Accuracy: 0.7431640625\n",
      "Batch: 9, Loss: 0.7811362743377686, Accuracy: 0.7412109375\n",
      "Batch: 10, Loss: 0.7790476083755493, Accuracy: 0.7470703125\n",
      "Batch: 11, Loss: 0.915459156036377, Accuracy: 0.6875\n",
      "Batch: 12, Loss: 0.8752480745315552, Accuracy: 0.712890625\n",
      "Batch: 13, Loss: 0.6970977783203125, Accuracy: 0.765625\n",
      "Batch: 14, Loss: 0.9315574765205383, Accuracy: 0.7021484375\n",
      "Batch: 15, Loss: 0.7923991680145264, Accuracy: 0.7548828125\n",
      "Batch: 16, Loss: 0.8112149238586426, Accuracy: 0.744140625\n",
      "Batch: 17, Loss: 0.8579854965209961, Accuracy: 0.71875\n",
      "Batch: 18, Loss: 0.8647026419639587, Accuracy: 0.71484375\n",
      "Batch: 19, Loss: 0.8774073719978333, Accuracy: 0.712890625\n",
      "Batch: 20, Loss: 0.7216446399688721, Accuracy: 0.765625\n",
      "Batch: 21, Loss: 0.7836252450942993, Accuracy: 0.744140625\n",
      "Batch: 22, Loss: 0.8971608877182007, Accuracy: 0.7119140625\n",
      "Batch: 23, Loss: 0.850507915019989, Accuracy: 0.7109375\n",
      "Batch: 24, Loss: 0.8401514291763306, Accuracy: 0.72265625\n",
      "Batch: 25, Loss: 0.8502520322799683, Accuracy: 0.736328125\n",
      "Batch: 26, Loss: 0.7088218927383423, Accuracy: 0.7548828125\n",
      "Batch: 27, Loss: 0.7510230541229248, Accuracy: 0.7451171875\n",
      "Batch: 28, Loss: 0.8657209277153015, Accuracy: 0.70703125\n",
      "Batch: 29, Loss: 0.8239654302597046, Accuracy: 0.7294921875\n",
      "Batch: 30, Loss: 0.7437942028045654, Accuracy: 0.7626953125\n",
      "Batch: 31, Loss: 0.7414405345916748, Accuracy: 0.7548828125\n",
      "Batch: 32, Loss: 0.7491408586502075, Accuracy: 0.7568359375\n",
      "Batch: 33, Loss: 0.8511040806770325, Accuracy: 0.712890625\n",
      "Batch: 34, Loss: 0.9304884672164917, Accuracy: 0.7001953125\n",
      "Batch: 35, Loss: 0.8673489093780518, Accuracy: 0.712890625\n",
      "Batch: 36, Loss: 0.8673704862594604, Accuracy: 0.728515625\n",
      "Batch: 37, Loss: 0.7985121011734009, Accuracy: 0.7451171875\n",
      "Batch: 38, Loss: 0.847663402557373, Accuracy: 0.71484375\n",
      "Batch: 39, Loss: 0.8428244590759277, Accuracy: 0.732421875\n",
      "Batch: 40, Loss: 0.8295915126800537, Accuracy: 0.7470703125\n",
      "Batch: 41, Loss: 0.7765402793884277, Accuracy: 0.76171875\n",
      "Batch: 42, Loss: 0.6440155506134033, Accuracy: 0.787109375\n",
      "Batch: 43, Loss: 0.8733395338058472, Accuracy: 0.703125\n",
      "Batch: 44, Loss: 0.8631479740142822, Accuracy: 0.7197265625\n",
      "Batch: 45, Loss: 0.7352155447006226, Accuracy: 0.75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 46, Loss: 0.7994890213012695, Accuracy: 0.736328125\n",
      "Batch: 47, Loss: 0.7481980323791504, Accuracy: 0.765625\n",
      "Batch: 48, Loss: 0.7238432168960571, Accuracy: 0.755859375\n",
      "Batch: 49, Loss: 0.8837344646453857, Accuracy: 0.7060546875\n",
      "Batch: 50, Loss: 0.8688434362411499, Accuracy: 0.7099609375\n",
      "Batch: 51, Loss: 0.8854270577430725, Accuracy: 0.7119140625\n",
      "Batch: 52, Loss: 0.8582497835159302, Accuracy: 0.732421875\n",
      "Batch: 53, Loss: 0.7602196335792542, Accuracy: 0.744140625\n",
      "Batch: 54, Loss: 0.8306304216384888, Accuracy: 0.7216796875\n",
      "Batch: 55, Loss: 0.9190937876701355, Accuracy: 0.6962890625\n",
      "Batch: 56, Loss: 0.8736739158630371, Accuracy: 0.71484375\n",
      "Batch: 57, Loss: 0.8069627285003662, Accuracy: 0.732421875\n",
      "Batch: 58, Loss: 0.8860222101211548, Accuracy: 0.720703125\n",
      "Batch: 59, Loss: 0.8077452182769775, Accuracy: 0.7431640625\n",
      "Batch: 60, Loss: 0.7445353269577026, Accuracy: 0.75\n",
      "Batch: 61, Loss: 0.8311846256256104, Accuracy: 0.7236328125\n",
      "Batch: 62, Loss: 0.787337064743042, Accuracy: 0.7314453125\n",
      "Batch: 63, Loss: 0.858259379863739, Accuracy: 0.7099609375\n",
      "Batch: 64, Loss: 0.8164618611335754, Accuracy: 0.7373046875\n",
      "Batch: 65, Loss: 0.8463048338890076, Accuracy: 0.7294921875\n",
      "Batch: 66, Loss: 0.7827954292297363, Accuracy: 0.76171875\n",
      "Batch: 67, Loss: 0.9042028188705444, Accuracy: 0.712890625\n",
      "Batch: 68, Loss: 0.9470686912536621, Accuracy: 0.701171875\n",
      "Batch: 69, Loss: 0.8275922536849976, Accuracy: 0.7353515625\n",
      "Batch: 70, Loss: 0.7955778241157532, Accuracy: 0.740234375\n",
      "Batch: 71, Loss: 0.8602169156074524, Accuracy: 0.70703125\n",
      "Batch: 72, Loss: 0.7466754913330078, Accuracy: 0.7470703125\n",
      "Batch: 73, Loss: 0.7710787653923035, Accuracy: 0.7470703125\n",
      "Batch: 74, Loss: 0.7479592561721802, Accuracy: 0.7626953125\n",
      "Batch: 75, Loss: 0.7317497134208679, Accuracy: 0.7607421875\n",
      "Batch: 76, Loss: 0.8244538307189941, Accuracy: 0.732421875\n",
      "Batch: 77, Loss: 0.7837247252464294, Accuracy: 0.755859375\n",
      "Batch: 78, Loss: 0.7707833647727966, Accuracy: 0.75\n",
      "Batch: 79, Loss: 0.7219582796096802, Accuracy: 0.767578125\n",
      "Batch: 80, Loss: 0.7878246307373047, Accuracy: 0.7392578125\n",
      "Batch: 81, Loss: 0.8959692716598511, Accuracy: 0.6904296875\n",
      "Batch: 82, Loss: 0.8349624872207642, Accuracy: 0.7177734375\n",
      "Batch: 83, Loss: 0.7129018306732178, Accuracy: 0.7744140625\n",
      "Batch: 84, Loss: 0.8154523372650146, Accuracy: 0.7373046875\n",
      "Batch: 85, Loss: 0.7458277940750122, Accuracy: 0.763671875\n",
      "Batch: 86, Loss: 0.9198950529098511, Accuracy: 0.7109375\n",
      "Batch: 87, Loss: 0.7486702799797058, Accuracy: 0.7607421875\n",
      "Batch: 88, Loss: 0.8554561734199524, Accuracy: 0.7451171875\n",
      "Batch: 89, Loss: 0.8457489013671875, Accuracy: 0.7353515625\n",
      "Batch: 90, Loss: 0.7570242881774902, Accuracy: 0.7626953125\n",
      "Batch: 91, Loss: 0.8128280639648438, Accuracy: 0.7216796875\n",
      "Batch: 92, Loss: 0.8070327043533325, Accuracy: 0.734375\n",
      "Batch: 93, Loss: 0.7570863962173462, Accuracy: 0.74609375\n",
      "Batch: 94, Loss: 0.7955201268196106, Accuracy: 0.732421875\n",
      "Batch: 95, Loss: 0.8710854053497314, Accuracy: 0.716796875\n",
      "Batch: 96, Loss: 0.8127733469009399, Accuracy: 0.73828125\n",
      "Batch: 97, Loss: 0.6738275289535522, Accuracy: 0.7744140625\n",
      "Batch: 98, Loss: 0.7589401602745056, Accuracy: 0.7529296875\n",
      "Batch: 99, Loss: 0.7496231198310852, Accuracy: 0.75\n",
      "Batch: 100, Loss: 0.8386512994766235, Accuracy: 0.7255859375\n",
      "Batch: 101, Loss: 0.8617271780967712, Accuracy: 0.72265625\n",
      "Batch: 102, Loss: 0.7864416241645813, Accuracy: 0.7490234375\n",
      "Batch: 103, Loss: 0.8249813318252563, Accuracy: 0.734375\n",
      "Batch: 104, Loss: 0.8005956411361694, Accuracy: 0.724609375\n",
      "Batch: 105, Loss: 0.8537604808807373, Accuracy: 0.7275390625\n",
      "Batch: 106, Loss: 0.8034871816635132, Accuracy: 0.7470703125\n",
      "Batch: 107, Loss: 0.8127708435058594, Accuracy: 0.7353515625\n",
      "Batch: 108, Loss: 0.8398101329803467, Accuracy: 0.7138671875\n",
      "Batch: 109, Loss: 0.9219235181808472, Accuracy: 0.6904296875\n",
      "Batch: 110, Loss: 0.771910548210144, Accuracy: 0.73828125\n",
      "Batch: 111, Loss: 0.8719408512115479, Accuracy: 0.703125\n",
      "Batch: 112, Loss: 0.8065389394760132, Accuracy: 0.734375\n",
      "Batch: 113, Loss: 0.8228297233581543, Accuracy: 0.7333984375\n",
      "Batch: 114, Loss: 0.8818134069442749, Accuracy: 0.7099609375\n",
      "Batch: 115, Loss: 0.9191446304321289, Accuracy: 0.70703125\n",
      "Batch: 116, Loss: 0.8506202101707458, Accuracy: 0.7236328125\n",
      "Batch: 117, Loss: 0.8621091842651367, Accuracy: 0.7041015625\n",
      "Batch: 118, Loss: 0.7280335426330566, Accuracy: 0.767578125\n",
      "Batch: 119, Loss: 0.6826760172843933, Accuracy: 0.7880859375\n",
      "Batch: 120, Loss: 0.8482203483581543, Accuracy: 0.70703125\n",
      "Batch: 121, Loss: 0.850874662399292, Accuracy: 0.7216796875\n",
      "Batch: 122, Loss: 0.7851848006248474, Accuracy: 0.7451171875\n",
      "Batch: 123, Loss: 0.7733906507492065, Accuracy: 0.7421875\n",
      "Batch: 124, Loss: 0.8431885242462158, Accuracy: 0.7158203125\n",
      "Batch: 125, Loss: 0.8712869882583618, Accuracy: 0.7294921875\n",
      "Batch: 126, Loss: 0.8653441071510315, Accuracy: 0.7333984375\n",
      "Batch: 127, Loss: 0.724227249622345, Accuracy: 0.7734375\n",
      "Batch: 128, Loss: 0.8952867984771729, Accuracy: 0.734375\n",
      "Batch: 129, Loss: 0.7765997648239136, Accuracy: 0.75\n",
      "Batch: 130, Loss: 0.9327133893966675, Accuracy: 0.689453125\n",
      "Batch: 131, Loss: 0.8801180124282837, Accuracy: 0.7041015625\n",
      "Batch: 132, Loss: 0.8947268128395081, Accuracy: 0.720703125\n",
      "Batch: 133, Loss: 0.7905990481376648, Accuracy: 0.75390625\n",
      "Batch: 134, Loss: 0.844480574131012, Accuracy: 0.708984375\n",
      "Batch: 135, Loss: 0.7489448189735413, Accuracy: 0.755859375\n",
      "Batch: 136, Loss: 0.8346390724182129, Accuracy: 0.732421875\n",
      "Batch: 137, Loss: 0.7983424663543701, Accuracy: 0.7333984375\n",
      "Batch: 138, Loss: 0.7204080820083618, Accuracy: 0.75390625\n",
      "Batch: 139, Loss: 0.7640173435211182, Accuracy: 0.7392578125\n",
      "Batch: 140, Loss: 0.828663170337677, Accuracy: 0.7216796875\n",
      "Batch: 141, Loss: 0.8588899374008179, Accuracy: 0.7216796875\n",
      "Batch: 142, Loss: 0.8808680772781372, Accuracy: 0.712890625\n",
      "Batch: 143, Loss: 0.8562256097793579, Accuracy: 0.728515625\n",
      "Batch: 144, Loss: 0.8261864185333252, Accuracy: 0.732421875\n",
      "Batch: 145, Loss: 0.7918203473091125, Accuracy: 0.740234375\n",
      "Batch: 146, Loss: 0.8688651323318481, Accuracy: 0.7294921875\n",
      "Batch: 147, Loss: 0.849631667137146, Accuracy: 0.720703125\n",
      "Batch: 148, Loss: 0.9378901124000549, Accuracy: 0.7021484375\n",
      "Batch: 149, Loss: 0.799056887626648, Accuracy: 0.7373046875\n",
      "Batch: 150, Loss: 0.7720361948013306, Accuracy: 0.7314453125\n",
      "Batch: 151, Loss: 0.7069982886314392, Accuracy: 0.765625\n",
      "Epoch 26/90\n",
      "Batch: 1, Loss: 1.0515176057815552, Accuracy: 0.65234375\n",
      "Batch: 2, Loss: 0.9071332216262817, Accuracy: 0.70703125\n",
      "Batch: 3, Loss: 0.8043147921562195, Accuracy: 0.7216796875\n",
      "Batch: 4, Loss: 0.7005219459533691, Accuracy: 0.7783203125\n",
      "Batch: 5, Loss: 0.7822859287261963, Accuracy: 0.7626953125\n",
      "Batch: 6, Loss: 0.835080623626709, Accuracy: 0.724609375\n",
      "Batch: 7, Loss: 0.8476159572601318, Accuracy: 0.7080078125\n",
      "Batch: 8, Loss: 0.7902196645736694, Accuracy: 0.7529296875\n",
      "Batch: 9, Loss: 0.76149982213974, Accuracy: 0.751953125\n",
      "Batch: 10, Loss: 0.7566924691200256, Accuracy: 0.7490234375\n",
      "Batch: 11, Loss: 0.9223403334617615, Accuracy: 0.689453125\n",
      "Batch: 12, Loss: 0.8709213733673096, Accuracy: 0.7197265625\n",
      "Batch: 13, Loss: 0.6811249256134033, Accuracy: 0.7783203125\n",
      "Batch: 14, Loss: 0.904619038105011, Accuracy: 0.69140625\n",
      "Batch: 15, Loss: 0.7634739875793457, Accuracy: 0.759765625\n",
      "Batch: 16, Loss: 0.7831412553787231, Accuracy: 0.75\n",
      "Batch: 17, Loss: 0.8403171300888062, Accuracy: 0.732421875\n",
      "Batch: 18, Loss: 0.8752540349960327, Accuracy: 0.7119140625\n",
      "Batch: 19, Loss: 0.8541859984397888, Accuracy: 0.732421875\n",
      "Batch: 20, Loss: 0.7252904176712036, Accuracy: 0.7744140625\n",
      "Batch: 21, Loss: 0.7800650596618652, Accuracy: 0.7314453125\n",
      "Batch: 22, Loss: 0.8485077023506165, Accuracy: 0.7255859375\n",
      "Batch: 23, Loss: 0.8382777571678162, Accuracy: 0.7158203125\n",
      "Batch: 24, Loss: 0.7967367172241211, Accuracy: 0.73046875\n",
      "Batch: 25, Loss: 0.8550407290458679, Accuracy: 0.73046875\n",
      "Batch: 26, Loss: 0.6937254667282104, Accuracy: 0.7626953125\n",
      "Batch: 27, Loss: 0.7699542045593262, Accuracy: 0.7294921875\n",
      "Batch: 28, Loss: 0.8314131498336792, Accuracy: 0.7197265625\n",
      "Batch: 29, Loss: 0.767716646194458, Accuracy: 0.7451171875\n",
      "Batch: 30, Loss: 0.7551341652870178, Accuracy: 0.748046875\n",
      "Batch: 31, Loss: 0.7483006119728088, Accuracy: 0.7587890625\n",
      "Batch: 32, Loss: 0.7319595813751221, Accuracy: 0.75\n",
      "Batch: 33, Loss: 0.8589265942573547, Accuracy: 0.7109375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 34, Loss: 0.925922691822052, Accuracy: 0.7060546875\n",
      "Batch: 35, Loss: 0.7981334924697876, Accuracy: 0.7333984375\n",
      "Batch: 36, Loss: 0.8600103259086609, Accuracy: 0.728515625\n",
      "Batch: 37, Loss: 0.7753693461418152, Accuracy: 0.755859375\n",
      "Batch: 38, Loss: 0.841866135597229, Accuracy: 0.716796875\n",
      "Batch: 39, Loss: 0.8420273661613464, Accuracy: 0.724609375\n",
      "Batch: 40, Loss: 0.8204824924468994, Accuracy: 0.75390625\n",
      "Batch: 41, Loss: 0.7913720607757568, Accuracy: 0.744140625\n",
      "Batch: 42, Loss: 0.6140881776809692, Accuracy: 0.8017578125\n",
      "Batch: 43, Loss: 0.8571716547012329, Accuracy: 0.7060546875\n",
      "Batch: 44, Loss: 0.8276760578155518, Accuracy: 0.73046875\n",
      "Batch: 45, Loss: 0.7406158447265625, Accuracy: 0.7490234375\n",
      "Batch: 46, Loss: 0.7751593589782715, Accuracy: 0.7451171875\n",
      "Batch: 47, Loss: 0.7420812845230103, Accuracy: 0.7578125\n",
      "Batch: 48, Loss: 0.6762021780014038, Accuracy: 0.7568359375\n",
      "Batch: 49, Loss: 0.8468033671379089, Accuracy: 0.712890625\n",
      "Batch: 50, Loss: 0.8291398286819458, Accuracy: 0.73046875\n",
      "Batch: 51, Loss: 0.860287606716156, Accuracy: 0.71875\n",
      "Batch: 52, Loss: 0.843150794506073, Accuracy: 0.734375\n",
      "Batch: 53, Loss: 0.7591878771781921, Accuracy: 0.7451171875\n",
      "Batch: 54, Loss: 0.7990262508392334, Accuracy: 0.736328125\n",
      "Batch: 55, Loss: 0.8677563667297363, Accuracy: 0.69921875\n",
      "Batch: 56, Loss: 0.8609586954116821, Accuracy: 0.724609375\n",
      "Batch: 57, Loss: 0.7805830240249634, Accuracy: 0.736328125\n",
      "Batch: 58, Loss: 0.8953672051429749, Accuracy: 0.728515625\n",
      "Batch: 59, Loss: 0.7905287742614746, Accuracy: 0.7392578125\n",
      "Batch: 60, Loss: 0.7394880056381226, Accuracy: 0.7568359375\n",
      "Batch: 61, Loss: 0.831375002861023, Accuracy: 0.724609375\n",
      "Batch: 62, Loss: 0.774945855140686, Accuracy: 0.7578125\n",
      "Batch: 63, Loss: 0.8281043767929077, Accuracy: 0.7373046875\n",
      "Batch: 64, Loss: 0.7911311388015747, Accuracy: 0.740234375\n",
      "Batch: 65, Loss: 0.8202619552612305, Accuracy: 0.734375\n",
      "Batch: 66, Loss: 0.7653406858444214, Accuracy: 0.76953125\n",
      "Batch: 67, Loss: 0.8718017339706421, Accuracy: 0.7177734375\n",
      "Batch: 68, Loss: 0.908231258392334, Accuracy: 0.7177734375\n",
      "Batch: 69, Loss: 0.8430222272872925, Accuracy: 0.73046875\n",
      "Batch: 70, Loss: 0.7758642435073853, Accuracy: 0.748046875\n",
      "Batch: 71, Loss: 0.8215728998184204, Accuracy: 0.7197265625\n",
      "Batch: 72, Loss: 0.7144291996955872, Accuracy: 0.7666015625\n",
      "Batch: 73, Loss: 0.7164124250411987, Accuracy: 0.779296875\n",
      "Batch: 74, Loss: 0.7255995869636536, Accuracy: 0.7587890625\n",
      "Batch: 75, Loss: 0.6969350576400757, Accuracy: 0.78125\n",
      "Batch: 76, Loss: 0.820447564125061, Accuracy: 0.7333984375\n",
      "Batch: 77, Loss: 0.7500103712081909, Accuracy: 0.7548828125\n",
      "Batch: 78, Loss: 0.7281389236450195, Accuracy: 0.7744140625\n",
      "Batch: 79, Loss: 0.7195485234260559, Accuracy: 0.7705078125\n",
      "Batch: 80, Loss: 0.7581899166107178, Accuracy: 0.76171875\n",
      "Batch: 81, Loss: 0.866341769695282, Accuracy: 0.6982421875\n",
      "Batch: 82, Loss: 0.8429996967315674, Accuracy: 0.716796875\n",
      "Batch: 83, Loss: 0.6850695013999939, Accuracy: 0.787109375\n",
      "Batch: 84, Loss: 0.794908881187439, Accuracy: 0.7412109375\n",
      "Batch: 85, Loss: 0.733086109161377, Accuracy: 0.75390625\n",
      "Batch: 86, Loss: 0.9147510528564453, Accuracy: 0.7138671875\n",
      "Batch: 87, Loss: 0.7504415512084961, Accuracy: 0.7548828125\n",
      "Batch: 88, Loss: 0.8618781566619873, Accuracy: 0.7314453125\n",
      "Batch: 89, Loss: 0.84686279296875, Accuracy: 0.716796875\n",
      "Batch: 90, Loss: 0.7637060880661011, Accuracy: 0.7568359375\n",
      "Batch: 91, Loss: 0.8012923002243042, Accuracy: 0.7138671875\n",
      "Batch: 92, Loss: 0.7851161956787109, Accuracy: 0.748046875\n",
      "Batch: 93, Loss: 0.7652219533920288, Accuracy: 0.75390625\n",
      "Batch: 94, Loss: 0.7838870286941528, Accuracy: 0.744140625\n",
      "Batch: 95, Loss: 0.8632651567459106, Accuracy: 0.70703125\n",
      "Batch: 96, Loss: 0.8135868310928345, Accuracy: 0.736328125\n",
      "Batch: 97, Loss: 0.6607789993286133, Accuracy: 0.787109375\n",
      "Batch: 98, Loss: 0.7376008033752441, Accuracy: 0.7578125\n",
      "Batch: 99, Loss: 0.7710035443305969, Accuracy: 0.740234375\n",
      "Batch: 100, Loss: 0.8197869062423706, Accuracy: 0.736328125\n",
      "Batch: 101, Loss: 0.8454815149307251, Accuracy: 0.720703125\n",
      "Batch: 102, Loss: 0.8066883087158203, Accuracy: 0.73828125\n",
      "Batch: 103, Loss: 0.8095447421073914, Accuracy: 0.7451171875\n",
      "Batch: 104, Loss: 0.7627432346343994, Accuracy: 0.748046875\n",
      "Batch: 105, Loss: 0.836068868637085, Accuracy: 0.7294921875\n",
      "Batch: 106, Loss: 0.7888238430023193, Accuracy: 0.751953125\n",
      "Batch: 107, Loss: 0.8084812164306641, Accuracy: 0.74609375\n",
      "Batch: 108, Loss: 0.7910236120223999, Accuracy: 0.728515625\n",
      "Batch: 109, Loss: 0.8762606382369995, Accuracy: 0.70703125\n",
      "Batch: 110, Loss: 0.7434137463569641, Accuracy: 0.7578125\n",
      "Batch: 111, Loss: 0.856458306312561, Accuracy: 0.7197265625\n",
      "Batch: 112, Loss: 0.8188145160675049, Accuracy: 0.7353515625\n",
      "Batch: 113, Loss: 0.8473095893859863, Accuracy: 0.728515625\n",
      "Batch: 114, Loss: 0.8898547887802124, Accuracy: 0.705078125\n",
      "Batch: 115, Loss: 0.8998788595199585, Accuracy: 0.716796875\n",
      "Batch: 116, Loss: 0.8532545566558838, Accuracy: 0.7177734375\n",
      "Batch: 117, Loss: 0.8536972403526306, Accuracy: 0.7197265625\n",
      "Batch: 118, Loss: 0.7190930843353271, Accuracy: 0.7646484375\n",
      "Batch: 119, Loss: 0.6680302619934082, Accuracy: 0.78125\n",
      "Batch: 120, Loss: 0.8210231065750122, Accuracy: 0.7236328125\n",
      "Batch: 121, Loss: 0.8580654263496399, Accuracy: 0.720703125\n",
      "Batch: 122, Loss: 0.7774849534034729, Accuracy: 0.75390625\n",
      "Batch: 123, Loss: 0.7402451038360596, Accuracy: 0.7587890625\n",
      "Batch: 124, Loss: 0.8243074417114258, Accuracy: 0.7216796875\n",
      "Batch: 125, Loss: 0.8724378943443298, Accuracy: 0.708984375\n",
      "Batch: 126, Loss: 0.8330581188201904, Accuracy: 0.7412109375\n",
      "Batch: 127, Loss: 0.7286819219589233, Accuracy: 0.7607421875\n",
      "Batch: 128, Loss: 0.8827559351921082, Accuracy: 0.7294921875\n",
      "Batch: 129, Loss: 0.7730388641357422, Accuracy: 0.74609375\n",
      "Batch: 130, Loss: 0.9013500213623047, Accuracy: 0.7021484375\n",
      "Batch: 131, Loss: 0.8562912940979004, Accuracy: 0.71484375\n",
      "Batch: 132, Loss: 0.8419476747512817, Accuracy: 0.7255859375\n",
      "Batch: 133, Loss: 0.7681872844696045, Accuracy: 0.7421875\n",
      "Batch: 134, Loss: 0.823246955871582, Accuracy: 0.7314453125\n",
      "Batch: 135, Loss: 0.7168987989425659, Accuracy: 0.77734375\n",
      "Batch: 136, Loss: 0.8077651858329773, Accuracy: 0.7392578125\n",
      "Batch: 137, Loss: 0.7952867150306702, Accuracy: 0.7216796875\n",
      "Batch: 138, Loss: 0.7186400294303894, Accuracy: 0.7529296875\n",
      "Batch: 139, Loss: 0.7445213198661804, Accuracy: 0.736328125\n",
      "Batch: 140, Loss: 0.7922283411026001, Accuracy: 0.7265625\n",
      "Batch: 141, Loss: 0.8698546886444092, Accuracy: 0.7021484375\n",
      "Batch: 142, Loss: 0.8692444562911987, Accuracy: 0.7080078125\n",
      "Batch: 143, Loss: 0.8053526878356934, Accuracy: 0.748046875\n",
      "Batch: 144, Loss: 0.8046671748161316, Accuracy: 0.7353515625\n",
      "Batch: 145, Loss: 0.7720305323600769, Accuracy: 0.7333984375\n",
      "Batch: 146, Loss: 0.8241865634918213, Accuracy: 0.732421875\n",
      "Batch: 147, Loss: 0.8322702050209045, Accuracy: 0.720703125\n",
      "Batch: 148, Loss: 0.8900106549263, Accuracy: 0.7080078125\n",
      "Batch: 149, Loss: 0.7773199081420898, Accuracy: 0.7314453125\n",
      "Batch: 150, Loss: 0.7602896690368652, Accuracy: 0.751953125\n",
      "Batch: 151, Loss: 0.708698570728302, Accuracy: 0.767578125\n",
      "Epoch 27/90\n",
      "Batch: 1, Loss: 1.0192021131515503, Accuracy: 0.6728515625\n",
      "Batch: 2, Loss: 0.8977124094963074, Accuracy: 0.705078125\n",
      "Batch: 3, Loss: 0.7884254455566406, Accuracy: 0.7421875\n",
      "Batch: 4, Loss: 0.66370689868927, Accuracy: 0.7822265625\n",
      "Batch: 5, Loss: 0.7454030513763428, Accuracy: 0.76171875\n",
      "Batch: 6, Loss: 0.8285942077636719, Accuracy: 0.712890625\n",
      "Batch: 7, Loss: 0.8228700160980225, Accuracy: 0.7109375\n",
      "Batch: 8, Loss: 0.7541302442550659, Accuracy: 0.751953125\n",
      "Batch: 9, Loss: 0.7559677958488464, Accuracy: 0.76171875\n",
      "Batch: 10, Loss: 0.7406027913093567, Accuracy: 0.76171875\n",
      "Batch: 11, Loss: 0.8986549377441406, Accuracy: 0.69921875\n",
      "Batch: 12, Loss: 0.8751479983329773, Accuracy: 0.7119140625\n",
      "Batch: 13, Loss: 0.650922417640686, Accuracy: 0.77734375\n",
      "Batch: 14, Loss: 0.9107993245124817, Accuracy: 0.69921875\n",
      "Batch: 15, Loss: 0.7549149990081787, Accuracy: 0.7626953125\n",
      "Batch: 16, Loss: 0.7629119157791138, Accuracy: 0.75390625\n",
      "Batch: 17, Loss: 0.8451869487762451, Accuracy: 0.71875\n",
      "Batch: 18, Loss: 0.8032644987106323, Accuracy: 0.7451171875\n",
      "Batch: 19, Loss: 0.8458293676376343, Accuracy: 0.7294921875\n",
      "Batch: 20, Loss: 0.7083916068077087, Accuracy: 0.7685546875\n",
      "Batch: 21, Loss: 0.7285317182540894, Accuracy: 0.7568359375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 22, Loss: 0.8169986009597778, Accuracy: 0.744140625\n",
      "Batch: 23, Loss: 0.8280127048492432, Accuracy: 0.71484375\n",
      "Batch: 24, Loss: 0.7823216915130615, Accuracy: 0.7314453125\n",
      "Batch: 25, Loss: 0.7987767457962036, Accuracy: 0.744140625\n",
      "Batch: 26, Loss: 0.6622346639633179, Accuracy: 0.775390625\n",
      "Batch: 27, Loss: 0.7413386702537537, Accuracy: 0.74609375\n",
      "Batch: 28, Loss: 0.7958415746688843, Accuracy: 0.7265625\n",
      "Batch: 29, Loss: 0.7652220129966736, Accuracy: 0.7470703125\n",
      "Batch: 30, Loss: 0.710512101650238, Accuracy: 0.7666015625\n",
      "Batch: 31, Loss: 0.7164819240570068, Accuracy: 0.767578125\n",
      "Batch: 32, Loss: 0.7201460599899292, Accuracy: 0.7744140625\n",
      "Batch: 33, Loss: 0.8196096420288086, Accuracy: 0.73046875\n",
      "Batch: 34, Loss: 0.886203408241272, Accuracy: 0.712890625\n",
      "Batch: 35, Loss: 0.8034420013427734, Accuracy: 0.732421875\n",
      "Batch: 36, Loss: 0.8345588445663452, Accuracy: 0.736328125\n",
      "Batch: 37, Loss: 0.7722823023796082, Accuracy: 0.7490234375\n",
      "Batch: 38, Loss: 0.821845531463623, Accuracy: 0.716796875\n",
      "Batch: 39, Loss: 0.7924032211303711, Accuracy: 0.7314453125\n",
      "Batch: 40, Loss: 0.782538115978241, Accuracy: 0.7431640625\n",
      "Batch: 41, Loss: 0.7422546744346619, Accuracy: 0.7578125\n",
      "Batch: 42, Loss: 0.6254936456680298, Accuracy: 0.78515625\n",
      "Batch: 43, Loss: 0.8231515884399414, Accuracy: 0.7216796875\n",
      "Batch: 44, Loss: 0.8104174137115479, Accuracy: 0.7275390625\n",
      "Batch: 45, Loss: 0.7024271488189697, Accuracy: 0.7705078125\n",
      "Batch: 46, Loss: 0.7328932285308838, Accuracy: 0.76171875\n",
      "Batch: 47, Loss: 0.7138500809669495, Accuracy: 0.7763671875\n",
      "Batch: 48, Loss: 0.6763664484024048, Accuracy: 0.7744140625\n",
      "Batch: 49, Loss: 0.8228262662887573, Accuracy: 0.712890625\n",
      "Batch: 50, Loss: 0.8395803570747375, Accuracy: 0.7255859375\n",
      "Batch: 51, Loss: 0.8258124589920044, Accuracy: 0.720703125\n",
      "Batch: 52, Loss: 0.8223567008972168, Accuracy: 0.7236328125\n",
      "Batch: 53, Loss: 0.7296931743621826, Accuracy: 0.7646484375\n",
      "Batch: 54, Loss: 0.7641193866729736, Accuracy: 0.7490234375\n",
      "Batch: 55, Loss: 0.8859038352966309, Accuracy: 0.703125\n",
      "Batch: 56, Loss: 0.8177518844604492, Accuracy: 0.7373046875\n",
      "Batch: 57, Loss: 0.7748230695724487, Accuracy: 0.75\n",
      "Batch: 58, Loss: 0.8539611101150513, Accuracy: 0.728515625\n",
      "Batch: 59, Loss: 0.7574647665023804, Accuracy: 0.7548828125\n",
      "Batch: 60, Loss: 0.7210515737533569, Accuracy: 0.7734375\n",
      "Batch: 61, Loss: 0.7968071103096008, Accuracy: 0.734375\n",
      "Batch: 62, Loss: 0.7450443506240845, Accuracy: 0.751953125\n",
      "Batch: 63, Loss: 0.8204996585845947, Accuracy: 0.7333984375\n",
      "Batch: 64, Loss: 0.796123206615448, Accuracy: 0.7451171875\n",
      "Batch: 65, Loss: 0.8170380592346191, Accuracy: 0.728515625\n",
      "Batch: 66, Loss: 0.7691797614097595, Accuracy: 0.7607421875\n",
      "Batch: 67, Loss: 0.8512405157089233, Accuracy: 0.734375\n",
      "Batch: 68, Loss: 0.8896095752716064, Accuracy: 0.712890625\n",
      "Batch: 69, Loss: 0.8164405822753906, Accuracy: 0.74609375\n",
      "Batch: 70, Loss: 0.7506822347640991, Accuracy: 0.759765625\n",
      "Batch: 71, Loss: 0.8252173662185669, Accuracy: 0.71875\n",
      "Batch: 72, Loss: 0.7078983187675476, Accuracy: 0.7685546875\n",
      "Batch: 73, Loss: 0.6984707117080688, Accuracy: 0.7783203125\n",
      "Batch: 74, Loss: 0.6900882124900818, Accuracy: 0.7724609375\n",
      "Batch: 75, Loss: 0.7063406705856323, Accuracy: 0.7666015625\n",
      "Batch: 76, Loss: 0.7842000722885132, Accuracy: 0.7509765625\n",
      "Batch: 77, Loss: 0.7271682620048523, Accuracy: 0.775390625\n",
      "Batch: 78, Loss: 0.7314897775650024, Accuracy: 0.7744140625\n",
      "Batch: 79, Loss: 0.6886105537414551, Accuracy: 0.78515625\n",
      "Batch: 80, Loss: 0.76941978931427, Accuracy: 0.74609375\n",
      "Batch: 81, Loss: 0.8543251752853394, Accuracy: 0.71484375\n",
      "Batch: 82, Loss: 0.823752760887146, Accuracy: 0.73046875\n",
      "Batch: 83, Loss: 0.6703695058822632, Accuracy: 0.7958984375\n",
      "Batch: 84, Loss: 0.7759236693382263, Accuracy: 0.73828125\n",
      "Batch: 85, Loss: 0.7234468460083008, Accuracy: 0.767578125\n",
      "Batch: 86, Loss: 0.8944981098175049, Accuracy: 0.720703125\n",
      "Batch: 87, Loss: 0.7318481802940369, Accuracy: 0.771484375\n",
      "Batch: 88, Loss: 0.836367130279541, Accuracy: 0.732421875\n",
      "Batch: 89, Loss: 0.7949674129486084, Accuracy: 0.7373046875\n",
      "Batch: 90, Loss: 0.7535606622695923, Accuracy: 0.7568359375\n",
      "Batch: 91, Loss: 0.7626658082008362, Accuracy: 0.7548828125\n",
      "Batch: 92, Loss: 0.7902451157569885, Accuracy: 0.7412109375\n",
      "Batch: 93, Loss: 0.7493699789047241, Accuracy: 0.7529296875\n",
      "Batch: 94, Loss: 0.758991539478302, Accuracy: 0.7490234375\n",
      "Batch: 95, Loss: 0.8437023162841797, Accuracy: 0.7041015625\n",
      "Batch: 96, Loss: 0.7880977392196655, Accuracy: 0.73828125\n",
      "Batch: 97, Loss: 0.6393486261367798, Accuracy: 0.7900390625\n",
      "Batch: 98, Loss: 0.7254221439361572, Accuracy: 0.7646484375\n",
      "Batch: 99, Loss: 0.726337194442749, Accuracy: 0.7509765625\n",
      "Batch: 100, Loss: 0.7965818643569946, Accuracy: 0.7373046875\n",
      "Batch: 101, Loss: 0.8315247297286987, Accuracy: 0.734375\n",
      "Batch: 102, Loss: 0.7450265288352966, Accuracy: 0.7626953125\n",
      "Batch: 103, Loss: 0.7992411851882935, Accuracy: 0.748046875\n",
      "Batch: 104, Loss: 0.7250827550888062, Accuracy: 0.7607421875\n",
      "Batch: 105, Loss: 0.81358802318573, Accuracy: 0.7197265625\n",
      "Batch: 106, Loss: 0.7583681344985962, Accuracy: 0.75390625\n",
      "Batch: 107, Loss: 0.7849507331848145, Accuracy: 0.740234375\n",
      "Batch: 108, Loss: 0.7959591150283813, Accuracy: 0.728515625\n",
      "Batch: 109, Loss: 0.8848297595977783, Accuracy: 0.716796875\n",
      "Batch: 110, Loss: 0.7492730617523193, Accuracy: 0.7548828125\n",
      "Batch: 111, Loss: 0.8008816242218018, Accuracy: 0.7412109375\n",
      "Batch: 112, Loss: 0.7859396934509277, Accuracy: 0.767578125\n",
      "Batch: 113, Loss: 0.7886182069778442, Accuracy: 0.7412109375\n",
      "Batch: 114, Loss: 0.8613793253898621, Accuracy: 0.7099609375\n",
      "Batch: 115, Loss: 0.8835996389389038, Accuracy: 0.7236328125\n",
      "Batch: 116, Loss: 0.8281334638595581, Accuracy: 0.724609375\n",
      "Batch: 117, Loss: 0.8459258675575256, Accuracy: 0.724609375\n",
      "Batch: 118, Loss: 0.7257968187332153, Accuracy: 0.7705078125\n",
      "Batch: 119, Loss: 0.6693029403686523, Accuracy: 0.7744140625\n",
      "Batch: 120, Loss: 0.8102867603302002, Accuracy: 0.7314453125\n",
      "Batch: 121, Loss: 0.8354033827781677, Accuracy: 0.71875\n",
      "Batch: 122, Loss: 0.7401700019836426, Accuracy: 0.7666015625\n",
      "Batch: 123, Loss: 0.7306849360466003, Accuracy: 0.767578125\n",
      "Batch: 124, Loss: 0.8216083645820618, Accuracy: 0.7353515625\n",
      "Batch: 125, Loss: 0.7957369685173035, Accuracy: 0.7470703125\n",
      "Batch: 126, Loss: 0.8016600608825684, Accuracy: 0.7470703125\n",
      "Batch: 127, Loss: 0.682316780090332, Accuracy: 0.78515625\n",
      "Batch: 128, Loss: 0.8363576531410217, Accuracy: 0.7392578125\n",
      "Batch: 129, Loss: 0.7550069093704224, Accuracy: 0.7490234375\n",
      "Batch: 130, Loss: 0.8850568532943726, Accuracy: 0.7001953125\n",
      "Batch: 131, Loss: 0.8359240293502808, Accuracy: 0.7294921875\n",
      "Batch: 132, Loss: 0.8545472025871277, Accuracy: 0.724609375\n",
      "Batch: 133, Loss: 0.7414980530738831, Accuracy: 0.7392578125\n",
      "Batch: 134, Loss: 0.8121223449707031, Accuracy: 0.720703125\n",
      "Batch: 135, Loss: 0.7216833233833313, Accuracy: 0.775390625\n",
      "Batch: 136, Loss: 0.7935209274291992, Accuracy: 0.748046875\n",
      "Batch: 137, Loss: 0.756687343120575, Accuracy: 0.744140625\n",
      "Batch: 138, Loss: 0.6906098127365112, Accuracy: 0.77734375\n",
      "Batch: 139, Loss: 0.7502663135528564, Accuracy: 0.7421875\n",
      "Batch: 140, Loss: 0.779253363609314, Accuracy: 0.736328125\n",
      "Batch: 141, Loss: 0.8487660884857178, Accuracy: 0.7265625\n",
      "Batch: 142, Loss: 0.8390532732009888, Accuracy: 0.7333984375\n",
      "Batch: 143, Loss: 0.8095561265945435, Accuracy: 0.728515625\n",
      "Batch: 144, Loss: 0.8055166006088257, Accuracy: 0.7265625\n",
      "Batch: 145, Loss: 0.7601773142814636, Accuracy: 0.7353515625\n",
      "Batch: 146, Loss: 0.8159099817276001, Accuracy: 0.7353515625\n",
      "Batch: 147, Loss: 0.8038656711578369, Accuracy: 0.732421875\n",
      "Batch: 148, Loss: 0.8807917833328247, Accuracy: 0.7021484375\n",
      "Batch: 149, Loss: 0.7684642672538757, Accuracy: 0.7470703125\n",
      "Batch: 150, Loss: 0.7374240159988403, Accuracy: 0.75390625\n",
      "Batch: 151, Loss: 0.6916022896766663, Accuracy: 0.7724609375\n",
      "Epoch 28/90\n",
      "Batch: 1, Loss: 1.0027194023132324, Accuracy: 0.685546875\n",
      "Batch: 2, Loss: 0.8822053670883179, Accuracy: 0.7021484375\n",
      "Batch: 3, Loss: 0.7397354245185852, Accuracy: 0.7529296875\n",
      "Batch: 4, Loss: 0.6770299077033997, Accuracy: 0.783203125\n",
      "Batch: 5, Loss: 0.7272552847862244, Accuracy: 0.763671875\n",
      "Batch: 6, Loss: 0.8005996942520142, Accuracy: 0.7392578125\n",
      "Batch: 7, Loss: 0.7955933809280396, Accuracy: 0.7265625\n",
      "Batch: 8, Loss: 0.7582330107688904, Accuracy: 0.7685546875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 9, Loss: 0.7290166616439819, Accuracy: 0.759765625\n",
      "Batch: 10, Loss: 0.7221686244010925, Accuracy: 0.763671875\n",
      "Batch: 11, Loss: 0.8753782510757446, Accuracy: 0.7255859375\n",
      "Batch: 12, Loss: 0.83676677942276, Accuracy: 0.7236328125\n",
      "Batch: 13, Loss: 0.655545711517334, Accuracy: 0.78125\n",
      "Batch: 14, Loss: 0.9038029909133911, Accuracy: 0.6962890625\n",
      "Batch: 15, Loss: 0.7200008630752563, Accuracy: 0.76953125\n",
      "Batch: 16, Loss: 0.7660614252090454, Accuracy: 0.75\n",
      "Batch: 17, Loss: 0.8296760320663452, Accuracy: 0.7333984375\n",
      "Batch: 18, Loss: 0.833115816116333, Accuracy: 0.720703125\n",
      "Batch: 19, Loss: 0.794957160949707, Accuracy: 0.73828125\n",
      "Batch: 20, Loss: 0.6991162300109863, Accuracy: 0.77734375\n",
      "Batch: 21, Loss: 0.7292184233665466, Accuracy: 0.75390625\n",
      "Batch: 22, Loss: 0.8199682235717773, Accuracy: 0.740234375\n",
      "Batch: 23, Loss: 0.7838913798332214, Accuracy: 0.736328125\n",
      "Batch: 24, Loss: 0.7912645936012268, Accuracy: 0.744140625\n",
      "Batch: 25, Loss: 0.7887858152389526, Accuracy: 0.75\n",
      "Batch: 26, Loss: 0.6631375551223755, Accuracy: 0.7666015625\n",
      "Batch: 27, Loss: 0.7068439722061157, Accuracy: 0.7490234375\n",
      "Batch: 28, Loss: 0.7876361608505249, Accuracy: 0.7236328125\n",
      "Batch: 29, Loss: 0.750879168510437, Accuracy: 0.744140625\n",
      "Batch: 30, Loss: 0.7109948992729187, Accuracy: 0.7802734375\n",
      "Batch: 31, Loss: 0.6745734214782715, Accuracy: 0.7802734375\n",
      "Batch: 32, Loss: 0.7031541466712952, Accuracy: 0.7607421875\n",
      "Batch: 33, Loss: 0.8046610355377197, Accuracy: 0.728515625\n",
      "Batch: 34, Loss: 0.889746904373169, Accuracy: 0.71484375\n",
      "Batch: 35, Loss: 0.7747835516929626, Accuracy: 0.74609375\n",
      "Batch: 36, Loss: 0.813617467880249, Accuracy: 0.73828125\n",
      "Batch: 37, Loss: 0.7381089925765991, Accuracy: 0.7646484375\n",
      "Batch: 38, Loss: 0.7798675894737244, Accuracy: 0.73828125\n",
      "Batch: 39, Loss: 0.7559016942977905, Accuracy: 0.7509765625\n",
      "Batch: 40, Loss: 0.753227949142456, Accuracy: 0.7685546875\n",
      "Batch: 41, Loss: 0.7397545576095581, Accuracy: 0.7568359375\n",
      "Batch: 42, Loss: 0.5855916738510132, Accuracy: 0.80859375\n",
      "Batch: 43, Loss: 0.8246076107025146, Accuracy: 0.712890625\n",
      "Batch: 44, Loss: 0.8041674494743347, Accuracy: 0.744140625\n",
      "Batch: 45, Loss: 0.7008011341094971, Accuracy: 0.7568359375\n",
      "Batch: 46, Loss: 0.7043111324310303, Accuracy: 0.7705078125\n",
      "Batch: 47, Loss: 0.7145524024963379, Accuracy: 0.775390625\n",
      "Batch: 48, Loss: 0.6649428606033325, Accuracy: 0.77734375\n",
      "Batch: 49, Loss: 0.7858197689056396, Accuracy: 0.7392578125\n",
      "Batch: 50, Loss: 0.7731246948242188, Accuracy: 0.751953125\n",
      "Batch: 51, Loss: 0.801449179649353, Accuracy: 0.7216796875\n",
      "Batch: 52, Loss: 0.8196585178375244, Accuracy: 0.73828125\n",
      "Batch: 53, Loss: 0.7125234007835388, Accuracy: 0.765625\n",
      "Batch: 54, Loss: 0.7499654293060303, Accuracy: 0.7451171875\n",
      "Batch: 55, Loss: 0.8701027631759644, Accuracy: 0.7119140625\n",
      "Batch: 56, Loss: 0.7996687293052673, Accuracy: 0.7470703125\n",
      "Batch: 57, Loss: 0.7455493807792664, Accuracy: 0.748046875\n",
      "Batch: 58, Loss: 0.8301592469215393, Accuracy: 0.748046875\n",
      "Batch: 59, Loss: 0.7554165124893188, Accuracy: 0.7578125\n",
      "Batch: 60, Loss: 0.7046046257019043, Accuracy: 0.775390625\n",
      "Batch: 61, Loss: 0.7834084630012512, Accuracy: 0.7373046875\n",
      "Batch: 62, Loss: 0.7204322218894958, Accuracy: 0.767578125\n",
      "Batch: 63, Loss: 0.8092849254608154, Accuracy: 0.7314453125\n",
      "Batch: 64, Loss: 0.7660379409790039, Accuracy: 0.7451171875\n",
      "Batch: 65, Loss: 0.7720884084701538, Accuracy: 0.7578125\n",
      "Batch: 66, Loss: 0.7363944053649902, Accuracy: 0.7763671875\n",
      "Batch: 67, Loss: 0.8494086861610413, Accuracy: 0.7255859375\n",
      "Batch: 68, Loss: 0.869207501411438, Accuracy: 0.72265625\n",
      "Batch: 69, Loss: 0.791378378868103, Accuracy: 0.740234375\n",
      "Batch: 70, Loss: 0.7300512790679932, Accuracy: 0.7646484375\n",
      "Batch: 71, Loss: 0.8256251215934753, Accuracy: 0.71875\n",
      "Batch: 72, Loss: 0.7186493873596191, Accuracy: 0.7705078125\n",
      "Batch: 73, Loss: 0.689017117023468, Accuracy: 0.78515625\n",
      "Batch: 74, Loss: 0.6627247333526611, Accuracy: 0.7861328125\n",
      "Batch: 75, Loss: 0.6758002042770386, Accuracy: 0.779296875\n",
      "Batch: 76, Loss: 0.792822003364563, Accuracy: 0.7373046875\n",
      "Batch: 77, Loss: 0.6966809034347534, Accuracy: 0.78125\n",
      "Batch: 78, Loss: 0.7050409317016602, Accuracy: 0.77734375\n",
      "Batch: 79, Loss: 0.6819116473197937, Accuracy: 0.7880859375\n",
      "Batch: 80, Loss: 0.7288919687271118, Accuracy: 0.759765625\n",
      "Batch: 81, Loss: 0.8430179953575134, Accuracy: 0.7265625\n",
      "Batch: 82, Loss: 0.7809606790542603, Accuracy: 0.7333984375\n",
      "Batch: 83, Loss: 0.6552442312240601, Accuracy: 0.7998046875\n",
      "Batch: 84, Loss: 0.7346452474594116, Accuracy: 0.7666015625\n",
      "Batch: 85, Loss: 0.6897633075714111, Accuracy: 0.775390625\n",
      "Batch: 86, Loss: 0.8655833601951599, Accuracy: 0.7177734375\n",
      "Batch: 87, Loss: 0.7125844955444336, Accuracy: 0.767578125\n",
      "Batch: 88, Loss: 0.8158726692199707, Accuracy: 0.734375\n",
      "Batch: 89, Loss: 0.7777406573295593, Accuracy: 0.76171875\n",
      "Batch: 90, Loss: 0.7322156429290771, Accuracy: 0.76171875\n",
      "Batch: 91, Loss: 0.7660306692123413, Accuracy: 0.75\n",
      "Batch: 92, Loss: 0.7671149373054504, Accuracy: 0.7490234375\n",
      "Batch: 93, Loss: 0.7145618200302124, Accuracy: 0.7568359375\n",
      "Batch: 94, Loss: 0.7448771595954895, Accuracy: 0.75\n",
      "Batch: 95, Loss: 0.8108161687850952, Accuracy: 0.7275390625\n",
      "Batch: 96, Loss: 0.7766043543815613, Accuracy: 0.7607421875\n",
      "Batch: 97, Loss: 0.6332324743270874, Accuracy: 0.798828125\n",
      "Batch: 98, Loss: 0.7428185343742371, Accuracy: 0.7490234375\n",
      "Batch: 99, Loss: 0.7290880084037781, Accuracy: 0.7646484375\n",
      "Batch: 100, Loss: 0.7695382833480835, Accuracy: 0.7353515625\n",
      "Batch: 101, Loss: 0.7901448607444763, Accuracy: 0.72265625\n",
      "Batch: 102, Loss: 0.7232392430305481, Accuracy: 0.75\n",
      "Batch: 103, Loss: 0.7716355323791504, Accuracy: 0.73828125\n",
      "Batch: 104, Loss: 0.7365514039993286, Accuracy: 0.7490234375\n",
      "Batch: 105, Loss: 0.821010172367096, Accuracy: 0.7294921875\n",
      "Batch: 106, Loss: 0.7425671815872192, Accuracy: 0.767578125\n",
      "Batch: 107, Loss: 0.7810008525848389, Accuracy: 0.7392578125\n",
      "Batch: 108, Loss: 0.7864910364151001, Accuracy: 0.732421875\n",
      "Batch: 109, Loss: 0.8480200171470642, Accuracy: 0.7255859375\n",
      "Batch: 110, Loss: 0.7229741811752319, Accuracy: 0.7646484375\n",
      "Batch: 111, Loss: 0.8251998424530029, Accuracy: 0.7333984375\n",
      "Batch: 112, Loss: 0.7907626032829285, Accuracy: 0.7529296875\n",
      "Batch: 113, Loss: 0.740127682685852, Accuracy: 0.7626953125\n",
      "Batch: 114, Loss: 0.8439878225326538, Accuracy: 0.724609375\n",
      "Batch: 115, Loss: 0.8674325346946716, Accuracy: 0.724609375\n",
      "Batch: 116, Loss: 0.8006948232650757, Accuracy: 0.7421875\n",
      "Batch: 117, Loss: 0.8305342793464661, Accuracy: 0.7255859375\n",
      "Batch: 118, Loss: 0.7032047510147095, Accuracy: 0.759765625\n",
      "Batch: 119, Loss: 0.6550405025482178, Accuracy: 0.7900390625\n",
      "Batch: 120, Loss: 0.7806539535522461, Accuracy: 0.7412109375\n",
      "Batch: 121, Loss: 0.8078809976577759, Accuracy: 0.7353515625\n",
      "Batch: 122, Loss: 0.7543039321899414, Accuracy: 0.75390625\n",
      "Batch: 123, Loss: 0.7354022264480591, Accuracy: 0.7646484375\n",
      "Batch: 124, Loss: 0.787080705165863, Accuracy: 0.7412109375\n",
      "Batch: 125, Loss: 0.8094040751457214, Accuracy: 0.7392578125\n",
      "Batch: 126, Loss: 0.8276888132095337, Accuracy: 0.7470703125\n",
      "Batch: 127, Loss: 0.6733677387237549, Accuracy: 0.791015625\n",
      "Batch: 128, Loss: 0.8443799614906311, Accuracy: 0.7275390625\n",
      "Batch: 129, Loss: 0.7551173567771912, Accuracy: 0.75\n",
      "Batch: 130, Loss: 0.8746813535690308, Accuracy: 0.71875\n",
      "Batch: 131, Loss: 0.7773455381393433, Accuracy: 0.7529296875\n",
      "Batch: 132, Loss: 0.7988258600234985, Accuracy: 0.7412109375\n",
      "Batch: 133, Loss: 0.7450802326202393, Accuracy: 0.75\n",
      "Batch: 134, Loss: 0.8167039155960083, Accuracy: 0.7255859375\n",
      "Batch: 135, Loss: 0.6876094341278076, Accuracy: 0.7880859375\n",
      "Batch: 136, Loss: 0.7825058102607727, Accuracy: 0.751953125\n",
      "Batch: 137, Loss: 0.7627649903297424, Accuracy: 0.744140625\n",
      "Batch: 138, Loss: 0.6820985078811646, Accuracy: 0.7783203125\n",
      "Batch: 139, Loss: 0.715024471282959, Accuracy: 0.767578125\n",
      "Batch: 140, Loss: 0.7668153047561646, Accuracy: 0.7392578125\n",
      "Batch: 141, Loss: 0.8155852556228638, Accuracy: 0.720703125\n",
      "Batch: 142, Loss: 0.81220942735672, Accuracy: 0.7255859375\n",
      "Batch: 143, Loss: 0.7749353647232056, Accuracy: 0.7529296875\n",
      "Batch: 144, Loss: 0.7661318778991699, Accuracy: 0.744140625\n",
      "Batch: 145, Loss: 0.7285274267196655, Accuracy: 0.765625\n",
      "Batch: 146, Loss: 0.8060873746871948, Accuracy: 0.7275390625\n",
      "Batch: 147, Loss: 0.7691749334335327, Accuracy: 0.7353515625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 148, Loss: 0.8392685651779175, Accuracy: 0.740234375\n",
      "Batch: 149, Loss: 0.7357957363128662, Accuracy: 0.7490234375\n",
      "Batch: 150, Loss: 0.7219581604003906, Accuracy: 0.7626953125\n",
      "Batch: 151, Loss: 0.6682960987091064, Accuracy: 0.779296875\n",
      "Epoch 29/90\n",
      "Batch: 1, Loss: 1.0005409717559814, Accuracy: 0.669921875\n",
      "Batch: 2, Loss: 0.8733366131782532, Accuracy: 0.6962890625\n",
      "Batch: 3, Loss: 0.7336618900299072, Accuracy: 0.75390625\n",
      "Batch: 4, Loss: 0.6594094038009644, Accuracy: 0.779296875\n",
      "Batch: 5, Loss: 0.7181371450424194, Accuracy: 0.7626953125\n",
      "Batch: 6, Loss: 0.7658596634864807, Accuracy: 0.74609375\n",
      "Batch: 7, Loss: 0.8171024322509766, Accuracy: 0.720703125\n",
      "Batch: 8, Loss: 0.7764894962310791, Accuracy: 0.74609375\n",
      "Batch: 9, Loss: 0.7486893534660339, Accuracy: 0.751953125\n",
      "Batch: 10, Loss: 0.72548508644104, Accuracy: 0.759765625\n",
      "Batch: 11, Loss: 0.8598321676254272, Accuracy: 0.71484375\n",
      "Batch: 12, Loss: 0.8261217474937439, Accuracy: 0.734375\n",
      "Batch: 13, Loss: 0.6468499898910522, Accuracy: 0.7763671875\n",
      "Batch: 14, Loss: 0.8558434844017029, Accuracy: 0.7177734375\n",
      "Batch: 15, Loss: 0.707645058631897, Accuracy: 0.77734375\n",
      "Batch: 16, Loss: 0.7547445297241211, Accuracy: 0.7587890625\n",
      "Batch: 17, Loss: 0.7880628705024719, Accuracy: 0.7421875\n",
      "Batch: 18, Loss: 0.8070575594902039, Accuracy: 0.736328125\n",
      "Batch: 19, Loss: 0.7896976470947266, Accuracy: 0.7470703125\n",
      "Batch: 20, Loss: 0.6429197192192078, Accuracy: 0.798828125\n",
      "Batch: 21, Loss: 0.7362843155860901, Accuracy: 0.759765625\n",
      "Batch: 22, Loss: 0.8103305101394653, Accuracy: 0.7392578125\n",
      "Batch: 23, Loss: 0.7946321964263916, Accuracy: 0.724609375\n",
      "Batch: 24, Loss: 0.7635307908058167, Accuracy: 0.7333984375\n",
      "Batch: 25, Loss: 0.7917132377624512, Accuracy: 0.7529296875\n",
      "Batch: 26, Loss: 0.6478697061538696, Accuracy: 0.78125\n",
      "Batch: 27, Loss: 0.6787601113319397, Accuracy: 0.763671875\n",
      "Batch: 28, Loss: 0.7855404019355774, Accuracy: 0.7333984375\n",
      "Batch: 29, Loss: 0.7413138151168823, Accuracy: 0.74609375\n",
      "Batch: 30, Loss: 0.6695261001586914, Accuracy: 0.779296875\n",
      "Batch: 31, Loss: 0.6901892423629761, Accuracy: 0.7724609375\n",
      "Batch: 32, Loss: 0.6983585953712463, Accuracy: 0.755859375\n",
      "Batch: 33, Loss: 0.8030129075050354, Accuracy: 0.7421875\n",
      "Batch: 34, Loss: 0.8644071817398071, Accuracy: 0.71875\n",
      "Batch: 35, Loss: 0.7941257953643799, Accuracy: 0.7314453125\n",
      "Batch: 36, Loss: 0.7931109666824341, Accuracy: 0.7509765625\n",
      "Batch: 37, Loss: 0.7249066829681396, Accuracy: 0.7646484375\n",
      "Batch: 38, Loss: 0.7571820616722107, Accuracy: 0.765625\n",
      "Batch: 39, Loss: 0.7641122341156006, Accuracy: 0.7294921875\n",
      "Batch: 40, Loss: 0.7668731808662415, Accuracy: 0.7607421875\n",
      "Batch: 41, Loss: 0.7116270065307617, Accuracy: 0.7646484375\n",
      "Batch: 42, Loss: 0.583918571472168, Accuracy: 0.8056640625\n",
      "Batch: 43, Loss: 0.7947560548782349, Accuracy: 0.7314453125\n",
      "Batch: 44, Loss: 0.7714009284973145, Accuracy: 0.755859375\n",
      "Batch: 45, Loss: 0.7011033892631531, Accuracy: 0.7568359375\n",
      "Batch: 46, Loss: 0.724315881729126, Accuracy: 0.767578125\n",
      "Batch: 47, Loss: 0.672455370426178, Accuracy: 0.791015625\n",
      "Batch: 48, Loss: 0.6335846185684204, Accuracy: 0.7890625\n",
      "Batch: 49, Loss: 0.8006508946418762, Accuracy: 0.7177734375\n",
      "Batch: 50, Loss: 0.7861760854721069, Accuracy: 0.755859375\n",
      "Batch: 51, Loss: 0.7691572904586792, Accuracy: 0.7568359375\n",
      "Batch: 52, Loss: 0.7582181096076965, Accuracy: 0.7568359375\n",
      "Batch: 53, Loss: 0.6915476322174072, Accuracy: 0.763671875\n",
      "Batch: 54, Loss: 0.7319529056549072, Accuracy: 0.7529296875\n",
      "Batch: 55, Loss: 0.8723119497299194, Accuracy: 0.7177734375\n",
      "Batch: 56, Loss: 0.8107180595397949, Accuracy: 0.73828125\n",
      "Batch: 57, Loss: 0.7440087795257568, Accuracy: 0.7412109375\n",
      "Batch: 58, Loss: 0.8447307348251343, Accuracy: 0.7353515625\n",
      "Batch: 59, Loss: 0.7166792154312134, Accuracy: 0.7724609375\n",
      "Batch: 60, Loss: 0.7045178413391113, Accuracy: 0.7744140625\n",
      "Batch: 61, Loss: 0.7798821926116943, Accuracy: 0.7451171875\n",
      "Batch: 62, Loss: 0.7157177925109863, Accuracy: 0.7685546875\n",
      "Batch: 63, Loss: 0.780724823474884, Accuracy: 0.7421875\n",
      "Batch: 64, Loss: 0.7536166906356812, Accuracy: 0.748046875\n",
      "Batch: 65, Loss: 0.786846399307251, Accuracy: 0.751953125\n",
      "Batch: 66, Loss: 0.7205017805099487, Accuracy: 0.7763671875\n",
      "Batch: 67, Loss: 0.8280417323112488, Accuracy: 0.7265625\n",
      "Batch: 68, Loss: 0.8608760833740234, Accuracy: 0.7265625\n",
      "Batch: 69, Loss: 0.7944397926330566, Accuracy: 0.7529296875\n",
      "Batch: 70, Loss: 0.6998382210731506, Accuracy: 0.7861328125\n",
      "Batch: 71, Loss: 0.768284797668457, Accuracy: 0.7373046875\n",
      "Batch: 72, Loss: 0.6916869878768921, Accuracy: 0.7841796875\n",
      "Batch: 73, Loss: 0.6758390069007874, Accuracy: 0.7890625\n",
      "Batch: 74, Loss: 0.6607888340950012, Accuracy: 0.78515625\n",
      "Batch: 75, Loss: 0.6632454991340637, Accuracy: 0.7744140625\n",
      "Batch: 76, Loss: 0.786859393119812, Accuracy: 0.7314453125\n",
      "Batch: 77, Loss: 0.6948580741882324, Accuracy: 0.775390625\n",
      "Batch: 78, Loss: 0.6822747588157654, Accuracy: 0.77734375\n",
      "Batch: 79, Loss: 0.6595684289932251, Accuracy: 0.7919921875\n",
      "Batch: 80, Loss: 0.7001198530197144, Accuracy: 0.7568359375\n",
      "Batch: 81, Loss: 0.8198087811470032, Accuracy: 0.7158203125\n",
      "Batch: 82, Loss: 0.7612260580062866, Accuracy: 0.748046875\n",
      "Batch: 83, Loss: 0.6377627849578857, Accuracy: 0.796875\n",
      "Batch: 84, Loss: 0.7321776151657104, Accuracy: 0.75390625\n",
      "Batch: 85, Loss: 0.6849955916404724, Accuracy: 0.7744140625\n",
      "Batch: 86, Loss: 0.8479883670806885, Accuracy: 0.7216796875\n",
      "Batch: 87, Loss: 0.7091985940933228, Accuracy: 0.7705078125\n",
      "Batch: 88, Loss: 0.7740581035614014, Accuracy: 0.744140625\n",
      "Batch: 89, Loss: 0.7621585130691528, Accuracy: 0.7587890625\n",
      "Batch: 90, Loss: 0.7181105613708496, Accuracy: 0.7626953125\n",
      "Batch: 91, Loss: 0.7233511209487915, Accuracy: 0.7587890625\n",
      "Batch: 92, Loss: 0.7333378791809082, Accuracy: 0.75\n",
      "Batch: 93, Loss: 0.7195432186126709, Accuracy: 0.7509765625\n",
      "Batch: 94, Loss: 0.7267907857894897, Accuracy: 0.7626953125\n",
      "Batch: 95, Loss: 0.7953121066093445, Accuracy: 0.7236328125\n",
      "Batch: 96, Loss: 0.7806446552276611, Accuracy: 0.7373046875\n",
      "Batch: 97, Loss: 0.6267685294151306, Accuracy: 0.79296875\n",
      "Batch: 98, Loss: 0.7015122771263123, Accuracy: 0.76171875\n",
      "Batch: 99, Loss: 0.7170841693878174, Accuracy: 0.7666015625\n",
      "Batch: 100, Loss: 0.7606895565986633, Accuracy: 0.75390625\n",
      "Batch: 101, Loss: 0.8004342317581177, Accuracy: 0.73828125\n",
      "Batch: 102, Loss: 0.7313131093978882, Accuracy: 0.76171875\n",
      "Batch: 103, Loss: 0.7545691728591919, Accuracy: 0.765625\n",
      "Batch: 104, Loss: 0.6996454000473022, Accuracy: 0.7607421875\n",
      "Batch: 105, Loss: 0.7716284990310669, Accuracy: 0.751953125\n",
      "Batch: 106, Loss: 0.7348232269287109, Accuracy: 0.7685546875\n",
      "Batch: 107, Loss: 0.7584882974624634, Accuracy: 0.7509765625\n",
      "Batch: 108, Loss: 0.7572821378707886, Accuracy: 0.74609375\n",
      "Batch: 109, Loss: 0.8363159894943237, Accuracy: 0.7060546875\n",
      "Batch: 110, Loss: 0.6968700289726257, Accuracy: 0.7705078125\n",
      "Batch: 111, Loss: 0.8064757585525513, Accuracy: 0.7421875\n",
      "Batch: 112, Loss: 0.7880541086196899, Accuracy: 0.75\n",
      "Batch: 113, Loss: 0.7615820169448853, Accuracy: 0.748046875\n",
      "Batch: 114, Loss: 0.8449891209602356, Accuracy: 0.728515625\n",
      "Batch: 115, Loss: 0.8514032363891602, Accuracy: 0.73046875\n",
      "Batch: 116, Loss: 0.7974604368209839, Accuracy: 0.7353515625\n",
      "Batch: 117, Loss: 0.8292829394340515, Accuracy: 0.7236328125\n",
      "Batch: 118, Loss: 0.6782480478286743, Accuracy: 0.78125\n",
      "Batch: 119, Loss: 0.6245328187942505, Accuracy: 0.7919921875\n",
      "Batch: 120, Loss: 0.7747945785522461, Accuracy: 0.728515625\n",
      "Batch: 121, Loss: 0.7943363785743713, Accuracy: 0.74609375\n",
      "Batch: 122, Loss: 0.7207331657409668, Accuracy: 0.7744140625\n",
      "Batch: 123, Loss: 0.7024074196815491, Accuracy: 0.767578125\n",
      "Batch: 124, Loss: 0.7733376622200012, Accuracy: 0.7509765625\n",
      "Batch: 125, Loss: 0.778567910194397, Accuracy: 0.7529296875\n",
      "Batch: 126, Loss: 0.795356273651123, Accuracy: 0.7490234375\n",
      "Batch: 127, Loss: 0.6544093489646912, Accuracy: 0.8037109375\n",
      "Batch: 128, Loss: 0.7958444356918335, Accuracy: 0.74609375\n",
      "Batch: 129, Loss: 0.7248064875602722, Accuracy: 0.767578125\n",
      "Batch: 130, Loss: 0.8610624670982361, Accuracy: 0.7197265625\n",
      "Batch: 131, Loss: 0.771514356136322, Accuracy: 0.73828125\n",
      "Batch: 132, Loss: 0.8110132217407227, Accuracy: 0.73828125\n",
      "Batch: 133, Loss: 0.7144408822059631, Accuracy: 0.7548828125\n",
      "Batch: 134, Loss: 0.7757983207702637, Accuracy: 0.7421875\n",
      "Batch: 135, Loss: 0.7024321556091309, Accuracy: 0.771484375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 136, Loss: 0.7490136623382568, Accuracy: 0.75390625\n",
      "Batch: 137, Loss: 0.7442200183868408, Accuracy: 0.7451171875\n",
      "Batch: 138, Loss: 0.6763197183609009, Accuracy: 0.771484375\n",
      "Batch: 139, Loss: 0.7260435819625854, Accuracy: 0.7470703125\n",
      "Batch: 140, Loss: 0.752963662147522, Accuracy: 0.7490234375\n",
      "Batch: 141, Loss: 0.8009020686149597, Accuracy: 0.7314453125\n",
      "Batch: 142, Loss: 0.816673994064331, Accuracy: 0.7333984375\n",
      "Batch: 143, Loss: 0.767019510269165, Accuracy: 0.7607421875\n",
      "Batch: 144, Loss: 0.7772795557975769, Accuracy: 0.748046875\n",
      "Batch: 145, Loss: 0.7215788960456848, Accuracy: 0.763671875\n",
      "Batch: 146, Loss: 0.7598428726196289, Accuracy: 0.7490234375\n",
      "Batch: 147, Loss: 0.770388126373291, Accuracy: 0.7373046875\n",
      "Batch: 148, Loss: 0.8439505100250244, Accuracy: 0.7294921875\n",
      "Batch: 149, Loss: 0.7266820073127747, Accuracy: 0.7607421875\n",
      "Batch: 150, Loss: 0.7083657383918762, Accuracy: 0.7646484375\n",
      "Batch: 151, Loss: 0.6592182517051697, Accuracy: 0.7841796875\n",
      "Epoch 30/90\n",
      "Batch: 1, Loss: 0.951542854309082, Accuracy: 0.6923828125\n",
      "Batch: 2, Loss: 0.8215514421463013, Accuracy: 0.7041015625\n",
      "Batch: 3, Loss: 0.7146093249320984, Accuracy: 0.771484375\n",
      "Batch: 4, Loss: 0.6384327411651611, Accuracy: 0.7939453125\n",
      "Batch: 5, Loss: 0.6885543465614319, Accuracy: 0.783203125\n",
      "Batch: 6, Loss: 0.7679627537727356, Accuracy: 0.740234375\n",
      "Batch: 7, Loss: 0.772454559803009, Accuracy: 0.7373046875\n",
      "Batch: 8, Loss: 0.7485803365707397, Accuracy: 0.74609375\n",
      "Batch: 9, Loss: 0.7345117330551147, Accuracy: 0.7666015625\n",
      "Batch: 10, Loss: 0.7192997932434082, Accuracy: 0.755859375\n",
      "Batch: 11, Loss: 0.8182706236839294, Accuracy: 0.7353515625\n",
      "Batch: 12, Loss: 0.7948320508003235, Accuracy: 0.7470703125\n",
      "Batch: 13, Loss: 0.6086794137954712, Accuracy: 0.7978515625\n",
      "Batch: 14, Loss: 0.8357618451118469, Accuracy: 0.7197265625\n",
      "Batch: 15, Loss: 0.6781806945800781, Accuracy: 0.7802734375\n",
      "Batch: 16, Loss: 0.7187667489051819, Accuracy: 0.7646484375\n",
      "Batch: 17, Loss: 0.77857506275177, Accuracy: 0.7529296875\n",
      "Batch: 18, Loss: 0.7917863130569458, Accuracy: 0.7265625\n",
      "Batch: 19, Loss: 0.7980896830558777, Accuracy: 0.7451171875\n",
      "Batch: 20, Loss: 0.6530332565307617, Accuracy: 0.783203125\n",
      "Batch: 21, Loss: 0.7042091488838196, Accuracy: 0.77734375\n",
      "Batch: 22, Loss: 0.8022250533103943, Accuracy: 0.736328125\n",
      "Batch: 23, Loss: 0.7418869733810425, Accuracy: 0.7578125\n",
      "Batch: 24, Loss: 0.7478349208831787, Accuracy: 0.7421875\n",
      "Batch: 25, Loss: 0.7298476696014404, Accuracy: 0.771484375\n",
      "Batch: 26, Loss: 0.6461433172225952, Accuracy: 0.7734375\n",
      "Batch: 27, Loss: 0.7014262676239014, Accuracy: 0.7607421875\n",
      "Batch: 28, Loss: 0.7719632983207703, Accuracy: 0.724609375\n",
      "Batch: 29, Loss: 0.7089661359786987, Accuracy: 0.759765625\n",
      "Batch: 30, Loss: 0.6797987222671509, Accuracy: 0.7763671875\n",
      "Batch: 31, Loss: 0.654682457447052, Accuracy: 0.775390625\n",
      "Batch: 32, Loss: 0.6956976056098938, Accuracy: 0.7744140625\n",
      "Batch: 33, Loss: 0.7791770696640015, Accuracy: 0.7509765625\n",
      "Batch: 34, Loss: 0.8318026661872864, Accuracy: 0.720703125\n",
      "Batch: 35, Loss: 0.7649248838424683, Accuracy: 0.73828125\n",
      "Batch: 36, Loss: 0.789824903011322, Accuracy: 0.751953125\n",
      "Batch: 37, Loss: 0.7423011660575867, Accuracy: 0.7783203125\n",
      "Batch: 38, Loss: 0.7596089839935303, Accuracy: 0.740234375\n",
      "Batch: 39, Loss: 0.7638143301010132, Accuracy: 0.7490234375\n",
      "Batch: 40, Loss: 0.731510579586029, Accuracy: 0.767578125\n",
      "Batch: 41, Loss: 0.7145257592201233, Accuracy: 0.767578125\n",
      "Batch: 42, Loss: 0.5895016193389893, Accuracy: 0.8095703125\n",
      "Batch: 43, Loss: 0.7779580354690552, Accuracy: 0.74609375\n",
      "Batch: 44, Loss: 0.7676419019699097, Accuracy: 0.7451171875\n",
      "Batch: 45, Loss: 0.671509325504303, Accuracy: 0.7705078125\n",
      "Batch: 46, Loss: 0.6874488592147827, Accuracy: 0.7724609375\n",
      "Batch: 47, Loss: 0.6620483994483948, Accuracy: 0.7998046875\n",
      "Batch: 48, Loss: 0.6296839714050293, Accuracy: 0.7958984375\n",
      "Batch: 49, Loss: 0.7814728021621704, Accuracy: 0.7548828125\n",
      "Batch: 50, Loss: 0.7780125141143799, Accuracy: 0.7490234375\n",
      "Batch: 51, Loss: 0.7765291929244995, Accuracy: 0.75\n",
      "Batch: 52, Loss: 0.7702280282974243, Accuracy: 0.7470703125\n",
      "Batch: 53, Loss: 0.6963552236557007, Accuracy: 0.7685546875\n",
      "Batch: 54, Loss: 0.7233402729034424, Accuracy: 0.75390625\n"
     ]
    }
   ],
   "source": [
    "file = open(os.path.join(data_directory, data_file), mode = 'r')\n",
    "data = file.read()\n",
    "file.close()\n",
    "if __name__ == \"__main__\":\n",
    "    training_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = pd.read_csv(os.path.join(data_directory, \"log.csv\"))\n",
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
